Automatically generated by Mendeley Desktop 1.13.6
Any changes to this file will be lost if it is regenerated by Mendeley.

BibTeX export options can be customized via Options -> BibTeX in Mendeley Desktop

@article{Zimmermann1980a,
author = {Zimmermann, Hubert},
file = {:home/tomaton/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Unknown - Unknown - OSI(1).pdf.pdf:pdf},
journal = {IEEE Transactions om Communications},
title = {{OSI Reference Model - The ISO Model of Architecture for Open Systems Interconnection}},
year = {1980}
}
@book{Manly2007,
abstract = {We study three different aspects of computational biology: interacting particle systems, phylogenetic distance methods, and Markov Chain Monte Carlo. Our study of interacting particle systems has two components: First, a Windowsbased simulator has been developed. It serves as a platform for many spatial biology studies; for example, plasmid transfer in biofilms. Second, a specific ecological model of multi-species cross-feeding has been studied using the simulator, where we have observed spatial self-organization and pattern formation (particularly, spiral waves). A mathematical derivation, which is based on analysis of partial differential equations, explains the phase-transitions observed in simulations. Distance methods have been widely used to infer phylogenies (evolution trees among different species) because they are fast and reasonably accurate. In this study, we have proved that a popular distance method named neighbor-joining is in fact a special case of least squares methods. The proof relates neighbor-joining to least squares statistics. Hence it provides an explanation for the robustness and accuracy of neighbor-joining. In an empirical study of MCMC, we investigate, through extensive simulations, how a mixture of local and heavy-tailed proposals (a.k.a., small world proposals) can dramatically increase the convergence rates of Markov chains that admit stationary measures that are multi-modal. In the theoretical part of the study, we have proved, using techniques of state decomposition and isoperimetric inequalities for log-concave distributions, that the small world proposals turn a slowly mixing chain into a rapidly mixing chain.},
author = {Manly, B F J},
booktitle = {Texts in statistical science},
doi = {10.2307/1271419},
isbn = {1584885416},
issn = {00401706},
pmid = {14391346},
publisher = {Chapman and Hall/CRC},
title = {{Randomization, bootstrap and Monte Carlo methods in biology}},
url = {http://www.loc.gov/catdir/toc/fy0702/2006047407.html},
year = {2007}
}
@phdthesis{Proß2013a,
author = {Pro\ss, Sabrina},
file = {:home/tomaton/Downloads/Ver\"{o}ffentlichungsreihe-IuM-Pross(1).pdf:pdf},
title = {{Hybrid modeling and optimization of biological processes}},
url = {http://pub.uni-bielefeld.de/download/2562185/2562188},
year = {2013}
}
@inproceedings{Foster1998,
address = {New York, New York, USA},
author = {Foster, Ian and Kesselman, Carl and Tsudik, Gene and Tuecke, Steven},
booktitle = {Proceedings of the 5th ACM Conference on Computer and Communications Security - CCS '98},
doi = {10.1145/288090.288111},
file = {:home/tomaton/Downloads/p83-foster.pdf:pdf},
isbn = {1581130074},
month = nov,
pages = {83--92},
publisher = {ACM Press},
title = {{A Security Architecture for Computational Grids}},
year = {1998}
}
@misc{Tiller2014,
annote = {Web accessed: April 2014},
author = {Tiller, Michael},
title = {{Modelica by Example}},
url = {http://book.xogeny.com},
year = {2014}
}
@misc{Fric2007,
address = {Praha},
author = {Fri\v{c}, Marek},
file = {:home/tomaton/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Fri\v{c} - 2007 - Parametrizovan\'{y} fonetogram obecn\'{y}ch ře\v{c}ov\'{y}ch a hlasov\'{y}ch projevů - ParVRP.pdf:pdf},
publisher = {V\'{y}zkumn\'{e} centrum hudebn\'{\i} akustiky HAMU},
title = {{Parametrizovan\'{y} fonetogram obecn\'{y}ch ře\v{c}ov\'{y}ch a hlasov\'{y}ch projevů - ParVRP}},
url = {http://zvuk.hamu.cz/vyzkum/dokumenty/TL12x.pdf},
year = {2007}
}
@article{Kulhanek2013c,
author = {Kulh\'{a}nek, Tom\'{a}\v{s} and Je\v{z}ek, Filip and Matej\'{a}k, Marek and \v{S}ilar, Jan and Privitzer, Pavol and Tribula, Martin and Kofr\'{a}nek, Jiř\'{\i}},
doi = {10.11239/jsmbe.51.R-32},
file = {:home/tomaton/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Kulh\'{a}nek et al. - 2013 - RESTful web service to build loosely coupled web based simulation of human physiology a s.pdf:pdf},
journal = {Transactions of Japanese Society for Medical and Biological Engineering},
number = {Supplement},
pages = {R--32},
title = {{RESTful Web Service to Build Loosely Coupled Web Based Simulation of Human Physiology}},
volume = {51},
year = {2013}
}
@inproceedings{kofranek2013hummod,
author = {Kofr\'{a}nek, Jiř\'{\i} and Matej\'{a}k, Marek and Privitzer, Pavol and Tribula, Martin and Kulh\'{a}nek, Tom\'{a}\v{s} and \v{S}ilar, Jan and Pecinovsk\'{y}, Rudolf},
booktitle = {Proceedings of World Congress in Computer Science 2013 (WORLDCOMP'13), International Conference on Modeling, Simulation and Visualisation Methods (MSV'13)},
pages = {182--188},
title = {{HumMod-Golem Edition: Large Scale Model of Integrative Physiology for Virtual Patient Simulators}},
year = {2013}
}
@book{khoo2000,
author = {Khoo, Michael C K},
publisher = {IEEE press},
title = {{Physiological Control Systems}},
year = {2000}
}
@article{Skaburskas2008,
author = {Skaburskas, K and Estrella, F and Shade, J and Manset, D and Revillard, J and Rios, A and Anjum, A and Branson, A and Bloodsworth, P and Hauer, T and McClatchey, R and Rogulin, D},
doi = {10.1088/1742-6596/119/8/082011},
file = {:home/tomaton/Downloads/1742-6596\_119\_8\_082011.pdf:pdf},
isbn = {1742-6596},
issn = {17426588},
journal = {Journal of Physics: Conference Series},
pages = {082011},
title = {{Health-e-Child: A Grid Platform for European Paediatrics}},
volume = {119},
year = {2008}
}
@inproceedings{Anderson2004,
author = {Anderson, DP},
booktitle = {Grid Computing, 2004. Proceedings. Fifth IEEE/ACM International Workshop on},
doi = {10.1109/GRID.2004.14},
file = {:home/tomaton/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Anderson - 2004 - Boinc A system for public-resource computing and storage.pdf:pdf},
publisher = {IEEE},
title = {{Boinc: A System for Public-resource Computing and Storage}},
year = {2004}
}
@article{Hartmanis1965,
author = {Hartmanis, J and Stearns, RE},
file = {:home/tomaton/Downloads/HartmanisStearns1965.pdf:pdf},
journal = {Transactions of the American Mathematical \ldots},
pages = {285--306},
title = {{On the computational complexity of algorithms}},
url = {http://www.jstor.org/stable/1994208},
volume = {117},
year = {1965}
}
@incollection{zhao2014migrating,
author = {Zhao, Yong and Li, Youfu and Raicu, Ioan and Lin, Cui and Tian, Wenhong and Xue, Ruini},
booktitle = {Cloud Computing for Data-Intensive Applications},
pages = {231--256},
publisher = {Springer},
title = {{Migrating Scientific Workflow Management Systems from the Grid to the Cloud}},
year = {2014}
}
@article{Yu2005,
abstract = {With the advent of Grid and application technologies, scientists and engineers are building more and more complex applications to manage and process large data sets, and execute scientific experiments on distributed resources. Such application scenarios require means for composing and executing complex workflows. Therefore, many efforts have been made towards the development of workflow management systems for Grid computing. In this paper, we propose a taxonomy that characterizes and classifies various approaches for building and executing workflows on Grids. We also survey several representative Grid workflow systems developed by various projects world-wide to demonstrate the comprehensiveness of the taxonomy. The taxonomy not only highlights the design and engineering similarities and differences of state-of-the-art in Grid workflow systems, but also identifies the areas that need further research.},
archivePrefix = {arXiv},
arxivId = {cs/0503025},
author = {Yu, Jia and Buyya, Rajkumar},
doi = {10.1007/s10723-005-9010-8},
eprint = {0503025},
file = {:home/tomaton/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Yu, Buyya - 2005 - A Taxonomy of Workflow Management Systems for Grid Computing.pdf:pdf},
issn = {15707873},
keywords = {grid computing,scheduling,taxonomy,workflow management},
pages = {29},
primaryClass = {cs},
title = {{A Taxonomy of Workflow Management Systems for Grid Computing}},
url = {http://arxiv.org/abs/cs/0503025},
year = {2005}
}
@article{Memon2014,
author = {Memon, Shahbaz and Riedel, Morris and Janetzko, Florian and Demeler, Borries and Gorbet, Gary and Marru, Suresh and Grimshaw, Andrew and Gunathilake, Lahiru and Singh, Raminder and Attig, Norbert and Lippert, Thomas},
doi = {10.1002/cpe.3251},
file = {:home/tomaton/Downloads/cpe3251.pdf:pdf},
issn = {15320626},
journal = {Concurrency and Computation: Practice and Experience},
month = sep,
number = {13},
pages = {2280--2291},
title = {{Advancements of the UltraScan Scientific Gateway for Open Standards-based Cyberinfrastructures}},
volume = {26},
year = {2014}
}
@article{Slavicek2010,
abstract = {Masaryk University in Brno is operating a regional PACS archive serving to mostly all hospitals in Brno metropolis and a lot of remote medicine institutions. The communication between modalities (i.e. CT, ultrasound, X-ray, etc.) PACS archive and viewing stations is based on DICOM standard. This paper describes current state of the art of this medicine images storage system.},
author = {Slavicek, K. and Dostal, O. and Javornik, M. and Drdla, M.},
doi = {10.1109/WKDD.2010.133},
file = {:home/tomaton/Downloads/05432612.pdf:pdf},
isbn = {978-1-4244-5397-9},
journal = {2010 Third International Conference on Knowledge Discovery and Data Mining},
keywords = {-pacs,Biomedical imaging,Brno metropolis,DICOM,Data processing,Data security,Hospitals,MEDIMED,Masaryk University,Medical diagnostic imaging,Network servers,PACS,PACS archive,Picture archiving and communication systems,Ultrasonic imaging,X-ray imaging,dicom,medical image processing,medicine image data processing,medicine images storage system,regional centre,remote medicine institutions,visual databases},
month = jan,
pages = {310--313},
publisher = {Ieee},
shorttitle = {Knowledge Discovery and Data Mining, 2010. WKDD '1},
title = {{MEDIMED - Regional Centre for Medicine Image Data Processing}},
year = {2010}
}
@article{Montagnat2007,
author = {Montagnat, Johan and Frohner, \'{A}kos and Jouvenot, Daniel and Pera, Christophe and Kunszt, Peter and Koblitz, Birger and Santos, Nuno and Loomis, Charles and Texier, Romain and Lingrand, Diane and Guio, Patrick and {Brito Da Rocha}, Ricardo and {Sobreira de Almeida}, Antonio and Farkas, Zolt\'{a}n},
doi = {10.1007/s10723-007-9088-2},
file = {:home/tomaton/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Montagnat et al. - 2007 - A Secure Grid Medical Data Manager Interfaced to the gLite Middleware.pdf:pdf},
issn = {1570-7873},
journal = {Journal of Grid Computing},
month = jul,
number = {1},
pages = {45--59},
title = {{A Secure Grid Medical Data Manager Interfaced to the gLite Middleware}},
volume = {6},
year = {2007}
}
@inproceedings{Kulhanek2010Mefanet,
author = {Kulh\'{a}nek, Tom\'{a}\v{s} and \v{S}ilar, Jan and Kofr\'{a}nek, Jiř\'{\i} and Matej\'{a}k, Marek and Privitzer, Pavol and Tribula, Martin},
booktitle = {Mefanet 2010},
editor = {Schwarz, Daniel and Komenda, Martin and Majern\'{\i}k, Jaroslav and \v{S}t\'{\i}pek, Stanislav and Mih\'{a}l, Vladim\'{\i}r and Du\v{s}ek, Ladislav},
file = {:home/tomaton/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Kulh\'{a}nek et al. - 2010 - Od v\'{y}ukov\'{e}ho modelu k identifikaci fyziologick\'{e}ho syst\'{e}mu.pdf:pdf},
keywords = {desktop grid,grid,identification of physiological systems},
publisher = {MSD Brno},
title = {{Od v\'{y}ukov\'{e}ho modelu k identifikaci fyziologick\'{e}ho syst\'{e}mu}},
url = {http://www.mefanet.cz/res/file/mefanet2010/prispevky/kulhanek-full.pdf},
year = {2010}
}
@inproceedings{fritzson2006openmodelica,
author = {Fritzson, Peter and Aronsson, Peter and Pop, Adrian and Lundvall, Hakan and Nystrom, Kaj and Saldamli, Levon and Broman, David and Sandholm, Anders},
booktitle = {Computer Aided Control System Design, 2006 IEEE International Conference on Control Applications, 2006 IEEE International Symposium on Intelligent Control},
organization = {IEEE},
pages = {1588--1595},
title = {{OpenModelica-A free open-source environment for system modeling, simulation, and teaching}},
year = {2006}
}
@inproceedings{maffioletti2012computational,
author = {Maffioletti, Sergio and Murri, Riccardo and Jonen, B and Scheuring, S},
booktitle = {Proceedings of the EGI Community Forum},
file = {:home/tomaton/Downloads/EGICF12-EMITC2\_063.pdf:pdf},
title = {{Computational Workflows with GC3Pie}},
year = {2012}
}
@article{Abbass2012,
author = {Abbass, Mohamed a. and ElSamahy, Emad and Genedy, Ahmed},
doi = {10.1109/iCBEB.2012.62},
file = {:home/tomaton/Downloads/06245052.pdf:pdf},
isbn = {9780769547060},
journal = {Proceedings - 2012 International Conference on Biomedical Engineering and Biotechnology, iCBEB 2012},
keywords = {Luczak model,cardiovascular system,coefficient of determination,parameter estimation,pattern search method,sensitivity analysis},
pages = {45--48},
title = {{An Optimized Cardiovascular Model: A Pattern Search Approach}},
volume = {1},
year = {2012}
}
@book{Foster1995,
abstract = {From the Publisher: At last, a practitioner's guide to parallel programming! Students and professionals who use parallel or distributed computer systems will be able to solve real problems with Designing and Building Parallel Programs. This book provides a comprehensive introduction to parallel algorithm design, performance analysis, and program construction. It describes the tools needed to write parallel programs and provides numerous examples. A unique feature is the companion on-line version, accessible via the World Wide Web using browsers such as Mosaic. This provides a convenient hypertext version of the text with pointers to programming tools, example programs, and other resources on parallel and distributed computing.},
author = {Foster, Ian},
booktitle = {Interface},
file = {:home/tomaton/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Foster - 1995 - Designing and Building Parallel Programs.pdf:pdf},
isbn = {0201575949},
publisher = {Addison-Wesley Publishing Company},
title = {{Designing and Building Parallel Programs}},
year = {1995}
}
@article{Morley2007,
abstract = {OBJECTIVE: Current left ventricular assist devices are designed to provide full hemodynamic support for patients with end-stage failing hearts, but their use has been limited by operative risks, low reliability, and device-related morbidity. Such concerns have resulted in minimum use of left ventricular assist devices for destination therapy. We hypothesize that partial circulatory support, which could be achieved with small pumps implanted with less-invasive procedures, might expand the role of circulatory support devices for treatment of heart failure. METHODS: We examine the hemodynamic effects of partial left ventricular support using a previously described computational model of the cardiovascular system. Results from simulations were validated by comparison with an in vivo hemodynamic study. RESULTS: Simulations demonstrated that partial support (2-3 L/min) increased total cardiac output (left ventricular assist device output plus native heart output) by more than 1 L/min and decreased left ventricular end-diastolic pressure by 7 to 10 mm Hg with moderate-to-severe heart failure. Analyses showed that the hemodynamic benefits of increased cardiac output and decreased left ventricular end-diastolic pressure are greater in less-dilated and less-dysfunctional hearts. Both the relationships between ventricular assist device flow and cardiac output and ventricular assist device flow and left atrial pressure predicted by the model closely approximated the same relationships obtained during hemodynamic study in a bovine heart failure model. CONCLUSIONS: Results suggest that a pump with a flow rate of 2 to 3 L/min could meaningfully affect cardiac output and blood pressure in patients with advanced compensated heart failure. The development of small devices capable of high reliability and minimal complications that can be implanted with less-invasive techniques is supported by these findings.},
author = {Morley, Deborah and Litwak, Kenneth and Ferber, Paul and Spence, Paul and Dowling, Robert and Meyns, Bart and Griffith, Bartley and Burkhoff, Daniel},
doi = {10.1016/j.jtcvs.2006.07.037},
issn = {1097-685X},
journal = {The Journal of thoracic and cardiovascular surgery},
keywords = {Animals,Blood Pressure,Cardiac Output,Cardiovascular,Cardiovascular Physiological Phenomena,Cattle,Computer Simulation,Heart Failure,Heart Failure: physiopathology,Heart Failure: therapy,Heart-Assist Devices,Humans,Male,Models,Ventricular Pressure},
number = {1},
pages = {21--28},
pmid = {17198776},
title = {{Hemodynamic effects of partial ventricular support in chronic heart failure: results of simulation validated with in vivo data.}},
volume = {133},
year = {2007}
}
@book{Li2014,
address = {New York, NY},
doi = {10.1007/978-1-4939-1905-5},
editor = {Li, Xiaolin and Qiu, Judy},
isbn = {978-1-4939-1904-8},
publisher = {Springer New York},
title = {{Cloud Computing for Data-Intensive Applications}},
url = {http://link.springer.com/10.1007/978-1-4939-1905-5},
year = {2014}
}
@book{Eykhoff1981,
address = {Oxford},
annote = {Monograph},
author = {Eykhoff, P},
isbn = {008025683X},
keywords = {estimation,mathematical models,operationeel onderzoek,operations research,schatting,systeemanalyse,systems analysis,testen,testing,wiskundige modellen},
publisher = {Pergamon},
series = {IFAC series for graduates, research workers and practising engineers;vol. 1},
title = {{Trends and Progress in System Identification}},
year = {1981}
}
@article{Titze1992,
author = {Titze, Ingo R.},
doi = {10.1044/jshr.3501.21},
issn = {1092-4388},
journal = {Journal of Speech Language and Hearing Research},
number = {1},
pages = {21},
publisher = {American Speech-Language-Hearing Association},
title = {{Acoustic Interpretation of the Voice Range Profile (Phonetogram)}},
url = {http://jslhr.pubs.asha.org/article.aspx?articleid=1779116},
volume = {35},
year = {1992}
}
@article{Wu2014,
abstract = {Big Data concern large-volume, complex, growing data sets with multiple, autonomous sources. With the fast development of networking, data storage, and the data collection capacity, Big Data are now rapidly expanding in all science and engineering domains, including physical, biological and biomedical sciences. This paper presents a HACE theorem that characterizes the features of the Big Data revolution, and proposes a Big Data processing model, from the data mining perspective. This data-driven model involves demand-driven aggregation of information sources, mining and analysis, user interest modeling, and security and privacy considerations. We analyze the challenging issues in the data-driven model and also in the Big Data revolution.},
author = {Wu, Xindong and Zhu, Xingquan and Wu, Gong-Qing and Ding, Wei},
doi = {10.1109/TKDE.2013.109},
file = {:home/tomaton/Downloads/06547630.pdf:pdf},
isbn = {1041-4347},
issn = {1041-4347},
journal = {IEEE Transactions on Knowledge and Data Engineering},
keywords = {Big Data,Big Data processing model,Big Data revolution,HACE theorem,autonomous sources,complex and evolving associations,data collection capacity,data driven model,data mining,data storage,demand driven aggregation,growing data sets,heterogeneity,information sources,networking,user interest modeling,user modelling},
number = {1},
pages = {97--107},
title = {{Data mining with big data}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=6547630},
volume = {26},
year = {2014}
}
@article{novak2007deployment,
author = {Nov\'{a}k, V\'{a}clav and Vojt\v{e}ch, Josef},
journal = {Networking Studies},
pages = {27},
title = {{Deployment of a DWDM System with CLA Optical Amplifiers in the CESNET2 Network}},
year = {2007}
}
@article{Gunarathne2010,
abstract = {Cloud computing offers exciting new approaches for scientific computing that leverage major commercial players’ hardware and software investments in large-scale data centers. Loosely coupled problems are very important in many scientific fields, and with the ongoing move towards data-intensive computing, they are on the rise. There exist several different approaches to leveraging clouds and cloud-oriented data processing frameworks to perform pleasingly parallel (also called embarrassingly parallel) computations. In this paper, we present three pleasingly parallel biomedical applications: (i) assembly of genome fragments; (ii) sequence alignment and similarity search; and (iii) dimension reduction in the analysis of chemical structures, which are implemented utilizing a cloud infrastructure service-based utility computing models of Amazon Web Services (http://Amazon.com Inc., Seattle, WA, USA) and Microsoft Windows Azure (Microsoft Corp., Redmond, WA, USA) as well as utilizing MapReduce-based data processing frameworks Apache Hadoop (Apache Software Foundation, Los Angeles, CA, USA) and Microsoft DryadLINQ. We review and compare each of these frameworks, performing a comparative study among them based on performance, cost, and usability. High latency, eventually consistent cloud infrastructure service-based frameworks that rely on off-the-node cloud storage were able to exhibit performance efficiencies and scalability comparable to the MapReduce-based frameworks with local disk-based storage for the applications considered. In this paper, we also analyze variations in cost among the different platform choices (e.g., Elastic Compute Cloud instance types), highlighting the importance of selecting an appropriate platform based on the nature of the computation. Copyright © 2011 John Wiley \& Sons, Ltd.},
author = {Gunarathne, Thilina and Wu, Tak Lon and Choi, Jong Youl and Bae, Seung Hee and Qiu, Judy},
doi = {10.1002/cpe.1780},
file = {:home/tomaton/Downloads/cpe1780.pdf:pdf},
isbn = {9781605589428},
issn = {15320626},
journal = {Concurrency Computation Practice and Experience},
keywords = {bioinformatics,cloud technology,map reduce},
number = {June},
pages = {2338--2354},
title = {{Cloud computing paradigms for pleasingly parallel biomedical applications}},
volume = {23},
year = {2011}
}
@article{Smith2004,
author = {Smith, Bram W and Chase, J Geoffrey and Nokes, Roger I and Shaw, Geoffrey M and Wake, Graeme},
doi = {10.1016/j.medengphy.2003.10.001},
file = {:home/tomaton/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Smith et al. - 2004 - Minimal haemodynamic system model including ventricular interaction and valve dynamics.pdf:pdf},
issn = {1350-4533},
journal = {Medical engineering \& physics},
keywords = {Blood Flow Velocity,Blood Pressure,Blood Pressure: physiology,Cardiac Output,Cardiac Output: physiology,Cardiovascular,Cardiovascular Physiological Phenomena,Computer Simulation,Heart Valves,Heart Valves: physiology,Hemorheology,Hemorheology: methods,Humans,Models,Ventricular Function},
number = {2},
pages = {131--139},
pmid = {15036180},
title = {{Minimal haemodynamic system model including ventricular interaction and valve dynamics.}},
volume = {26},
year = {2004}
}
@inproceedings{Duque,
address = {Tokyo, Japan},
author = {Duque, H and Montagnat, J and Pierson, J and Brunie, L and Magnin, I E},
booktitle = {Biogrid'03 workshop},
file = {:home/tomaton/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Duque et al. - Unknown - DM 2 A Distributed Medical Data Manager for Grids ∗.pdf:pdf},
pages = {138--147},
title = {{DM 2 : A Distributed Medical Data Manager for Grids}}
}
@article{Erberich2006,
author = {Erberich, S. G. and Bhandekar, M. and Nelson, M. D. and Chervenak, A. and Kesselman, C.},
doi = {10.1007/s11548-006-0013-0},
file = {:home/tomaton/Downloads/CARS2006-LE445-DICOM\_Grid\_Interface-manuscript.pdf:pdf},
issn = {18616410},
journal = {International Journal of Computer Assisted Radiology and Surgery},
keywords = {DICOM,Data Grid,Globus Toolkit 4,Grid PACS,OGSA,PACS},
number = {ii},
pages = {100--102},
title = {{DICOM Grid Interface Service for Clinical and Research PACS: A Globus Toolkit Web Service for Medical Data Grids}},
volume = {1},
year = {2006}
}
@article{Bosin2011,
author = {Bosin, Andrea and Dess\`{\i}, Nicoletta and Pes, Barbara},
doi = {10.1016/j.future.2010.07.003},
file = {:home/tomaton/Downloads/1-s2.0-S0167739X10001251-main.pdf:pdf},
isbn = {0706758501},
issn = {0167739X},
journal = {Future Generation Computer Systems},
month = jan,
number = {1},
pages = {20--31},
publisher = {Elsevier B.V.},
title = {{Extending the SOA paradigm to e-Science environments}},
volume = {27},
year = {2011}
}
@article{Glatard2013,
abstract = {This paper presents the Virtual Imaging Platform (VIP), a platform accessible at http://vip.creatis.insa-lyon.fr to facilitate the sharing of object models and medical image simulators, and to provide access to distributed computing and storage resources. A complete overview is presented, describing the ontologies designed to share models in a common repository, the workflow template used to integrate simulators, and the tools and strategies used to exploit computing and storage resources. Simulation results obtained in four image modalities and with different models show that VIP is versatile and robust enough to support large simulations. The platform currently has 200 registered users who consumed 33 years of CPU time in 2011.},
author = {Glatard, Tristan and Lartizien, Carole and Gibaud, Bernard and {Da Silva}, Rafael Ferreira and Forestier, Germain and Cervenansky, Fr\'{e}d\'{e}ric and Alessandrini, Martino and Benoit-Cattin, Hugues and Bernard, Olivier and Camarasu-Pop, Sorina and Cerezo, Nadia and Clarysse, Patrick and Gaignard, Alban and Hugonnard, Patrick and Liebgott, Herv\'{e} and Marache, Simon and Marion, Adrien and Montagnat, Johan and Tabary, Joachim and Friboulet, Denis},
doi = {10.1109/TMI.2012.2220154},
file = {:home/tomaton/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Glatard et al. - 2013 - A virtual imaging platform for multi-modality medical image simulation.pdf:pdf},
isbn = {1558-254X (Electronic) 0278-0062 (Linking)},
issn = {02780062},
journal = {IEEE Transactions on Medical Imaging},
keywords = {Distributed computing infrastructures,medical image simulation,ontology,workflows},
number = {1},
pages = {110--118},
pmid = {23014715},
title = {{A virtual imaging platform for multi-modality medical image simulation}},
volume = {32},
year = {2013}
}
@article{Youseff2006,
author = {Youseff, Lamia and Wolski, Rich and Gorda, Brent and Krintz, Chandra},
doi = {10.1007/11942634\_49},
file = {:home/tomaton/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Youseff et al. - 2006 - Paravirtualization for HPC Systems(2).pdf:pdf},
journal = {Frontiers of High Performance Computing and Networking \^{a}€“ ISPA 2006 Workshops},
pages = {474--486},
title = {{Paravirtualization for HPC Systems}},
year = {2006}
}
@article{Takahashi2003,
abstract = {In this paper, we propose a high-performance parallel three-dimensional fast Fourier transform (FFT) algorithm on clusters of PCs. The three-dimensional FFT algorithm can be altered into a block three-dimensional FFT algorithm to reduce the number of cache misses. We show that the block three-dimensional FFT algorithm improves performance by utilizing the cache memory effectively. We use the block three-dimensional FFT algorithm to implement the parallel three-dimensional FFT algorithm. We succeeded in obtaining performance of over 1.3 GFLOPS on an 8-node dual Pentium III 1 GHz PC SMP cluster. ?? 2002 Elsevier Science B.V. All rights reserved.},
author = {Takahashi, Daisuke},
doi = {10.1016/S0010-4655(02)00818-4},
file = {:home/tomaton/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Takahashi - 2003 - Efficient implementation of parallel three-dimensional FFT on clusters of PCs.pdf:pdf},
issn = {00104655},
journal = {Computer Physics Communications},
keywords = {All-to-all communication,Cache memory,Clusters of PCs,Cyclic distribution,Fast Fourier transform},
pages = {144--150},
title = {{Efficient implementation of parallel three-dimensional FFT on clusters of PCs}},
volume = {152},
year = {2003}
}
@article{Belgacem2015,
author = {Belgacem, Mohamed Ben and Chopard, Bastien},
doi = {10.1016/j.future.2014.08.003},
file = {:home/tomaton/Downloads/1-s2.0-S0167739X14001514-main.pdf:pdf},
issn = {0167-739X},
journal = {Future Generation Computer Systems},
keywords = {distributed computation},
pages = {11--21},
publisher = {Elsevier B.V.},
title = {{A hybrid HPC/cloud distributed infrastructure: Coupling EC2 cloud resources with HPC clusters to run large tightly coupled multiscale applications}},
url = {http://dx.doi.org/10.1016/j.future.2014.08.003},
volume = {42},
year = {2015}
}
@article{matejakmedsoft2011,
author = {Matej\'{a}k, M and Kofr\'{a}nek, J},
journal = {sborn\'{\i}k př\'{\i}sp\v{e}vků Medsoft 2011},
title = {{Hummod - Golem edition - rozs\'{a}hl\'{y} model fyziologick\'{y}ch syst\'{e}mů}}
}
@article{DeLeoLeBorgne2002,
abstract = {Professional vocalists encounter demands requiring voluntary control of phonation, while utilizing a considerable range of frequency and intensity. These quantifiable acoustic events can be measured and represented in a phonetogram. Previous research has compared the phonetograms of trained and untrained voices and found significant differences between these groups. This study was designed to assess the effects of vocal training for singers over a period of nine months. Phonetogram contour changes were examined, with the primary focus on expansion of frequency range and/or intensity control. Twenty-one first-year, master's level, vocal music students, who were engaged in an intensive vocal performance curriculum, participated in this study. Following nine months of vocal training, significant differences were revealed in the subjects' mean frequency range and minimum vocal intensity across frequency levels. There was no significant difference for the mean maximum vocal intensity across frequency levels following vocal training.},
author = {{DeLeo LeBorgne}, Wendy and Weinrich, Barbara D.},
doi = {10.1016/S0892-1997(02)00070-X},
file = {:home/tomaton/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/DeLeo LeBorgne, Weinrich - 2002 - Phonetogram changes for trained singers over a nine-month period of vocal training.pdf:pdf},
isbn = {0892-1997 (Print)},
issn = {08921997},
journal = {Journal of Voice},
keywords = {Fundamental frequency/sound pressure level profile,Phonetogram,Vocal intensity,Vocal range profile (VRP),Vocal training},
number = {1},
pages = {37--43},
pmid = {12002885},
title = {{Phonetogram Changes for Trained Singers over a Nine-month Period of Vocal Training}},
volume = {16},
year = {2002}
}
@article{Cooling2008,
author = {Cooling, M T and Hunter, P and Crampin, E J},
doi = {10.1049/iet-syb},
journal = {Systems Biology, IET},
number = {April 2007},
pages = {73--79},
title = {{Modelling Biological Modularity with CellML}},
url = {http://ieeexplore.ieee.org/xpls/abs\_all.jsp?arnumber=4483541},
year = {2008}
}
@book{Fowler2003,
abstract = {The practice of enterprise application development has benefited from the emergence of many new enabling technologies. Multi-tiered object-oriented platforms, such as Java and .NET, have become commonplace. These new tools and technologies are capable of building powerful applications, but they are not easily implemented. Common failures in enterprise applications often occur because their developers do not understand the architectural lessons that experienced object developers have learned. Patterns of Enterprise Application Architecture is written in direct response to the stiff challenges that face enterprise application developers. The author, noted object-oriented designer Martin Fowler, noticed that despite changes in technology-from Smalltalk to CORBA to Java to .NET-the same basic design ideas can be adapted and applied to solve common problems. With the help of an expert group of contributors, Martin distills over forty recurring solutions into patterns. The result is an indispensable handbook of solutions that are applicable to any enterprise application platform. This book is actually two books in one. The first section is a short tutorial on developing enterprise applications, which you can read from start to finish to understand the scope of the book's lessons. The next section, the bulk of the book, is a detailed reference to the patterns themselves. Each pattern provides usage and implementation information, as well as detailed code examples in Java or C. The entire book is also richly illustrated with UML diagrams to further explain the concepts. Armed with this book, you will have the knowledge necessary to make important architectural decisions about building an enterprise application and the proven patterns for use when building them.},
author = {Fowler, Martin},
booktitle = {Trial},
isbn = {0321127420},
pages = {560},
publisher = {Pearson Education, Inc.},
title = {{Patterns of Enterprise Application Architecture}},
year = {2003}
}
@article{Guyton1972,
author = {Guyton, A C and Coleman, T G and Granger, H J},
doi = {10.1146/annurev.ph.34.030172.000305},
issn = {0066-4278},
journal = {Annual review of physiology},
keywords = {Aldosterone,Aldosterone: physiology,Angiotensin II,Angiotensin II: physiology,Biological,Blood Circulation,Blood Pressure,Body Fluids,Body Fluids: physiology,Cardiac Output,Heart Failure,Heart Failure: physiopathology,Homeostasis,Hypertension,Hypertension: physiopathology,Kidney,Kidney: physiology,Models,Natriuresis,Nephrosis,Nephrosis: physiopathology,Oxygen,Oxygen: blood,Physical Exertion,Pressoreceptors,Pressoreceptors: physiology,Reflex,Renal,Renal: physiopathology,Renin,Renin: physiology,Systems Analysis},
pages = {13--46},
pmid = {4334846},
title = {{Circulation: Overall Regulation.}},
volume = {34},
year = {1972}
}
@article{hunter2002,
author = {Hunter, Peter and Robbins, Peter and Noble, Denis},
journal = {European journal of physiology},
number = {1},
pages = {1--9},
publisher = {Springer},
title = {{The IUPS Human Physiome Project}},
volume = {445},
year = {2002}
}
@article{Livny1997,
abstract = {Little attention has been devoted to high throughput computing (HTC)$\backslash$nenvironments that can deliver large amounts of processing capacity$\backslash$nover long time periods. For almost a decade, we have been developing,$\backslash$nimplementing, and deploying, HTC tools that harness the capacity$\backslash$nof hundreds of distributively owned workstations. Using our software,$\backslash$nthe Condor HTC environment, scientists may simultaneously and transparently$\backslash$nexploit resources they are not even aware exist. We outline the architecture$\backslash$nof Condor and discuss the principles that have been guiding us and$\backslash$nthe lessons we have learned},
author = {Livny, Miron and Basney, Jim and Raman, Rajesh and Tannenbaum, Todd},
issn = {1421-6337},
journal = {SPEEDUP Journal},
pages = {36--40},
title = {{Mechanisms for High Throughput Computing}},
volume = {11},
year = {1997}
}
@inproceedings{Fedak2001,
author = {Fedak, Gilles and Cappello, Franck and Sud, Universitc Paris},
booktitle = {Proceedings of First IEEE/ACM International Symposium on Cluster Computing and the Grid},
doi = {10.1109/CCGRID.2001.923246},
file = {:home/tomaton/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Fedak, Cappello, Sud - 2001 - XtremWeb A Generic Global Computing System.pdf:pdf},
isbn = {0769510108},
pages = {582--587},
title = {{XtremWeb : A Generic Global Computing System}},
year = {2001}
}
@book{Mattson2004,
abstract = {The Parallel Programming Guide for Every Software Developer From grids and clusters to next-generation game consoles, parallel computing is going mainstream. Innovations such as Hyper-Threading Technology, HyperTransport Technology, and multicore microprocessors from IBM, Intel, and Sun are accelerating the movement's growth. Only one thing is missing: programmers with the skills to meet the soaring demand for parallel software. That's where Patterns for Parallel Programming comes in. It's the first parallel programming guide written specifically to serve working software developers, not just computer scientists. The authors introduce a complete, highly accessible pattern language that will help any experienced developer "think parallel"-and start writing effective parallel code almost immediately. Instead of formal theory, they deliver proven solutions to the challenges faced by parallel programmers, and pragmatic guidance for using today's parallel APIs in the real world. Coverage includes: Understanding the parallel computing landscape and the challenges faced by parallel developers Finding the concurrency in a software design problem and decomposing it into concurrent tasks Managing the use of data across tasks Creating an algorithm structure that effectively exploits the concurrency you've identified Connecting your algorithmic structures to the APIs needed to implement them Specific software constructs for implementing parallel programs Working with today's leading parallel programming environments: OpenMP, MPI, and Java Patterns have helped thousands of programmers master object-oriented development and other complex programming technologies. With this book, you will learn that they're the best way to master parallel programming too.},
author = {Mattson, Timothy G. and Sanders, Beverly A. and Massingill, Berna L.},
file = {:home/tomaton/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Unknown - Unknown - No Title(4).pdf:pdf},
isbn = {0321630033},
pages = {384},
publisher = {Pearson Education},
title = {{Patterns for Parallel Programming}},
volume = {5},
year = {2004}
}
@article{Bernstein2009,
abstract = {Cloud computing is a term applied to large, hosted datacenters, usually geographically distributed, which offer various computational services on a ldquoutilityrdquo basis. Most typically the configuration and provisioning of these datacenters, as far as the services for the subscribers go, is highly automated, to the point of the service being delivered within seconds of the subscriber request. Additionally, the datacenters typically use hypervisor based virtualization as a technique to deliver these services. The concept of a cloud operated by one service provider or enterprise interoperating with a clouds operated by another is a powerful idea. So far that is limited to use cases where code running on one cloud explicitly references a service on another cloud. There is no implicit and transparent interoperability. Use cases for interoperability, as well as work-in-progress around inter-cloud protocols and formats for enabling those use cases, are discussed in this paper.},
author = {Bernstein, David and Ludvigson, Erik and Sankar, Krishna and Diamond, Steve and Morrow, Monique},
doi = {10.1109/ICIW.2009.55},
file = {:home/tomaton/Downloads/05072540(1).pdf:pdf},
isbn = {9780769536132},
journal = {Proceedings of the 2009 4th International Conference on Internet and Web Applications and Services, ICIW 2009},
pages = {328--336},
title = {{Blueprint for the intercloud - Protocols and formats for cloud computing interoperability}},
year = {2009}
}
@article{Vinoski2007,
abstract = {This paper discusses the representational state transfer (REST) and service-oriented architecture (SOA) debate. The author tries to explain REST from the viewpoint of someone steeped in SOA, with the intention of helping SOA people understand the value the REST camp so rightfully touts},
author = {Vinoski, Steve},
doi = {10.1109/MIC.2007.22},
file = {:home/tomaton/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Vinoski - 2007 - REST eye for the SOA guy.pdf:pdf},
isbn = {1089-7801 VO - 11},
issn = {10897801},
journal = {IEEE Internet Computing},
keywords = {Representational State Transfer,Service-oriented architecture},
pages = {82--84},
title = {{REST Eye for the SOA Guy}},
volume = {11},
year = {2007}
}
@article{Chang2010,
abstract = {The Modeling Markup Language (MML) framework is a conceptual paradigm to quickly develop and solve biological models utilizing the CellML specification. In this study, we present the open source toolkit developed for this project and a possible workflow to create different scales of cardiac tissue models from a range of CellML models. Models from the CellML repository and other sources were tested for interoperability against the MML framework. Furthermore, to demonstrate the ability of the MML framework to deploy different scales of geometry, a model of atrial electrical activation is also presented.},
author = {Chang, David C. and Dokos, Socrates and Lovell, Nigel H.},
doi = {10.1109/IEMBS.2010.5626847},
file = {:home/tomaton/Downloads/05626847.pdf:pdf},
isbn = {9781424441235},
issn = {1557-170X},
journal = {2010 Annual International Conference of the IEEE Engineering in Medicine and Biology Society, EMBC'10},
keywords = {Algorithms and Tools for Physiome,Multiscale Modeling,Physiological Modeling},
pages = {1481--1484},
pmid = {21096362},
title = {{MML toolkit and work flow overview: Creating temporo-spatial heart models from CellML}},
year = {2010}
}
@book{Bankman2000,
booktitle = {Book},
editor = {Bankman, Issac N.},
file = {:home/tomaton/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Bankman - 2000 - Handbook of Medical Imaging.pdf:pdf},
isbn = {0120777908},
title = {{Handbook of Medical Imaging; Processing and Analysis}},
year = {2000}
}
@article{Camarasu-Pop2010,
abstract = {Medical imaging research deals with large, heterogeneous and fragmented amounts of medical images. The need for secure, federated and functional medical image databases is very strong within these research communities. This paper provides an overview of the different projects concerned with building medical image databases for medical imaging research. It also discusses the characteristics and requirements of this community and tries to determine to what extent existing solutions can answer these specific requirements.},
author = {Camarasu-Pop, Sorina and Cervenansky, Frederic and Cardenas, Yonny and Nief, Jean Yves and Benoit-Cattin, Hugues},
doi = {10.1109/CCGRID.2010.55},
file = {:home/tomaton/Downloads/05493396.pdf:pdf},
isbn = {9781424469871},
journal = {CCGrid 2010 - 10th IEEE/ACM International Conference on Cluster, Cloud, and Grid Computing},
pages = {739--744},
title = {{Overview of Medical Data Management Solutions for Research Communities}},
year = {2010}
}
@article{Saritas2013,
abstract = {Magnetic Particle Imaging (MPI) is a new tracer imaging modality that is gaining significant interest from NMR and MRI researchers. While the physics of MPI differ substantially from MRI, it employs hardware and imaging concepts that are familiar to MRI researchers, such as magnetic excitation and detection, pulse sequences, and relaxation effects. Furthermore, MPI employs the same superparamagnetic iron oxide (SPIO) contrast agents that are sometimes used for MR angiography and are often used for MRI cell tracking studies. These SPIOs are much safer for humans than iodine or gadolinium, especially for Chronic Kidney Disease (CKD) patients. The weak kidneys of CKD patients cannot safely excrete iodine or gadolinium, leading to increased morbidity and mortality after iodinated X-ray or CT angiograms, or after gadolinium-MRA studies. Iron oxides, on the other hand, are processed in the liver, and have been shown to be safe even for CKD patients. Unlike the "black blood" contrast generated by SPIOs in MRI due to increased T2 dephasing, SPIOs in MPI generate positive, "bright blood" contrast. With this ideal contrast, even prototype MPI scanners can already achieve fast, high-sensitivity, and high-contrast angiograms with millimeter-scale resolutions in phantoms and in animals. Moreover, MPI shows great potential for an exciting array of applications, including stem cell tracking in vivo, first-pass contrast studies to diagnose or stage cancer, and inflammation imaging in vivo. So far, only a handful of prototype small-animal MPI scanners have been constructed worldwide. Hence, MPI is open to great advances, especially in hardware, pulse sequence, and nanoparticle improvements, with the potential to revolutionize the biomedical imaging field. © 2012 Elsevier Inc. All rights reserved.},
author = {Saritas, Emine U. and Goodwill, Patrick W. and Croft, Laura R. and Konkle, Justin J. and Lu, Kuan and Zheng, Bo and Conolly, Steven M.},
doi = {10.1016/j.jmr.2012.11.029},
file = {:home/tomaton/Downloads/1-s2.0-S1090780712003734-main.pdf:pdf},
isbn = {10907807 (ISSN)},
issn = {10907807},
journal = {Journal of Magnetic Resonance},
keywords = {Angiography,MPI,Magnetic Particle Imaging,Magnetic nanoparticles,SPIO,Stem cell tracking,Superparamagnetic iron oxide},
pages = {116--126},
pmid = {23305842},
title = {{Magnetic particle imaging (MPI) for NMR and MRI researchers}},
url = {http://dx.doi.org/10.1016/j.jmr.2012.11.029},
volume = {229},
year = {2013}
}
@inproceedings{Kulhanek2014Parameters,
author = {Kulh\'{a}nek, Tom\'{a}\v{s} and Matej\'{a}k, Marek and \v{S}ilar, Jan and Kofr\'{a}nek, Jiř\'{\i}},
booktitle = {Biomedical and Health Informatics (BHI), 2014 IEEE-EMBS International Conference on},
doi = {10.1109/BHI.2014.6864463},
file = {:home/tomaton/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Kulhanek et al. - 2014 - Parameter estimation of complex mathematical models of human physiology using remote simulation distributed in.pdf:pdf},
isbn = {9781479921317},
keywords = {cloud computing,information services,parallel proc},
pages = {712--715},
title = {{Parameter Estimation of Complex Mathematical Models of Human Physiology Using Remote Simulation Distributed in Scientific Cloud}},
year = {2014}
}
@article{Gupta1993,
abstract = {Parallel computers have demonstrated a remarkable potential for achieving high performance at a reasonable cost for many computer vision and image processing (CVIP) applications. A major obstacle to the use of parallel computers is the lack of a universally accepted metric to study the scalability of parallel algorithms and architectures. The authors apply different scalability measures to various 2-D FFT algorithms and target architectures and compare the expected performance to the measured results. A number of algorithms in computer vision and image processing exhibit regular communication patterns similar to the 2-D FFT. The authors can therefore extrapolate the observations to determine which aspects of these measures are relevant to the scalability analysis of other similar image processing algorithms},
author = {Gupta, Anshul and Kumar, Vipin},
doi = {10.1109/CAMP.1993.622464},
file = {:home/tomaton/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Gupta, Kumar - 1993 - The Scalability of FFT on Parallel Computers.pdf:pdf},
isbn = {0-8186-5420-1},
journal = {IEEE Transactions on Parallel and Distributed Systems},
number = {8},
pages = {1--27},
title = {{The Scalability of FFT on Parallel Computers}},
volume = {4},
year = {1993}
}
@book{Sipser2012,
author = {Sipser, Michael},
file = {:home/tomaton/Downloads/Introduction\_to\_the\_theory\_of\_computation.pdf:pdf},
title = {{Introduction to the Theory of Computation}},
year = {2012}
}
@book{Levesque2010,
abstract = {High Performance Computing: Programming and Applications presents techniques that address new performance issues in the programming of high performance computing (HPC) applications. Omitting tedious details, the book discusses hardware architecture concepts and programming techniques that are the most pertinent to application developers for achieving high performance. Even though the text concentrates on C and Fortran, the techniques described can be applied to other languages, such as C++ and Java. Drawing on their experience with chips from AMD and systems, interconnects, and software from Cray Inc., the authors explore the problems that create bottlenecks in attaining good performance. They cover techniques that pertain to each of the three levels of parallelism: Message passing between the nodes Shared memory parallelism on the nodes or the multiple instruction, multiple data (MIMD) units on the accelerator Vectorization on the inner level After discussing architectural and software challenges, the book outlines a strategy for porting and optimizing an existing application to a large massively parallel processor (MPP) system. With a look toward the future, it also introduces the use of general purpose graphics processing units (GPGPUs) for carrying out HPC computations. A companion website at www.hybridmulticoreoptimization.com contains all the examples from the book, along with updated timing results on the latest released processors.},
author = {Levesque, John and Wagenbreth, Gene},
isbn = {1420077066},
pages = {244},
publisher = {CRC Press},
title = {{High Performance Computing: Programming and Applications}},
year = {2010}
}
@book{Meurs2011,
author = {van Meurs, W},
publisher = {McGraw-Hill Professional},
title = {{Modeling and Simulation in Biomedical Engineering: Applications in Cardiorespiratory Physiology}},
year = {2011}
}
@inproceedings{Cobham1964,
author = {Cobham, Alan},
booktitle = {Proc. 1964 Congress for Logic,Methodology and Philosophy of Science.},
pages = {24--30},
title = {{The Intrinsic Computational Difficulty of Functions}},
year = {1964}
}
@article{Kacsuk2008,
author = {Kacsuk, P. and Farkas, Z. and Fedak, G.},
doi = {10.1109/eScience.2008.111},
file = {:home/tomaton/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Kacsuk, Farkas, Fedak - 2008 - Towards Making BOINC and EGEE Interoperable.pdf:pdf},
isbn = {978-1-4244-3380-3},
journal = {2008 IEEE Fourth International Conference on eScience},
keywords = {BOINC,Desktop Grid,EGEE,Grid,Service Grid,XtremWeb},
month = dec,
pages = {478--484},
publisher = {Ieee},
title = {{Towards Making BOINC and EGEE Interoperable}},
year = {2008}
}
@book{Culer1998,
author = {Culer, David and Singh, Jaswinder Pal and Gupta, Anoop},
file = {:home/tomaton/Downloads/culler.pdf:pdf},
publisher = {Morgan Kaufmann},
title = {{Parallel Computer Architecture}},
year = {1998}
}
@article{Korf1985,
author = {Korf, Richard E},
file = {:home/tomaton/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Korf - 1985 - Depth -First Iterativ e-Deepening An Optimal Admissible Tree Search.pdf:pdf},
journal = {Artificial Intelligence},
pages = {97--109},
title = {{Depth-First Iterative-Deepening: An Optimal Admissible Tree Search}},
volume = {27},
year = {1985}
}
@article{Diaz2012,
abstract = {In this work, we present a survey of the different parallel programming models and tools available today with special consideration to their suitability for high-performance computing. Thus, we review the shared and distributed memory approaches, as well as the current heterogeneous parallel programming model. In addition, we analyze how the partitioned global address space (PGAS) and hybrid parallel programming models are used to combine the advantages of shared and distributed memory systems. The work is completed by considering languages with specific parallel support and the distributed programming paradigm. In all cases, we present characteristics, strengths, and weaknesses. The study shows that the availability of multi-core CPUs has given new impulse to the shared memory parallel programming approach. In addition, we find that hybrid parallel programming is the current way of harnessing the capabilities of computer clusters with multi-core nodes. On the other hand, heterogeneous programming is found to be an increasingly popular paradigm, as a consequence of the availability of multi-core CPUs+GPUs systems. The use of open industry standards like OpenMP, MPI, or OpenCL, as opposed to proprietary solutions, seems to be the way to uniformize and extend the use of parallel programming models.},
author = {Diaz, Javier and Mu\~{n}oz-Caro, Camelia and Ni\~{n}o, Alfonso},
doi = {10.1109/TPDS.2011.308},
file = {:home/tomaton/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Diaz, Mu\~{n}oz-Caro, Ni\~{n}o - 2012 - A survey of parallel programming models and tools in the multi and many-core era.pdf:pdf},
isbn = {1045-9219},
issn = {10459219},
journal = {IEEE Transactions on Parallel and Distributed Systems},
keywords = {Distributed programming,Heterogeneous (hybrid) systems,Parallelism and concurrency},
number = {8},
pages = {1369--1386},
title = {{A Survey of Parallel Programming Models and Tools in the Multi and Many-core Era}},
volume = {23},
year = {2012}
}
@inproceedings{Kulhanek2012,
author = {Kulh\'{a}nek, Tom\'{a}\v{s} and Fri\v{c}, Marek and Hrb, Jaroslav},
booktitle = {sborn\'{\i}k př\'{\i}sp\v{e}vků MEDSOFT},
file = {:home/tomaton/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Kulh\'{a}nek, Fri\v{c}, Hrb - 2012 - VZD\'{A}LEN\'{A} ANAL\'{Y}ZA LIDSK\'{E}HO HLASU V RE\'{A}LN\'{E}M \v{C}ASE .pdf:pdf},
pages = {180--184},
title = {{Vzd\'{a}len\'{a} anal\'{y}za lidsk\'{e}ho hlasu v re\'{a}ln\'{e}m \v{c}ase}},
url = {http://www.creativeconnections.cz/medsoft/2012/Medsoft\_Kulh\'{a}nek\_Tom\'{a}\v{s}.pdf},
year = {2012}
}
@inproceedings{Pierce2014,
abstract = {We present an overview of the Apache Airavata Application Programming Interface (API), describe the design choices and implementation details, and describe how API methods map to the UltraScan Science Gateway use case. The Airavata API is designed to standardize access to Airavata services that provide gateways with scientific application metadata and execution management. The API also represents an important milestone in the development of Science Gateway Platform as a Service (SciGaP), a hosted, multi-tenanted gateway service based on open source Airavata software. The UltraScan gateway is a production XSEDE gateway that has been using Airavata services for over three years through customized interfaces and represents a stringent test of the API design and implementation.},
author = {Pierce, Marlon and Marru, Suresh and Demeler, Borries and Singh, Raminderjeet and Gorbet, Gary},
booktitle = {2014 9th Gateway Computing Environments Workshop},
doi = {10.1109/GCE.2014.15},
file = {:home/tomaton/Downloads/p25-pierce.pdf:pdf},
isbn = {978-1-4799-7030-8},
keywords = {Catalogs,Communities,Data models,Educational institutions,Logic gates,Science gateways,Servers,Software,application programming interfac,application programming interface design,cloud computing,cyberinfrastructure},
month = nov,
pages = {25--29},
publisher = {IEEE},
shorttitle = {Gateway Computing Environments Workshop (GCE), 201},
title = {{The Apache Airavata Application Programming Interface: Overview and Evaluation with the UltraScan Science Gateway}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=7021845},
year = {2014}
}
@article{Kulhanek2014Modeling,
abstract = {This letter introduces an alternative approach to modeling the cardiovascular system with a short-term control mechanism published in Computers in Biology and Medicine, Vol. 47 (2014), pp. 104-112. We recommend using abstract components on a distinct physical level, separating the model into hydraulic components, subsystems of the cardiovascular system and individual subsystems of the control mechanism and scenario. We recommend utilizing an acausal modeling feature of Modelica language, which allows model variables to be expressed declaratively. Furthermore, the Modelica tool identifies which are the dependent and independent variables upon compilation. An example of our approach is introduced on several elementary components representing the hydraulic resistance to fluid flow and the elastic response of the vessel, among others. The introduced model implementation can be more reusable and understandable for the general scientific community.},
author = {Kulh\'{a}nek, Tom\'{a}\v{s} and Kofr\'{a}nek, Jiř\'{\i} and Matej\'{a}k, Marek},
doi = {10.1016/j.compbiomed.2014.08.025},
file = {:home/tomaton/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Kulh\'{a}nek, Kofr\'{a}nek, Matej\'{a}k - 2014 - Modeling of short-term mechanism of arterial pressure control in the cardiovascular system Objec.pdf:pdf},
issn = {1879-0534},
journal = {Computers in Biology and Medicine},
month = sep,
pages = {137--144},
pmid = {25240104},
title = {{Modeling of Short-term Mechanism of Arterial Pressure Control in the Cardiovascular System: Object-oriented and Acausal Approach.}},
volume = {54},
year = {2014}
}
@article{Kofranek2011d,
author = {Kofr\'{a}nek, Jiř\'{\i} and Matej\'{a}k, Marek and Privitzer, Pavol},
file = {:home/tomaton/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Kofr\'{a}nek, Matej\'{a}k, Privitzer - 2011 - Complex Model of Integrated Physiological System - A Theoretical Basis For Medical Training Simu.pdf:pdf},
isbn = {9788021055391},
journal = {Mefanet Report 04},
pages = {32--59},
title = {{Complex Model of Integrated Physiological System - A Theoretical Basis For Medical Training Simulators}},
url = {http://www.mefanet.cz/res/file/reporty/mefanet-report-2011.pdf},
year = {2011}
}
@misc{Fric2012,
address = {Praha},
author = {Fri\v{c}, Marek and Kulh\'{a}nek, Tom\'{a}\v{s} and Hrb, Jaroslav},
file = {:home/tomaton/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Fri\v{c}, Kulh\'{a}nek, Hrb - 2012 - Syst\'{e}m pro vzd\'{a}len\v{e} př\'{\i}stupnou anal\'{y}zu hlasu RealVoiceLab.pdf:pdf},
publisher = {V\'{y}zkumn\'{e} centrum hudebn\'{\i} akustiky HAMU},
title = {{Syst\'{e}m pro vzd\'{a}len\v{e} př\'{\i}stupnou anal\'{y}zu hlasu RealVoiceLab}},
url = {http://zvuk.hamu.cz/vyzkum/dokumenty/TL46x.pdf},
year = {2012}
}
@inproceedings{Matejak2014,
author = {Matej\'{a}k, Marek and Kulh\'{a}nek, Tom\'{a}\v{s} and \v{S}ilar, Jan and Privitzer, Pavol and Je\v{z}ek, Filip and Kofr\'{a}nek, Jiř\'{\i}},
booktitle = {Proceedings of the 10th International Modelica Conference, March 10-12, 2014, Lund, Sweden},
doi = {10.3384/ecp14096499},
file = {:home/tomaton/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Matej\'{a}k et al. - 2014 - Physiolibrary - Modelica library for Physiology.pdf:pdf},
keywords = {HumMod,Integrative physiology,Modelica library,Physiolibrary,Physiology,System biology},
pages = {499--505},
publisher = {Link\"{o}ping University Electronic Press},
title = {{Physiolibrary - Modelica Library for Physiology}},
year = {2014}
}
@article{Pasley2005,
abstract = {As the use of Web services grows, organizations are increasingly choosing the Business Process Execution Language for modeling business processes within the Web services architecture. In addition to orchestrating organizations' Web services, BPEL's strengths include asynchronous message handling, reliability, and recovery. By developing Web services with BPEL in mind, organizations can implement aspects of the service-oriented architecture that might previously have been difficult to achieve.},
author = {Pasley, James},
doi = {10.1109/MIC.2005.56},
file = {:home/tomaton/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Pasley - 2005 - How BPEL and SOA are changing web services development.pdf:pdf},
isbn = {1089-7801},
issn = {10897801},
journal = {IEEE Internet Computing},
number = {June},
pages = {60--67},
title = {{How BPEL and SOA Are Changing Web Services Development}},
volume = {9},
year = {2005}
}
@article{Mell2011,
author = {Mell, Peter and Grance, Timothy},
file = {:home/tomaton/Downloads/SP800-145.pdf:pdf},
title = {{The NIST Definition of Cloud Computing}},
url = {http://csrc.nist.gov/publications/nistpubs/800-145/SP800-145.pdf},
year = {2011}
}
@article{Plankensteiner2013,
abstract = {Today there exist a wide variety of scientific workflow management systems, each designed to fulfill the needs of a certain scientific community. Unfortunately, once a workflow application has been designed in one particular system it becomes very hard to share it with users working with different systems. Portability of workflows and interoperability between current systems barely exists. In this work, we present the fine-grained interoperability solution proposed in the SHIWA European project that brings together four representative European workflow systems: ASKALON, MOTEUR, WS-PGRADE, and Triana. The proposed interoperability is realised at two levels of abstraction: abstract and concrete. At the abstract level, we propose a generic Interoperable Workflow Intermediate Representation (IWIR) that can be used as a common bridge for translating workflows between different languages independent of the underlying distributed computing infrastructure. At the concrete level, we propose a bundling technique that aggregates the abstract IWIR representation and concrete task representations to enable workflow instantiation, execution and scheduling. We illustrate case studies using two real-workflow applications designed in a native environment and then translated and executed by a foreign workflow system in a foreign distributed computing infrastructure.},
author = {Plankensteiner, Kassian and Prodan, Radu and Janetschek, Matthias and Fahringer, Thomas and Montagnat, Johan and Rogers, David and Harvey, Ian and Taylor, Ian and Balask\'{o}, \'{A}kos and Kacsuk, P\'{e}ter},
doi = {10.1007/s10723-013-9261-8},
file = {:home/tomaton/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Plankensteiner et al. - 2013 - Fine-Grain Interoperability of Scientific Workflows in Distributed Computing Infrastructures.pdf:pdf},
issn = {15707873},
journal = {Journal of Grid Computing},
keywords = {Distributed computing,Grid computing,Intermediate representation,Interoperability,Portability,Scientific workflow},
pages = {429--455},
title = {{Fine-Grain Interoperability of Scientific Workflows in Distributed Computing Infrastructures}},
volume = {11},
year = {2013}
}
@article{Raicu2010,
abstract = {Many-task computing aims to bridge the gap between two computing paradigms, high throughput computing and high performance computing. Many-task computing denotes high-performance computations comprising multiple distinct activities, coupled via file system operations. The aggregate number of tasks, quantity of computing, and volumes of data may be extremely large. Traditional techniques found in production systems in the scientific community to support many-task computing do not scale to today's largest systems, due to issues in local resource manager scalability and granularity, efficient utilization of the raw hardware, long wait queue times, and shared/parallel file system contention and scalability. To address these limitations, we adopted a "top-down" approach to building a middleware called Falkon, to support the most demanding many-task computing applications at the largest scales. Falkon (Fast and Light-weight tasK executiON framework) integrates (1) multi-level scheduling to enable dynamic resource provisioning and minimize wait queue times, (2) a streamlined task dispatcher able to achieve orders-of-magnitude higher task dispatch rates than conventional schedulers, and (3) data diffusion which performs data caching and uses a data-aware scheduler to co-locate computational and storage resources. Micro-benchmarks have shown Falkon to achieve over 15K+ tasks/s throughputs, scale to hundreds of thousands of processors and to millions of queued tasks, and execute billions of tasks per day. Data diffusion has also shown to improve applications scalability and performance, with its ability to achieve hundreds of Gb/s I/O rates on modest sized clusters, with Tb/s I/O rates on the horizon. Falkon has shown orders of magnitude improvements in performance and scalability than traditional approaches to resource management across many diverse workloads and applications at scales of billions of tasks on hundreds of thousands of processors across clusters, specialized systems, Grids, and supercomputers. Falkon's performance and scalability have enabled a new class of applications called Many-Task Computing to operate at previously so-believed impossible scales with high efficiency. © 2010 Springer Science+Business Media, LLC.},
author = {Raicu, Ioan and Foster, Ian and Wilde, Mike and Zhang, Zhao and Iskra, Kamil and Beckman, Peter and Zhao, Yong and Szalay, Alex and Choudhary, Alok and Little, Philip and Moretti, Christopher and Chaudhary, Amitabh and Thain, Douglas},
doi = {10.1007/s10586-010-0132-9},
isbn = {1386785715737543},
issn = {13867857},
journal = {Cluster Computing},
keywords = {Computing,Data-intensive distributed computing,Falkon,High-performance computing,High-throughput,Loosely-coupled applications,Many-task computing,Petascale,Swift},
pages = {291--314},
title = {{Middleware Support for Many-task Computing}},
volume = {13},
year = {2010}
}
@article{Kacsuk2011,
abstract = {P-GRADE portal is one of the most widely used general-purpose grid portal in Europe. The paper summarizes the most advanced features of P-GRADE, such as parameter sweep workflow execution, multi-grid workflow execution and integration with the DSpace workflow repository. It also shows the NGS P-GRADE portal that extends P-GRADE with the GEMLCA legacy code execution support in Grid systems, as well as with coarse-grain workflow interoperability services. Next, the paper introduces the second generation P-GRADE portal called WS-PGRADE that merges the advanced features of the first generation P-GRADE portals and extends them with new workflow and architecture concepts. Finally, the application-specific science gateway of the CancerGrid project is briefly described to demonstrate that application-specific portals can easily be developed on top of the general-purpose WS-PGRADE portal.},
author = {Kacsuk, Peter},
doi = {10.1002/cpe.1654},
file = {:home/tomaton/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Kacsuk - 2011 - P-GRADE portal family for grid infrastructures.pdf:pdf},
issn = {15320626},
journal = {Concurrency Computation Practice and Experience},
keywords = {grid,interoperability,portal,portal framework,repository,science gateway,workflow},
pages = {235--245},
title = {{P-GRADE Portal Family for Grid Infrastructures}},
volume = {23},
year = {2011}
}
@article{Ross2010,
abstract = {Teleradiology aims to even radiologists' workload, ensure on-call services, reduce waiting lists, consult other specialists and cut costs. Cross-border teleradiology widens this scope beyond the country borders. However, the new service should not reduce the quality of radiology. Quality and trust are key factors in establishment of teleradiology. Additionally there are organizational, technical, legal, security and linguistic issues influencing the service. Herein, we have used experiences from two partially European Union funded telemedicine projects to evaluate factors affecting cross-border teleradiology. Clinical partners from Czech Republic, Denmark, Estonia, Finland, Lithuania and the Netherlands went through 649 radiology test cases in two different teleradiology projects to build trust and agree about the report structure. Technical set-up was established using secure Internet data transfer, streaming technology, integration of workflows and creating structured reporting tool to overcome language barriers. The biggest barrier to overcome in cross-border teleradiology was the language issue. Establishment of the service was technically and semantically successful but limited to knee and hip X-ray examinations only because the structured reporting tool did not cover any other anatomical regions yet. Special attention has to be paid to clinical quality and trust between partners in cross-border teleradiology. Our experience shows that it is achievable. Legal, security and financial aspects are not covered in this paper because today they differ country by country. There is however an European Union level harmonization process started to enable cross-border eHealth in general.},
author = {Ross, Peeter and Sepper, Ruth and Pohjonen, Hanna},
doi = {10.1016/j.ejrad.2009.10.016},
file = {:home/tomaton/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Ross, Sepper, Pohjonen - 2010 - Cross-border teleradiology-experience from two international teleradiology projects.pdf:pdf},
issn = {1872-7727},
journal = {European journal of radiology},
keywords = {Europe,Interinstitutional Relations,Internationality,Internet,Internet: trends,Medical Informatics,Medical Informatics: trends,Radiology Information Systems,Radiology Information Systems: trends,Telemedicine,Telemedicine: trends},
month = jan,
number = {1},
pages = {20--5},
pmid = {19914019},
title = {{Cross-border Teleradiology -- Experience from Two International Teleradiology Projects.}},
volume = {73},
year = {2010}
}
@article{kulhanek2010b,
author = {Kulh\'{a}nek, Tom\'{a}\v{s} and Fri\v{c}, Marek and \v{S}\'{a}rek, Milan},
file = {:home/tomaton/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Kulh\'{a}nek, Fri\v{c}, \v{S}\'{a}rek - 2010 - Remote Analysis of Human Voice--Lossless Sound Recording Redirection.pdf:pdf},
journal = {Analysis of Biomedical Signals and Images. Proceedings of 20th International EURASIP Conference (BIOSIGNAL)},
pages = {394--397},
title = {{Remote Analysis of Human Voice -- Lossless Sound Recording Redirection}},
url = {http://bs2010.biosignal.cz/papers/1092.pdf},
year = {2010}
}
@article{Frey2001,
abstract = {In recent years, there has been a dramatic increase in the amount
of available computing and storage resources, yet few have been able to
exploit these resources in an aggregated form. We present the Condor-G
system, which leverages software from Globus and Condor to allow users
to harness multi-domain resources as if they all belong to one personal
domain. We describe the structure of Condor-G and how it handles job
management, resource selection, security and fault tolerance},
author = {Frey, J. and Tannenbaum, T. and Livny, M. and Foster, I. and Tuecke, S.},
doi = {10.1109/HPDC.2001.945176},
isbn = {0-7695-1296-8},
issn = {1082-8907},
journal = {Proceedings 10th IEEE International Symposium on High Performance Distributed Computing},
title = {{Condor-G: a computation management agent for multi-institutional
grids}},
year = {2001}
}
@inproceedings{Kulhanek2010d,
author = {Kulh\'{a}nek, Tom\'{a}\v{s} and Fri\v{c}, Marek and \v{S}\'{a}rek, Milan},
booktitle = {sborn\'{\i}k př\'{\i}sp\v{e}vků MEDSOFT},
file = {:home/tomaton/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Kulh\'{a}nek, Fri\v{s}, \v{S}\'{a}rek - 2010 - VZD\'{A}LEN\'{A} ANAL\'{Y}ZA LIDSK\'{E}HO HLASU - BEZEZTR\'{A}TOV\'{E} NAHR\'{A}-.pdf:pdf},
pages = {96--101},
title = {{Vzd\'{a}len\'{a} anal\'{y}za lidsk\'{e}ho hlasu - bezeztr\'{a}tov\'{e} nahr\'{a}v\'{a}n\'{\i} zvuku přes ip s\'{\i}t\v{e}}},
year = {2010}
}
@article{Curcin2008,
abstract = {The past decade has witnessed a growing trend in designing and using workflow systems with a focus on supporting the scientific research process in bioinformatics and other areas of life sciences. The aim of these systems is mainly to simplify access, control and orchestration of remote distributed scientific data sets using remote computational resources, such as EBI web services. In this paper we present the state of the art in the field by reviewing six such systems: Discovery Net, Taverna, Triana, Kepler, Yawl and BPEL. We provide a high-level framework for comparing the systems based on their control flow and data flow properties with a view of both informing future research in the area by academic researchers and facilitating the selection of the most appropriate system for a specific application task by practitioners.},
author = {Curcin, V. and Ghanem, M.},
doi = {10.1109/CIBEC.2008.4786077},
file = {:home/tomaton/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Curcin, Ghanem - 2008 - Scientific workflow systems - can one size fit all.pdf:pdf},
isbn = {978-1-4244-2694-2},
journal = {2008 Cairo International Biomedical Engineering Conference},
title = {{Scientific Workflow Systems - Can One Size Fit All?}},
year = {2008}
}
@article{Gleich2005,
abstract = {The use of contrast agents and tracers in medical imaging has a long history. They provide important information for diagnosis and therapy, but for some desired applications, a higher resolution is required than can be obtained using the currently available medical imaging techniques. Consider, for example, the use of magnetic tracers in magnetic resonance imaging: detection thresholds for in vitro and in vivo imaging are such that the background signal from the host tissue is a crucial limiting factor. A sensitive method for detecting the magnetic particles directly is to measure their magnetic fields using relaxometry; but this approach has the drawback that the inverse problem (associated with transforming the data into a spatial image) is ill posed and therefore yields low spatial resolution. Here we present a method for obtaining a high-resolution image of such tracers that takes advantage of the nonlinear magnetization curve of small magnetic particles. Initial 'phantom' experiments are reported that demonstrate the feasibility of the imaging method. The resolution that we achieve is already well below 1 mm. We evaluate the prospects for further improvement, and show that the method has the potential to be developed into an imaging method characterized by both high spatial resolution as well as high sensitivity.},
author = {Gleich, Bernhard and Weizenecker, J\"{u}rgen},
doi = {10.1038/nature03808},
issn = {1476-4687},
journal = {Nature},
keywords = {Contrast Media,Contrast Media: chemistry,Magnetic Resonance Imaging,Magnetic Resonance Imaging: instrumentation,Magnetic Resonance Imaging: methods,Magnetics,Magnetics: diagnostic use,Phantoms, Imaging,Sensitivity and Specificity,Tomography,Tomography: instrumentation,Tomography: methods},
language = {en},
month = jun,
number = {7046},
pages = {1214--7},
pmid = {15988521},
publisher = {Nature Publishing Group},
title = {{Tomographic imaging using the nonlinear response of magnetic particles.}},
url = {http://www.nature.com.ezproxy.techlib.cz/nature/journal/v435/n7046/full/nature03808.html},
volume = {435},
year = {2005}
}
@book{foster2004,
author = {Foster, Ian and Kesselman, Carl},
publisher = {Morgan Kaufmann},
title = {{The Grid 2: Blueprint for a New Computing Infrastructure}},
year = {2004}
}
@article{Brunberg2009,
author = {Brunberg, A and Abel, D and Autschbach, R},
journal = {4th European Conference of the International Federation for Medical and Biological Engineering IFMBE Proceedings},
keywords = {a,cardiovascular system,ii,m aterials and methods,model requirements,modeling,physiological control loops,simulation},
pages = {2600--2603},
title = {{An Object-oriented Model of the Cardiovascular System with a Focus on Physiological Control Loops}},
volume = {22},
year = {2009}
}
@book{Hohpe2002,
author = {Hohpe, Gregor and Woolf, Bobby},
file = {:home/tomaton/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Hohpe - 2002 - Enterprise Integration Patterns.pdf:pdf},
publisher = {Pearson Education, Inc.},
title = {{Enterprise Integration Patterns}},
year = {2002}
}
@inproceedings{Kofranek2011hummod,
author = {Kofr\'{a}nek, Jiř\'{\i} and Matej\'{a}k, Marek and Privitzer, Pavol},
booktitle = {Proceedings 8th Modelica Conference, Dresden, Germany},
pages = {713--724},
title = {{Hummod -- Large Scale Physiological Models in Modelica}},
year = {2011}
}
@article{Hunter2004,
abstract = {The IUPS Physiome Project is an internationally collaborative open-source project to provide a public domain framework for computational physiology, including the development of modelling standards, computational tools and web-accessible databases of models of structure and function at all spatial scales. A number of papers in this volume deal with the development of specific mathematical models of physiological processes. This paper stands back from the detail of individual models and reviews the current state of the IUPS Physiome Project including organ and organ system continuum models, the interpretation of constitutive law parameters in terms of micro-structural models, and markup languages for standardizing cellular processes. Some current practical applications of the physiome models are given and some of the challenges for the next 5 years of the Physiome Project at the level of organs, cells and proteins are proposed.},
author = {Hunter, P J},
doi = {10.1016/j.pbiomolbio.2004.02.006},
issn = {0079-6107},
journal = {Progress in biophysics and molecular biology},
keywords = {Biological,Cell Physiological Phenomena,Computational Biology,Computational Biology: methods,Computational Biology: organization \& administrati,Computer Simulation,Database Management Systems,Information Storage and Retrieval,International Cooperation,Models,Research,Research Design,Research: organization \& administration,Systems Integration,Viscera,Viscera: physiology},
month = jan,
number = {2-3},
pages = {551--69},
pmid = {15142761},
title = {{The IUPS Physiome Project: A Framework for Computational Physiology}},
volume = {85},
year = {2004}
}
@misc{Modelica,
title = {{Modelica and the Modelica Association}},
url = {http://www.modelica.org}
}
@article{Anjum,
author = {Anjum, Ashiq and Bloodsworth, Peter and Branson, Andrew and Hauer, Tam\'{a}s and Munir, Kamran and Rogulin, Dmitry and Shamdasani, Jetendr and Lane, Coldharbour and Bs, Bristol and Anjum, Email Ashiq and Hauer, Tamas and Mcclatchey, Richard},
file = {:home/tomaton/Downloads/0707.0763v1.pdf:pdf},
keywords = {biomedical application,data modelling,ontologies,user requirements},
title = {{The Requirements for Ontologies in Medical Data Integration : A Case Study}}
}
@article{Matejak2014sj,
author = {Matej\'{a}k, Marek and Kulh\'{a}nek, Tom\'{a}\v{s} and Matou\v{s}ek, Stanislav},
doi = {10.3109/00365513.2014.984320},
file = {:home/tomaton/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Matej\'{a}k, Kulh\'{a}nek, Matou\v{s}ek - 2014 - Adair-Based Hemoglobin Equilibrium with Oxygen, Carbon Dioxide and Hydrogen Ion Activity.pdf:pdf},
journal = {Scandinavian Journal of Clinical \& Laboratory Investigation},
keywords = {acid-base equilibrium,blood gas analysis,carboxyhemoglobin,hemoglobin a},
title = {{Adair-based Hemoglobin Equilibrium with Oxygen, Carbon Dioxide and Hydrogen Ion Activity}},
year = {2014}
}
@inproceedings{Jezek2012,
author = {Je\v{z}ek, Filip and Kro\v{c}ek, Tom\'{a}\v{s} and Matej\'{a}k, Marek and Kofr\'{a}nek, Jiř\'{\i}},
booktitle = {sborn\'{\i}k př\'{\i}sp\v{e}vků MEDSOFT},
file = {:home/tomaton/Downloads/Medsoft\_Je\v{z}ek\_Filip.pdf:pdf},
pages = {139--146},
title = {{Zku\v{s}enosti z inovace v\'{y}uky Modelov\'{a}n\'{\i} a Simulace na FEL \v{C}VUT}},
year = {2012}
}
@book{fritzson2010,
author = {Fritzson, Peter},
publisher = {Wiley. com},
title = {{Principles of object-oriented modeling and simulation with Modelica 2.1}},
year = {2010}
}
@article{Goodwin2004,
abstract = {Full-body patient simulators provide the technology and the environment necessary for excellent clinical education while eliminating risk to the patient. The extension of simulator-based training into management of basic and critical situations in complex patient populations is natural. We describe the derivation of an infant cardiovascular model through the redefinition of a complete set of parameters for an existing adult model. Specifically, we document a stepwise parameter estimation process, explicit simplifying assumptions, and sources for these parameters. The simulated vital signs are within the target hemodynamic variables, and the simulated systemic arterial pressure wave form and left ventricular pressure volume loop are realistic. The system reacts appropriately to blood loss, and incorporation of aortic stenosis is straightforward. This infant cardiovascular model can form the basis for screen-based educational simulations. The model is also an essential step in attaining a full-body, model-driven infant simulator.},
author = {Goodwin, Jane A and van Meurs, Willem L and {S\'{a} Couto}, Carla D and Beneken, Jan E W and Graves, Shirley A},
doi = {10.1213/01.ANE.0000134797.52793.AF},
institution = {Nemours Children's Clinic-Jacksonville, 807 Children's Way, Jacksonville, FL 32207, USA. jgoodwin@nemours.org},
isbn = {0003-2999},
issn = {0003-2999},
journal = {Anesthesia and analgesia},
number = {6},
pages = {1655--1664},
pmid = {15562049},
title = {{A model for educational simulation of infant cardiovascular physiology.}},
volume = {99},
year = {2004}
}
@book{Hall2010a,
abstract = {The 12th edition of Guyton and Hall Textbook of Medical Physiology continues this bestselling title's long tradition as one of the world's favorite physiology textbooks. The immense success of this book is due to its description of complex physiologic principles in language that is easy to read and understand. Now with an improved color art program, thorough updates reflecting today's medicine and science, and accessible online at studentconsult.com, this textbook is an excellent source for mastering essential human physiology knowledge. Learn and remember vital concepts easily thanks to short, easy-to-read, masterfully edited chapters and a user-friendly full-color design. See core concepts applied to real-life situations with clinical vignettes throughout the text. Discover the newest in physiology with updates that reflect the latest advances in molecular biology, cardiovascular, neurophysiology and gastrointestinal topics. Visualize physiologic principles clearly with over 1000 bold, full-color drawings and diagrams. Distinguish core concepts from more in-depth material with a layout that uses gray shading to clearly differentiate between "need-to-know" and "nice-to-know" information. Access the complete contents online at studentconsult.com along with bonus resources such as image banks, self-assessment questions, physiology animations and more! This new edition continues the long tradition of "Guyton" as one of the world's favorite physiology textbooks},
author = {Hall, John E},
booktitle = {Physiology},
isbn = {0721602401},
pages = {1091},
pmid = {15882912},
title = {{Guyton and Hall Textbook of Medical Physiology}},
year = {2010}
}
@article{PlanckCollaboration2013,
abstract = {The ESA's Planck satellite, dedicated to studying the early universe, was launched on May 2009 and has been surveying the microwave and submillimetre sky since August 2009. In March 2013, ESA and the Planck Collaboration publicly released the initial cosmology products based on the first 15.5 months of Planck operations, along with a set of scientific and technical papers and a web-based explanatory supplement. This paper describes the mission and its performance, and gives an overview of the processing and analysis of the data, the characteristics of the data, the main scientific results, and the science data products and papers in the release. Scientific results include robust support for the standard, six parameter LCDM model of cosmology and improved measurements for the parameters that define this model, including a highly significant deviation from scale invariance of the primordial power spectrum. The Planck values for some of these parameters and others derived from them are significantly different from those previously determined. Several large scale anomalies in the CMB temperature distribution detected earlier by WMAP are confirmed with higher confidence. Planck sets new limits on the number and mass of neutrinos, and has measured gravitational lensing of CMB anisotropies at 25 sigma. Planck finds no evidence for non-Gaussian statistics of the CMB anisotropies. There is some tension between Planck and WMAP results; this is evident in the power spectrum and results for some of the cosmology parameters. In general, Planck results agree well with results from the measurements of baryon acoustic oscillations. Because the analysis of Planck polarization data is not yet as mature as the analysis of temperature data, polarization results are not released. We do, however, illustrate the robust detection of the E-mode polarization signal around CMB hot- and cold-spots.},
archivePrefix = {arXiv},
arxivId = {1303.5062},
author = {{Planck Collaboration} and Ade, P. a. R. and Aghanim, N. and Armitage-Caplan, C. and Arnaud, M. and Ashdown, M. and Atrio-Barandela, F. and Aumont, J. and Baccigalupi, C. and Banday, a. J. and Barreiro, R. B. and Bartelmann, M. and Bartlett, J. G. and Battaner, E. and Benabed, K. and Beno\^{\i}t, A. and Benoit-L\'{e}vy, A. and Bernard, J. -P. and Bersanelli, M. and Bielewicz, P. and Bobin, J. and Bock, J. J. and Bonaldi, A. and Bond, J. R. and Borrill, J. and Bouchet, F. R. and Boulanger, F. and Bowyer, J. W. and Bridges, M. and Bucher, M. and Burigana, C. and Butler, R. C. and Cappellini, B. and Cardoso, J. -F. and Carr, R. and Casale, M. and Catalano, A. and Challinor, A. and Chamballu, A. and Chary, R. -R. and Chen, X. and Chiang, L. -Y and Chiang, H. C. and Christensen, P. R. and Church, S. and Clements, D. L. and Colombi, S. and Colombo, L. P. L. and Couchot, F. and Coulais, A. and Crill, B. P. and Curto, A. and Cuttaia, F. and Danese, L. and Davies, R. D. and Davis, R. J. and de Bernardis, P. and de Rosa, A. and de Zotti, G. and Delabrouille, J. and Delouis, J. -M. and D\'{e}sert, F. -X. and Dickinson, C. and Diego, J. M. and Dole, H. and Donzelli, S. and Dor\'{e}, O. and Douspis, M. and Dunkley, J. and Dupac, X. and Efstathiou, G. and En\ss lin, T. a. and Eriksen, H. K. and Falgarone, E. and Finelli, F. and Foley, S. and Forni, O. and Frailis, M. and Franceschi, E. and Freschi, M. and Fromenteau, S. and Gaier, T. C. and Galeotta, S. and Gallegos, J. and Gandolfo, B. and Ganga, K. and Giard, M. and Giardino, G. and Giraud-H\'{e}raud, Y. and Gonz\'{a}lez-Nuevo, J. and G\'{o}rski, K. M. and Gratton, S. and Gregorio, A. and Gruppuso, A. and Haissinski, J. and Hansen, F. K. and Hanson, D. and Harrison, D. and Helou, G. and Henrot-Versill\'{e}, S. and Hern\'{a}ndez-Monteagudo, C. and Herranz, D. and Hildebrandt, S. R. and Hivon, E. and Hobson, M. and Holmes, W. a. and Hornstrup, A. and Hovest, W. and Huffenberger, K. M. and Jaffe, T. R. and Jaffe, a. H. and Jewell, J. and Jones, W. C. and Juvela, M. and Kangaslahti, P. and Keih\"{a}nen, E. and Keskitalo, R. and Kisner, T. S. and Kneissl, R. and Knoche, J. and Knox, L. and Kunz, M. and Kurki-Suonio, H. and Lagache, G. and L\"{a}hteenm\"{a}ki, A. and Lamarre, J. -M. and Lasenby, A. and Laureijs, R. J. and Lawrence, C. R. and Jeune, M. Le and Leach, S. and Leahy, J. P. and Leonardi, R. and Le\'{o}n-Tavares, J. and Leroy, C. and Lesgourgues, J. and Liguori, M. and Lilje, P. B. and Linden-V\o rnle, M. and L\'{o}pez-Caniego, M. and Lowe, S. and Lubin, P. M. and Mac\'{\i}as-P\'{e}rez, J. F. and Maffei, B. and Maino, D. and Mandolesi, N. and Maris, M. and Marshall, D. J. and Martin, P. G. and Mart\'{\i}nez-Gonz\'{a}lez, E. and Masi, S. and Matarrese, S. and Matthai, F. and Mazzotta, P. and McDonald, A. and McGehee, P. and Meinhold, P. R. and Melchiorri, A. and Melin, J. -B. and Mendes, L. and Mennella, A. and Migliaccio, M. and Miniscalco, R. and Mitra, S. and Miville-Desch\^{e}nes, M. -a. and Moneti, A. and Montier, L. and Morgante, G. and Mortlock, D. and Moss, A. and Munshi, D. and Murphy, J. a. and Naselsky, P. and Nati, F. and Natoli, P. and Netterfield, C. B. and N\o rgaard-Nielsen, H. U. and North, C. and Noviello, F. and Novikov, D. and Novikov, I. and O'Dwyer, I. J. and Osborne, S. and Oxborrow, C. a. and Paci, F. and Pagano, L. and Pajot, F. and Paladini, R. and Paoletti, D. and Partridge, B. and Pasian, F. and Patanchon, G. and Pearson, D. and Pearson, T. J. and Perdereau, O. and Perotto, L. and Perrotta, F. and Piacentini, F. and Piat, M. and Pierpaoli, E. and Pietrobon, D. and Plaszczynski, S. and Platania, P. and Pointecouteau, E. and Polenta, G. and Ponthieu, N. and Popa, L. and Poutanen, T. and Pratt, G. W. and Pr\'{e}zeau, G. and Prunet, S. and Puget, J. -L. and Rachen, J. P. and Reach, W. T. and Rebolo, R. and Reinecke, M. and Remazeilles, M. and Renault, C. and Ricciardi, S. and Riller, T. and Ristorcelli, I. and Rocha, G. and Rosset, C. and Rossetti, M. and Roudier, G. and Rowan-Robinson, M. and Rubi\~{n}o-Mart\'{\i}n, J. a. and Rusholme, B. and Salerno, E. and Sandri, M. and Santos, D. and Savini, G. and Scott, D. and Seiffert, M. D. and Shellard, E. P. S. and Smoot, G. F. and Spencer, L. D. and Starck, J. -L. and Stolyarov, V. and Stompor, R. and Sudiwala, R. and Sunyaev, R. and Sureau, F. and Sutton, D. and Suur-Uski, a. -S. and Sygnet, J. -F. and Tauber, J. a. and Tavagnacco, D. and Taylor, D. and Terenzi, L. and Texier, D. and Toffolatti, L. and Tomasi, M. and Tristram, M. and Tucci, M. and Tuovinen, J. and T\"{u}rler, M. and Tuttlebee, M. and Umana, G. and Valenziano, L. and Valiviita, J. and {Van Tent}, B. and Varis, J. and Vibert, L. and Vielva, P. and Villa, F. and Vittorio, N. and Wade, L. a. and Wandelt, B. D. and Watson, R. and Watson, C. and White, M. and White, S. D. M. and Wilkinson, A. and Yvon, D. and Zacchei, A. and Zonca, A.},
doi = {10.1051/0004-6361/201321529},
eprint = {1303.5062},
file = {:home/tomaton/Downloads/1303.5062v2.pdf:pdf},
issn = {1943-2879},
journal = {Physics},
keywords = {cosmology},
month = mar,
pages = {107},
title = {{Planck 2013 Results. I. Overview of Products and Scientific Results}},
volume = {6},
year = {2013}
}
@techreport{Herr2006,
author = {Herr, Werner and Kaltchev, D I and Schmidt, F and Mcintosh, E},
file = {:home/tomaton/Downloads/lhc-project-report-927.pdf:pdf},
keywords = {01 Circular Colliders},
number = {June 2006},
pages = {30--33},
title = {{Large Scale Beam-beam Simulations for the CERN LHC Using Distributed Computing}},
url = {http://cds.cern.ch/record/972345},
year = {2006}
}
@article{Kacsuk2008a,
abstract = {Grid interoperability has recently become a major issue at Grid forums. Most of the current ideas try to solve the problem at the middleware level where unfortunately too many components (information system, broker, etc.) should be made interoperable. As an alternative concept the P-GRADE portal is the first Grid portal that tries to solve the problem at the level of workflows. It means that the components of a workflow can be executed simultaneously in several Grids. In this way the user can exploit more parallelism than inside one Grid. More than that the workflow level completely hides the low level Grid details for the end-user who does not have to learn the low level Grid commands of different Grids. In this way porting workflow application between different Grids can be done with minimal user efforts. The paper describes those features and techniques that are provided and used by the P-GRADE portal to solve the Grid interoperability problem. ?? 2008 Elsevier B.V. All rights reserved.},
author = {Kacsuk, Peter and Kiss, Tamas and Sipos, Gergely},
doi = {10.1016/j.future.2008.02.008},
file = {:home/tomaton/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Kacsuk, Kiss, Sipos - 2008 - Solving the grid interoperability problem by P-GRADE portal at workflow level.pdf:pdf},
issn = {0167739X},
journal = {Future Generation Computer Systems},
keywords = {Grid,Interoperability,Legacy code,Portal,Workflow},
pages = {744--751},
title = {{Solving the Grid Interoperability Problem By P-GRADE Portal at Workflow Level}},
volume = {24},
year = {2008}
}
@article{Chervenak2012,
abstract = {Progress in our understanding of brain disorders increasingly relies on the costly collection of large standardized brain magnetic resonance imaging (MRI) data sets. Moreover, the clinical interpretation of brain scans benefits from compare and contrast analyses of scans from patients with similar, and sometimes rare, demographic, diagnostic, and treatment status. A solution to both needs is to acquire standardized, research-ready clinical brain scans and to build the information technology infrastructure to share such scans, along with other pertinent information, across hospitals. This paper describes the design, deployment, and operation of a federated imaging system that captures and shares standardized, de-identified clinical brain images in a federation across multiple institutions. In addition to describing innovative aspects of the system architecture and our initial testing of the deployed infrastructure, we also describe the Standardized Imaging Protocol (SIP) developed for the project and our interactions with the Institutional Review Board (IRB) regarding handling patient data in the federated environment.},
author = {Chervenak, Ann L. and {Van Erp}, Theo G M and Kesselman, Carl and D'Arcy, Mike and Sobell, Janet and Keator, David and Dahm, Lisa and Murry, Jim and Law, Meng and Hasso, Anton and Ames, Joseph and MacCiardi, Fabio and Potkin, Steven G.},
doi = {10.3233/978-1-61499-054-3-19},
file = {:home/tomaton/Downloads/HealthGrid2012-BIRN.pdf:pdf},
isbn = {9781614990536},
issn = {09269630},
journal = {Studies in Health Technology and Informatics},
keywords = {Architecture,Brain,De-identification,Federation,Health,Hospitals,Imaging,Infrastructure,MRI,Open source,Pilot,Protocol,Sharing,Standardization},
pages = {19--28},
pmid = {22941984},
title = {{A System Architecture for Sharing De-identified, Research-ready Brain Scans and Health Information Across Clinical Imaging Centers}},
volume = {175},
year = {2012}
}
@article{Cook1983,
abstract = {An historical overview of computational complexity is presented. Emphasis is on the fundamental issues of defining the intrinsic computational complexity of a problem and proving upper and lower bounds on the complexity of problems. Probabilistic and parallel computation are discussed.},
author = {Cook, Stephen A.},
doi = {10.1145/358141.358144},
file = {:home/tomaton/Downloads/p400-cook.pdf:pdf},
isbn = {0001-0782},
issn = {00010782},
journal = {Communications of the ACM},
month = jun,
number = {6},
pages = {400--408},
title = {{An Overview of Computational Complexity}},
volume = {26},
year = {1983}
}
@article{Hui2007,
abstract = {Published models of excitable cells can be used to fit to a range of action potential experimental data. CellML is a well-defined standard for publishing and exchanging such models, but currently there is a lack of software that utilizes CellML for parameter analysis. In this paper, we introduce a Java-based utility capable of performing model simulation, identifiability analysis, and parameter optimization of ionic cardiac cell models written in CellML. Identifiability analysis was performed in seven CellML models. Parameter identifiability was consistently improved by using the compensatory membrane current as opposed to the membrane voltage as the residual. as well as through the introduction of an additional stimulus set used in the fitting process.},
author = {Hui, Ben B B and Dokos, Socrates and Lovell, Nigel H},
doi = {10.1109/IEMBS.2007.4353539},
file = {:home/tomaton/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Hui, Dokos, Lovell - 2007 - Parameter identifiability of cardiac ionic models using a novel CellML least squares optimization tool.pdf:pdf},
issn = {1557-170X},
journal = {Conference proceedings : ... Annual International Conference of the IEEE Engineering in Medicine and Biology Society. IEEE Engineering in Medicine and Biology Society. Conference},
keywords = {Action Potentials,Action Potentials: physiology,Animals,Cardiac,Cardiac: physiology,Cardiovascular,Computer Graphics,Computer Simulation,Heart Conduction System,Heart Conduction System: physiology,Humans,Ion Channel Gating,Ion Channel Gating: physiology,Ion Channels,Ion Channels: physiology,Least-Squares Analysis,Models,Myocytes,Programming Languages,User-Computer Interface},
month = jan,
pages = {5307--10},
pmid = {18003205},
shorttitle = {Engineering in Medicine and Biology Society, 2007.},
title = {{Parameter identifiability of cardiac ionic models using a novel CellML least squares optimization tool.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/18003205},
volume = {2007},
year = {2007}
}
@article{Tondel2011,
abstract = {Deterministic dynamic models of complex biological systems contain a large number of parameters and state variables, related through nonlinear differential equations with various types of feedback. A metamodel of such a dynamic model is a statistical approximation model that maps variation in parameters and initial conditions (inputs) to variation in features of the trajectories of the state variables (outputs) throughout the entire biologically relevant input space. A sufficiently accurate mapping can be exploited both instrumentally and epistemically. Multivariate regression methodology is a commonly used approach for emulating dynamic models. However, when the input-output relations are highly nonlinear or non-monotone, a standard linear regression approach is prone to give suboptimal results. We therefore hypothesised that a more accurate mapping can be obtained by locally linear or locally polynomial regression. We present here a new method for local regression modelling, Hierarchical Cluster-based PLS regression (HC-PLSR), where fuzzy C-means clustering is used to separate the data set into parts according to the structure of the response surface. We compare the metamodelling performance of HC-PLSR with polynomial partial least squares regression (PLSR) and ordinary least squares (OLS) regression on various systems: six different gene regulatory network models with various types of feedback, a deterministic mathematical model of the mammalian circadian clock and a model of the mouse ventricular myocyte function.},
author = {T\o ndel, Kristin and Indahl, Ulf G and Gjuvsland, Arne B and Vik, Jon Olav and Hunter, Peter and Omholt, Stig W and Martens, Harald},
doi = {10.1186/1752-0509-5-90},
file = {:home/tomaton/Downloads/1752-0509-5-90.pdf:pdf},
isbn = {1752-0509},
issn = {1752-0509},
journal = {BMC systems biology},
number = {1},
pages = {90},
pmid = {21627852},
publisher = {BioMed Central Ltd},
title = {{Hierarchical Cluster-based Partial Least Squares Regression (HC-PLSR) is an Efficient Tool for Metamodelling of Nonlinear Dynamic Models.}},
url = {http://www.biomedcentral.com/1752-0509/5/90},
volume = {5},
year = {2011}
}
@book{Saltelli2008,
abstract = {Complex mathematical and computational models are used in all areas of society and technology and yet model based science is increasingly contested or refuted, especially when models are applied to controversial themes in domains such as health, the environment or the economy. More stringent standards of proofs are demanded from model-based numbers, especially when these numbers represent potential financial losses, threats to human health or the state of the environment. Quantitative sensitivity analysis is generally agreed to be one such standard. Mathematical models are good at mapping assumptions into inferences. A modeller makes assumptions about laws pertaining to the system, about its status and a plethora of other, often arcane, system variables and internal model settings. To what extent can we rely on the model-based inference when most of these assumptions are fraught with uncertainties? Global Sensitivity Analysis offers an accessible treatment of such problems via quantitative sensitivity analysis, beginning with the first principles and guiding the reader through the full range of recommended practices with a rich set of solved exercises. The text explains the motivation for sensitivity analysis, reviews the required statistical concepts, and provides a guide to potential applications. The book: Provides a self-contained treatment of the subject, allowing readers to learn and practice global sensitivity analysis without further materials. Presents ways to frame the analysis, interpret its results, and avoid potential pitfalls. Features numerous exercises and solved problems to help illustrate the applications. Is authored by leading sensitivity analysis practitioners, combining a range of disciplinary backgrounds. Postgraduate students and practitioners in a wide range of subjects, including statistics, mathematics, engineering, physics, chemistry, environmental sciences, biology, toxicology, actuarial sciences, and econometrics will find much of use here. This book will prove equally valuable to engineers working on risk analysis and to financial analysts concerned with pricing and hedging. 2008 John Wiley \{\&\} Sons, Ltd.},
author = {Saltelli, Andrea and Ratto, Marco and Andres, Terry and Campolongo, Francesca and Cariboni, Jessica and Gatelli, Debora and Saisana, Michaela and Tarantola, Stefano},
booktitle = {Global Sensitivity Analysis. the Primer},
doi = {10.1002/9780470725184},
file = {:home/tomaton/Downloads/Global Sensitivity AnalysisThe Primer.pdf:pdf},
isbn = {9780470059975},
pages = {1--292},
title = {{Global Sensitivity Analysis. The Primer}},
year = {2008}
}
@article{P.BryanHeidorn2008,
abstract = {One of the primary outputs of the scientific enterprise is data, but many institutions such as libraries that are charged with preserving and disseminating scholarly output have largely ignored this form of documentation of scholarly activity. This paper focuses on a particularly troublesome class of data, termed dark data. “Dark data” is not carefully indexed and stored so it becomes nearly invisible to scientists and other potential users and therefore is more likely to remain underutilized and eventually lost. The article discusses how the concepts from long-tail economics can be used to understand potential solutions for better curation of this data. The paper describes why this data is critical to scientific progress, some of the properties of this data, as well as some social and technical barriers to proper management of this class of data. Many potentially useful institutional, social, and technical solutions are under development and are introduced in the last sections of the paper, but these solutions are largely unproven and require additional research and development.},
author = {{P. Bryan Heidorn}},
doi = {10.1353/lib.0.0036},
file = {:home/tomaton/Downloads/heidorn.pdf:pdf},
isbn = {1559-0682},
issn = {1559-0682},
journal = {Library Trends},
number = {2},
pages = {280--299},
title = {{Shedding Light on the Dark Data in the Long Tail of Science}},
volume = {57},
year = {2008}
}
@article{Bayer1972Sym,
author = {Bayer, Rudolf},
doi = {10.1007/BF00289509},
issn = {0001-5903},
journal = {Acta Informatica},
number = {4},
pages = {290--306},
title = {{Symmetric Binary B-Trees: Data Structure and Maintenance Algorithms}},
volume = {1},
year = {1972}
}
@article{Shi1996,
author = {Shi, Yuan},
file = {:home/tomaton/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Shi - 1996 - Reevaluating Amdahl's Law and Gustafson's Law.pdf:pdf},
journal = {Computer Science Department, Temple University},
pages = {1--9},
title = {{Reevaluating Amdahl's Law and Gustafson's Law}},
year = {1996}
}
@article{Kulhanek2011,
author = {Kulh\'{a}nek, Tom\'{a}\v{s}},
file = {:home/tomaton/Downloads/mefanet-report-2011.pdf:pdf},
isbn = {978-80-210-5539-1},
journal = {Mefanet Report},
pages = {69--72},
title = {{From Educational Models Towards Identification of Physiological Systems}},
url = {http://www.mefanet.cz/res/file/reporty/mefanet-report-2011.pdf},
volume = {04},
year = {2011}
}
@article{Urbah2009,
author = {Urbah, Etienne and Kacsuk, Peter and Farkas, Zoltan and Fedak, Gilles and Kecskemeti, Gabor and Lodygensky, Oleg and Marosi, Attila and Balaton, Zoltan and Caillat, Gabriel and Gombas, Gabor and Kornafeld, Adam and Kovacs, Jozsef and He, Haiwu and Lovas, Robert},
doi = {10.1007/s10723-009-9137-0},
file = {:home/tomaton/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Urbah et al. - 2009 - EDGeS Bridging EGEE to BOINC and XtremWeb.pdf:pdf},
issn = {1570-7873},
journal = {Journal of Grid Computing},
month = sep,
number = {3},
pages = {335--354},
title = {{EDGeS: Bridging EGEE to BOINC and XtremWeb}},
volume = {7},
year = {2009}
}
@book{Rauber2013,
author = {Rauber, Thomas and R\"{u}nger, Gudula},
file = {:home/tomaton/Documents/Studium-Dokumenty/Articles/Theory Of Computation/Parallel Programming - T Rauber.G Runger.PDF:PDF},
isbn = {9783642048173},
publisher = {Springer},
title = {{Parallel Programming: For Multicore and Cluster Systems}},
year = {2013}
}
@article{Laure2006,
abstract = {The past few years have seen the creation of the first producti on level Grid infrastructures that offer their users a dependab le service at an unprecedented scale. Depending on the flavor of middleware services these infrastructures deploy (for instance Condor, gLite, Globus, UNICORE, to name only a few) different interfaces to program the Grid infrastructures are provided. Despite ongoing efforts to standardize Grid service interfaces, there are still si gnificant differences in how applications can interface to a Grid infrastructure. In this paper we describe the middleware (gLite) and services deployed on the EGEE Grid infrastructure and explain how applications can interface to them.},
author = {Laure, E and Fisher, S and Frohner, A and Grandi, C and Kunszt, P and Krenek, A and Mulmo, O and Pacini, F and Prelz, F and White, J and Others},
file = {:home/tomaton/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Laure et al. - 2006 - Programming the Grid with gLite.pdf:pdf},
journal = {Computational Methods in Science and Technology},
pages = {33--45},
title = {{Programming the Grid with gLite}},
volume = {12},
year = {2006}
}
@article{Dostal2006,
author = {Dostal, O and Javornik, M and Ventruba, P},
journal = {INTERNATIONAL JOURNAL OF COMPUTER ASSISTED RADIOLOGY AND SURGERY},
pages = {98},
publisher = {SPRINGER SCIENCE+ BUSINESS MEDIA},
title = {{Collaborative environment supporting research and education in the area of medical image information}},
volume = {1},
year = {2006}
}
@article{Kroon1996,
author = {Kroon, F. W.},
doi = {10.1007/BF00372775},
issn = {0039-3215},
journal = {Studia Logica},
month = may,
number = {3},
pages = {427--454},
title = {{The intrinsic difficulty of recursive functions}},
url = {http://link.springer.com/10.1007/BF00372775},
volume = {56},
year = {1996}
}
@article{Marosi2013,
abstract = {The paper completes the work started in the EU FP7 EDGI project for extending service grids with volunteer (global) and institutional (local) desktop grids. The Generic BOINC Application Client (GBAC) concept described in the paper enables the transparent and automatic forwarding of parameter sweep application (parametric) jobs from service grid VOs (Virtual Organizations) into connected desktop grids without any porting effort. GBAC that introduces virtualization for the volunteer BOINC (Berkeley Open Infrastructure for Network Computing) clients can also be considered as a first step towards establishing volunteer cloud systems since it provides solutions for several problems of creating such a volunteer cloud system. © 2012 Elsevier B.V. All rights reserved.},
author = {Marosi, Attila and Kov\'{a}cs, J\'{o}zsef and Kacsuk, Peter},
doi = {10.1016/j.future.2012.03.013},
file = {:home/tomaton/Downloads/toward\_a\_volunteer\_cloud(1).pdf:pdf},
issn = {0167739X},
journal = {Future Generation Computer Systems},
keywords = {Cloud,Desktop grid,Virtualization,Volunteer computing},
number = {6},
pages = {1442--1451},
publisher = {Elsevier B.V.},
title = {{Towards a volunteer cloud system}},
url = {http://dx.doi.org/10.1016/j.future.2012.03.013},
volume = {29},
year = {2013}
}
@article{Itu2013,
abstract = {We propose a CFD-based approach for the non-invasive hemodynamic assessment of pre- and post-operative coarctation of aorta (CoA) patients. Under our approach, the pressure gradient across the coarctation is determined from computational modeling based on physiological principles, medical imaging data, and routine non-invasive clinical measurements. The main constituents of our approach are a reduced-order model for computing blood flow in patient-specific aortic geometries, a parameter estimation procedure for determining patient-specific boundary conditions and vessel wall parameters from non-invasive measurements, and a comprehensive pressure-drop formulation coupled with the overall reduced-order model. The proposed CFD-based algorithm is fully automatic, requiring no iterative tuning procedures for matching the computed results to observed patient data, and requires approximately 6-8 min of computation time on a standard personal computer (Intel Core2 Duo CPU, 3.06 GHz), thus making it feasible for use in a clinical setting. The initial validation studies for the pressure-drop computations have been performed on four patient datasets with native or recurrent coarctation, by comparing the results with the invasively measured peak pressure gradients recorded during routine cardiac catheterization procedure. The preliminary results are promising, with a mean absolute error of less than 2 mmHg in all the patients.},
author = {Itu, Lucian and Sharma, Puneet and Ralovich, Krist\'{o}f and Mihalef, Viorel and Ionasec, Razvan and Everett, Allen and Ringel, Richard and Kamen, Ali and Comaniciu, Dorin},
doi = {10.1007/s10439-012-0715-0},
file = {:home/tomaton/Downloads/ralovich2013abme.pdf:pdf},
issn = {00906964},
journal = {Annals of Biomedical Engineering},
keywords = {CFD,Coarctation of aorta,Non-invasive,PC-MRI,Pressure gradient,Reduced-order models},
number = {4},
pages = {669--681},
pmid = {23232558},
title = {{Non-invasive Hemodynamic Assessment of Aortic Coarctation: Validation with in Vivo Measurements}},
volume = {41},
year = {2013}
}
@article{kulhanek2010c,
author = {Kulh\'{a}nek, Tom\'{a}\v{s}},
issn = {1801-5603},
journal = {European Journal for Biomedical Informatics (EJBI)},
number = {1},
pages = {55--58},
title = {{Infrastructure for Data Storage and Computation in Biomedical Research}},
url = {http://www.ejbi.org/img/ejbi/ejbi2010-1.pdf},
volume = {6},
year = {2010}
}
@article{Hunter2013,
abstract = {Peter Hunter1,3⇓, Tara Chapman4,5, Peter V. Coveney6, Bernard de Bono3,8, Vanessa Diaz7, John Fenner9, Alejandro F. Frangi11,12, Peter Harris13, Rod Hose9, Peter Kohl2,14, Pat Lawford9, Keith McCormack9, Miriam Mendes6, Stig Omholt15, Alfio Quarteroni16,17, Nour Shublaq6, John Sk\aa r18, Karl Stroetmann20, Jesper Tegner19, S. Randall Thomas21,22, Ioannis Tollis23,25, Ioannis Tsamardinos24,25, Johannes H. G. M. van Beek26 and Marco Viceconti10,271Department of Physiology, Anatomy and Genetics, University of Oxford, Oxford, UK2Department of Computer Science, University of Oxford, Oxford, UK3Auckland Bioengineering Institute (ABI), University of Auckland, New Zealand4Laboratory of Anatomy, Biomechanics and Organogenesis, Faculty of Medicine, Universit\'{e} Libre de Bruxelles, Belgium5Laboratory of Anthropology and Prehistory, Royal Belgian Institute of Natural Sciences, Brussels, Belgium6Centre for Computational Science, University College London, London, UK7Department of Mechanical Engineering, University College London, London, UK8CHIME Institute, Archway Campus, University College London, London, UK9Department of Cardiovascular Science (Medical Physics Group), Faculty of Medicine, Dentistry and Health, University of Sheffield, Sheffield, UK10INSIGNEO Institute for in silico medicine, University of Sheffield, Sheffield, UK11Networking Biomedical Research Center on Bioengineering, Biomaterials and Nanomedicine (CIBER-BBN), Barcelona, Spain12Center for Computational Imaging and Simulation Technologies in Biomedicine (CISTIB), Department of Mechanical Engineering, University of Sheffield, Sheffield, UK13Department of Physiology, Faculty of Medicine, Dentistry and Health Sciences, The University of Melbourne, Australia14National Heart and Lung Institute, Imperial College London, London, UK15Cardiac Exercise Research Group, Department of Circulation and Medical Imaging, NTNU Norwegian University of Science and Technology, Trondheim, Norway16Ecole Polytechnique F\'{e}d\'{e}rale de Lausanne, Switzerland17Politecnico di Milano, Milan, Italy18Department of LIME, Karolinska University Hospital, Karolinska Institutet, Stockholm, Sweden19Department of Medicine, Unit for Computational Medicine, Center for Molecular Medicine, Karolinska University Hospital, Karolinska Institutet, Stockholm, Sweden20Empirica Communication and Technology Research, Bonn, Germany21IR4M CNRS UMR8081, Institut Gustave-Roussy, Dept Imagerie/Echographie, Orsay, France22Universit\'{e} Paris-Sud, CNRS, Orsay, France23Computational Medicine Laboratory, Foundation for Research and Technology Hellas (FORTH), Heraklion, Crete, Greece24Bioinformatics Laboratory, Institute of Computer Science, Foundation for Research and Technology Hellas (FORTH), Heraklion, Crete, Greece25Computer Science Department, University of Crete, Heraklion, Crete, Greece26Section Medical Genomics, Department of Clinical Genetics, VU University Medical Centre, Amsterdam, The Netherlands27Laboratorio di Tecnologia Medica, Istituto Ortopedico Rizzoli, Bologna, Italye-mail: p.hunter\{at\}auckland.ac.nzAbstract European funding under Framework 7 (FP7) for the virtual physiological human (VPH) project has been in place now for 5 years. The VPH Network of Excellence (NoE) has been set up to help develop common standards, open source software, freely accessible data and model repositories, and various training and dissemination activities for the project. It is also working to coordinate the many clinically targeted projects that have been funded under the FP7 calls. An initial vision for the VPH was defined by the FP6 STEP project in 2006. In 2010, we wrote an assessment of the accomplishments of the first two years of the VPH in which we considered the biomedical science, healthcare and information and communications technology challenges facing the project (Hunter et al. 2010 Phil. Trans. R. Soc. A 368, 2595–2614 (doi:10.1098/rsta.2010.0048)). We proposed that a not-for-profit professional umbrella organization, the VPH Institute, should be established as a means of sustaining the VPH vision beyond the time-frame of the NoE. Here, we update and extend this assessment and in particular address the following issues raised in response to Hunter et al.: (i) a vision for the VPH updated in the light of progress made so far, (ii) biomedical science and healthcare challenges that the VPH initiative can address while also providing innovation opportunities for the European industry, and (iii) external changes needed in regulatory policy and business models to realize the full potential that the VPH has to offer to industry, clinics and society generally. virtual physiological humanphysiomecomputational physiologysystems biologymultiscale modellingFootnotesOne contribution of 25 to a Theme Issue ‘The virtual physiological human: integrative approaches to computational biomedicine’.© 2013 The Author(s) Published by the Royal Society. All rights reserved.},
author = {Hunter, Peter and Chapman, Tara and Coveney, Peter V and de Bono, Bernard and Diaz, Vanessa and Fenner, John and Frangi, Alejandro F and Harris, Peter and Hose, Rod and Kohl, Peter and Lawford, Pat and McCormack, Keith and Mendes, Miriam and Omholt, Stig and Quarteroni, Alfio and Shublaq, Nour and Sk\aa r, John and Stroetmann, Karl and Tegner, Jesper and Thomas, S Randall and Tollis, Ioannis and Tsamardinos, Ioannis and van Beek, Johannes H G M and Viceconti, Marco},
file = {:home/tomaton/Downloads/20130004.full.pdf:pdf},
journal = {Interface Focus},
month = feb,
number = {2},
title = {{A Vision and Strategy for the Virtual Physiological Human: 2012 Update}},
url = {http://rsfs.royalsocietypublishing.org/content/3/2/20130004.abstract},
volume = {3},
year = {2013}
}
@article{Westerhof2009,
abstract = {Frank's Windkessel model described the hemodynamics of the arterial system in terms of resistance and compliance. It explained aortic pressure decay in diastole, but fell short in systole. Therefore characteristic impedance was introduced as a third element of the Windkessel model. Characteristic impedance links the lumped Windkessel to transmission phenomena (e.g., wave travel). Windkessels are used as hydraulic load for isolated hearts and in studies of the entire circulation. Furthermore, they are used to estimate total arterial compliance from pressure and flow; several of these methods are reviewed. Windkessels describe the general features of the input impedance, with physiologically interpretable parameters. Since it is a lumped model it is not suitable for the assessment of spatially distributed phenomena and aspects of wave travel, but it is a simple and fairly accurate approximation of ventricular afterload.},
author = {Westerhof, Nico and Lankhaar, Jan-Willem and Westerhof, Berend E},
doi = {10.1007/s11517-008-0359-2},
file = {:home/tomaton/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Westerhof, Lankhaar, Westerhof - 2009 - The arterial Windkessel.pdf:pdf},
issn = {1741-0444},
journal = {Medical \& biological engineering \& computing},
keywords = {Aorta,Aorta: physiology,Arteries,Arteries: physiology,Cardiovascular,Hemodynamics,Hemodynamics: physiology,Humans,Models,Vascular Resistance,Vascular Resistance: physiology},
month = feb,
number = {2},
pages = {131--41},
pmid = {18543011},
title = {{The arterial Windkessel.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/18543011},
volume = {47},
year = {2009}
}
@article{Butterworth2014,
author = {Butterworth, Erik and Jardine, Bartholomew E. and Raymond, Gary M. and Neal, Maxwell L. and Bassingthwaighte, James B.},
doi = {10.12688/f1000research.2-288.v2},
file = {:home/tomaton/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Butterworth et al. - 2014 - JSim, an open-source modeling system for data analysis.pdf:pdf},
issn = {2046-1402},
journal = {F1000Research},
month = may,
title = {{JSim, an Open-source Modeling System for Data Analysis}},
volume = {2},
year = {2014}
}
@book{Hurwitz2007,
author = {Hurwitz, Judith and Bloor, Robin and Baroudi, Carol and Kaufman, Marcia},
file = {:home/tomaton/Downloads/Service\_Oriented\_Architecture\_for\_DUMmIES.pdf:pdf},
isbn = {9780470054352},
pages = {376},
title = {{Service Oriented Architecture For Dummies}},
year = {2007}
}
@book{Greenlaw1995,
address = {Oxford},
author = {Greenlaw, Raymond and Hoover, H James and Ruzzo, Walter L},
file = {:home/tomaton/Downloads/limits-to-parallel-computation-p-completeness-theory.9780195085914.35897.pdf:pdf},
publisher = {Oxford university press},
title = {{Limits to Parallel Computation}},
year = {1995}
}
@inproceedings{Kulhanek2012a,
address = {Prague},
author = {Kulh\'{a}nek, Tom\'{a}\v{s} and Fri\v{c}, Marek},
booktitle = {EGI Technical Forum, Prague},
file = {:home/tomaton/Downloads/Remote analysis of human voice - environment for voice training and ORL medicine - Contribution.pdf:pdf},
title = {{Remote Analysis of Human Voice - Environment for Voice Training and ORL Medicine}},
year = {2012}
}
@book{Papadimitriou1995,
author = {Papadimitriou, CH},
file = {:home/tomaton/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Papadimitriou - 1995 - Computational complexity.pdf:pdf},
publisher = {Addison-WesleyPublishing Company},
title = {{Computational Complexity}},
year = {1995}
}
@article{Anderson2006,
abstract = {With his brilliant theory of the Long Tail - a powerful new economic force in a world where the internet allows almost unlimited choice - Chris Anderson has identified an important truth about our economy and culture: the future does not lie in hits - the high-volume end of a traditional demand curve - but in what used to be regarded as misses - the curve's endlessly long tail.},
author = {Anderson, Chris},
file = {:home/tomaton/Downloads/chris-anderson-the-long-tail-why-the-future-of-business-is-selling-less-of-more.pdf:pdf},
isbn = {184413850X},
issn = {02650487},
journal = {World Journal Of The International Linguistic Association},
pages = {256},
title = {{The Long Tail: How Endless Choice Is Creating Unlimited Demand}},
year = {2006}
}
@article{Bird2009,
author = {Bird, I. and Jones, B. and Kee, K.F.},
doi = {10.1109/MC.2009.28},
file = {:home/tomaton/Downloads/04755154.pdf:pdf},
issn = {0018-9162},
journal = {Computer},
month = jan,
number = {1},
pages = {36--46},
title = {{The Organization and Management of Grid Infrastructures}},
volume = {42},
year = {2009}
}
@article{Foster2001,
author = {Foster, Ian and Kesselman, Carl and Tuecke, Steven},
file = {:home/tomaton/Downloads/anatomy.pdf:pdf},
journal = {International Journal of High Performance Computing Applications},
number = {3},
pages = {200--222},
title = {{The Anatomy of the Grid: Enabling Scalable Virtual Organizations}},
volume = {15},
year = {2001}
}
@article{Svec2010,
abstract = {This tutorial addresses fundamental characteristics of microphones (frequency response, frequency range, dynamic range, and directionality), which are important for accurate measurements of voice and speech.},
author = {\v{S}vec, Jan G. and Granqvist, Svante},
doi = {10.1044/1058-0360(2010/09-0091)},
file = {:home/tomaton/Downloads/document(3).pdf:pdf},
issn = {10580360},
journal = {American Journal of Speech-Language Pathology},
keywords = {Measurement,Microphones,Requirements,Voice},
number = {November},
pages = {356--368},
pmid = {20601621},
title = {{Guidelines for Selecting Microphones for Human Voice Production Research}},
volume = {19},
year = {2010}
}
@article{Hunter2009,
abstract = {<para> The revolution in molecular biology over the past 50 years has given us an extraordinarily detailed parts list for life, but little understanding of how the parts integrate into the physiological function of the healthy and diseased human body. In contrast, the engineering sciences, from a detailed knowledge of its components, have successfully explained how a plane actually flies. The key difference is the use of mathematical models based on physical principles and a systematic approach to knowledge management. In this review, we describe the efforts of the Virtual Physiological Human (VPH) Physiome Project to address the challenge of integrating molecular, cellular and tissue/organ structure and function through the use of multiscale modeling based on the development of community standards, open source tools and web-accessible databases. We illustrate two applications of the framework, one to cardiology and one to bone fracture prediction in the elderly. </para>},
author = {Hunter, P. J. and Viceconti, M.},
doi = {10.1109/RBME.2009.2036204},
file = {:home/tomaton/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Hunter, Viceconti - 2009 - The VPH-Physiome Project Standards and Tools for Multiscale Modeling in Clinical Applications.pdf:pdf},
isbn = {1937-3333},
issn = {1937-3333},
journal = {IEEE Reviews in Biomedical Engineering},
keywords = {Bioengineering,VPH,computational physiology,multiscale modeling,physiome},
pages = {40--53},
title = {{The VPH-Physiome Project: Standards and Tools for Multiscale Modeling in Clinical Applications}},
volume = {2},
year = {2009}
}
@article{Svec1996,
abstract = {A digital technique for high-speed visualization of vibration, called videokymography, was developed and applied to the vocal folds. The system uses a modified video camera able to work in two modes: high-speed (nearly 8,000 images/s) and standard (50 images/s in CCIR norm). In the high-speed mode, the camera selects one active horizontal line (transverse to the glottis) from the whole laryngeal image. The successive line images are presented in real time on a commercial TV monitor, filling each video frame from top to bottom. The system makes it possible to observe left-right asymmetries, open quotient, propagation of mucosal waves, movement of the upper and, in the closing phase, the lower margins of the vocal folds, etc. The technique is suitable for further processing and quantification of recorded vibration.},
author = {\v{S}vec, Jan G. and Schutte, Harm K.},
doi = {10.1016/S0892-1997(96)80047-6},
file = {:home/tomaton/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/\v{S}vec, Schutte - 1996 - Videokymography High-speed line scanning of vocal fold vibration.pdf:pdf},
issn = {08921997},
journal = {Journal of Voice},
keywords = {High-speed imaging,Laryngoscopy,Stroboscopy,Vibration,Vibration study,Videokymography,Vocal fold vibration,Vocal folds},
number = {2},
pages = {201--205},
pmid = {8734395},
title = {{Videokymography: High-speed Line Scanning of Vocal Fold Vibration}},
volume = {10},
year = {1996}
}
@article{Gustafson1988,
author = {Gustafson, John L.},
doi = {10.1145/42411.42415},
file = {:home/tomaton/Downloads/p532-gustafson.pdf:pdf},
issn = {00010782},
journal = {Communications of the ACM},
month = may,
number = {5},
pages = {532--533},
title = {{Reevaluating Amdahl's law}},
volume = {31},
year = {1988}
}
@article{Anderson2002,
author = {Anderson, David P. and Cobb, Jeff and Korpela, Eric and Lebofsky, Matt and Werthimer, Dan},
doi = {10.1145/581571.581573},
file = {:home/tomaton/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Anderson et al. - 2002 - SETI@home an experiment in public-resource computing.pdf:pdf},
issn = {00010782},
journal = {Communications of the ACM},
month = nov,
number = {11},
pages = {56--61},
title = {{SETI@home: An Experiment in Public-Resource Computing}},
volume = {45},
year = {2002}
}
@book{Li,
author = {Li, Xiaolin and Qiu, Judy},
file = {:home/tomaton/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Li, Qiu - Unknown - Cloud Computing for Data Intensive Application.pdf:pdf},
isbn = {9781493919048},
publisher = {Springer},
title = {{Cloud Computing for Data Intensive Application}}
}
@article{Matsunaga2008,
author = {Matsunaga, Andr\'{e}a and Tsugawa, Maur\'{\i}cio and Fortes, Jos\'{e}},
doi = {10.1109/eScience.2008.62},
file = {:home/tomaton/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Matsunaga, Tsugawa, Fortes - 2008 - CloudBLAST Combining MapReduce and Virtualization on Distributed Resources for Bioinformatics Applic.pdf:pdf},
isbn = {978-1-4244-3380-3},
journal = {2008 IEEE Fourth International Conference on eScience},
keywords = {-cloud},
month = dec,
pages = {222--229},
publisher = {Ieee},
title = {{CloudBLAST: Combining MapReduce and Virtualization on Distributed Resources for Bioinformatics Applications}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=4736761},
year = {2008}
}
@article{Kofranek2011,
abstract = {The paper is a presentation of the current state of development for the Atlas of Physiology and Pathophysiology (Atlas). Our main aim is to provide a novel interactive multimedia application that can be used for biomedical education where (a) simulations are combined with tutorials and (b) the presentation layer is simplified while the underlying complexity of the model is retained. The development of the Atlas required the cooperation of many professionals including teachers, system analysts, artists, and programmers. During the design of the Atlas, tools were developed that allow for component-based creation of simulation models, creation of interactive multimedia and their final coordination into a compact unit based on the given design. The Atlas is a freely available online application, which can help to explain the function of individual physiological systems and the causes and symptoms of their disorders.},
author = {Kofranek, Jiri and Matousek, Stanislav and Rusz, Jan and Stodulka, Petr and Privitzer, Pavol and Matejak, Marek and Tribula, Martin},
doi = {10.1016/j.cmpb.2010.12.007},
file = {:home/tomaton/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Kofranek et al. - 2011 - The Atlas of Physiology and Pathophysiology Web-based multimedia enabled interactive simulations.pdf:pdf},
issn = {1872-7565},
journal = {Computer methods and programs in biomedicine},
keywords = {Atlases as Topic,Computer Simulation,Internet,Physiology},
month = nov,
number = {2},
pages = {143--53},
pmid = {21232813},
title = {{The Atlas of Physiology and Pathophysiology: Web-based multimedia enabled interactive simulations.}},
volume = {104},
year = {2011}
}
@article{Erberich2007,
abstract = {The Digital Imaging and Communications in Medicine (DICOM) standard defines Radiology medical device interoperability and image data exchange between modalities, image databases - Picture Archiving and Communication Systems (PACS) - and image review end-points. However the scope of DICOM and PACS technology is currently limited to the trusted and static environment of the hospital. In order to meet the demand for ad-hoc tele-radiology and image guided medical procedures within the global healthcare enterprise, a new technology must provide mobility, security, flexible scale of operations, and rapid responsiveness for DICOM medical devices and subsequently medical image data. Grid technology, an informatics approach to securely federate independently operated computing, storage, and data management resources at the global scale over public networks, meets these core requirements. Here we present an approach to federate DICOM and PACS devices for large-scale medical image workflows within a global healthcare enterprise. The Globus MEDICUS (Medical Imaging and Computing for Unified Information Sharing) project uses the standards-based Globus Toolkit Grid infrastructure to vertically integrate a new service for DICOM devices - the DICOM Grid Interface Service (DGIS). This new service translates between DICOM and Grid operations and thus transparently extends DICOM to Globus based Grid infrastructure. This Grid image workflow paradigm has been designed to provide not only solutions for global image communication, but fault-tolerance and disaster recovery using Grid data replication technology. Actual use-case of 40 MEDICUS Grid connected international hospitals of the Childerns Oncology Group and the Neuroblastoma Cancer Foundation and further clinical applications are discussed. The open-source Globus MEDICU http://dev.globus.org/wiki/Incubator/MEDICUS.},
author = {Erberich, Stephan G and Silverstein, Jonathan C and Chervenak, Ann and Schuler, Robert and Nelson, Marvin D and Kesselman, Carl},
file = {:home/tomaton/Downloads/00b495256f029e3f31000000.pdf:pdf},
isbn = {0926-9630 (Print)$\backslash$r0926-9630 (Linking)},
issn = {0926-9630},
journal = {Studies in Health Technology and Informatics},
pages = {269--278},
pmid = {17476069},
title = {{Globus MEDICUS -- Federation of DICOM Medical Imaging Devices into Healthcare Grids.}},
volume = {126},
year = {2007}
}
@incollection{Brunberg2010,
author = {Brunberg, A and Maschuw, J and Autschbach, R and Abel, D},
booktitle = {World Congress on Medical Physics and Biomedical Engineering, September 7 - 12, 2009, Munich, Germany SE  - 48},
doi = {10.1007/978-3-642-03895-2\_48},
editor = {D\"{o}ssel, Olaf and Schlegel, WolfgangC.},
isbn = {978-3-642-03894-5},
keywords = {Modeling,cardiovascular system,graphical user interface,physiological control loops,simulation},
pages = {166--169},
publisher = {Springer Berlin Heidelberg},
series = {IFMBE Proceedings},
title = {{Object-oriented Model Library of the Cardiovascular System Including Physiological Control Loops}},
url = {http://dx.doi.org/10.1007/978-3-642-03895-2\_48},
volume = {25/13},
year = {2010}
}
@article{Palladino1997,
abstract = {Myocardial contractile properties form the cornerstone of the heart's ability to pump blood. Efforts have been made to characterize these properties via classic elasticity theory concepts, which can lead to spurious results, as demonstrated by experiments measuring intramyocardial pressure. Two ways out of these difficulties are identified. One is to start at the cellular level, the other at the chamber level. The latter allows separation of ventricle (source) and arterial (load) effects on measured pressure and flow, distinct from previous definitions of ventricular contractility which tended to lump the two.},
author = {Palladino, Joseph L and Rabbany, Sina Y and Mulier, Jan P and Noordergraaf, Abraham},
journal = {Technology and Health Care},
month = jan,
number = {1},
pages = {135--144},
title = {{A perspective on myocardial contractility}},
url = {http://iospress.metapress.com/content/5REMNVKBRLKGHHJN},
volume = {5},
year = {1997}
}
@book{Russell2009,
abstract = {The long-anticipated revision of this \#1 selling book offers the most comprehensive, state of the art introduction to the theory and practice of artificial intelligence for modern applications. Intelligent Agents. Solving Problems by Searching. Informed},
author = {Russell, Stuart and Norvig, Peter},
booktitle = {Prentice Hall},
doi = {10.1017/S0269888900007724},
file = {:home/tomaton/Downloads/Artificial-Intelligence-A-Modern-Approach-3rd-Edition.pdf:pdf},
isbn = {0136042597},
issn = {0269-8889},
title = {{Artificial Intelligence: A Modern Approach, 3rd edition}},
year = {2009}
}
@book{Nilsson2006,
author = {Nilsson, Jimmy},
publisher = {Pearson Education, Inc.},
title = {{Applying Domain-Driven Design and Patterns}},
year = {2006}
}
@article{Moler1986,
author = {Moler, Cleve},
journal = {Hypercube multiprocessors},
pages = {181--195},
title = {{Matrix Computation on Distributed Memory Multiprocessors}},
year = {1986}
}
@inproceedings{Raicu2008,
abstract = {Many-task computing aims to bridge the gap between two computing paradigms, high throughput computing and high performance computing. Many task computing differs from high throughput computing in the emphasis of using large number of computing resources over short periods of time to accomplish many computational tasks (i.e. including both dependent and independent tasks), where primary metrics are measured in seconds (e.g. FLOPS, tasks/sec, MB/s I/O rates), as opposed to operations (e.g. jobs) per month. Many task computing denotes high-performance computations comprising multiple distinct activities, coupled via file system operations. Tasks may be small or large, uniprocessor or multiprocessor, compute-intensive or data-intensive. The set of tasks may be static or dynamic, homogeneous or heterogeneous, loosely coupled or tightly coupled. The aggregate number of tasks, quantity of computing, and volumes of data may be extremely large. Many task computing includes loosely coupled applications that are generally communication-intensive but not naturally expressed using standard message passing interface commonly found in high performance computing, drawing attention to the many computations that are heterogeneous but not ldquohappilyrdquo parallel.},
author = {Raicu, Ioan and Foster, Ian T. and Zhaoyo, Yong},
booktitle = {2008 Workshop on Many-Task Computing on Grids and Supercomputers, MTAGS 2008},
doi = {10.1109/MTAGS.2008.4777912},
isbn = {9781424428724},
keywords = {HPC,HTC,High Performance Computing,High Throughput Computing,MTC,Many-task Computing},
title = {{Many-task computing for grids and supercomputers}},
year = {2008}
}
@article{Lewis1996a,
abstract = {Before examining the intrinsic nature of computation we must have a precise idea of what computation means. In other works, we need to know what we're talking about! To do this, we shall begin with intuitive notions of terms such as calculation, computing procedure, and algorithm. Then we shall be able to develop a precise, formal characterization of computation which captures all of the modern aspects and concepts of this important activity.},
author = {Lewis, FD},
file = {:home/tomaton/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Lewis - 1996 - Essentials of Theoretical Computer Science.pdf:pdf},
journal = {University of Kentucky, Lexington, KY},
title = {{Essentials of Theoretical Computer Science}},
year = {1996}
}
@inproceedings{kulhanek2009,
author = {Kulh\'{a}nek, Tom\'{a}\v{s} and \v{S}\'{a}rek, Milan},
booktitle = {Proceedings of the 2009 Euro American Conference on Telematics and Information Systems New Opportunities to increase Digital Citizenship - EATIS '09},
doi = {10.1145/1551722.1551732},
isbn = {9781605583983},
organization = {ACM},
pages = {1--3},
title = {{Processing of medical images in virtual distributed environment}},
year = {2009}
}
@incollection{Raicu2012,
abstract = {Many-task computing aims to bridge the gap between two computing paradigms, high throughput computing and high performance computing. Many task computing denotes high-performance computations comprising multiple distinct activities, coupled via file system operations. The aggregate number of tasks, quantity of computing, and volumes of data may be extremely large. Traditional techniques to support many-task computing commonly found in scientific computing (i.e. the reliance on parallel file systems with static configurations) do not scale to today’s largest systems for data intensive application, as the rate of increase in the number of processors per system is outgrowing the rate of performance increase of parallel file systems. We argue that in such circumstances, data locality is critical to the successful and efficient use of large distributed systems for data-intensive applications. We propose a “data diffusion” approach to enable data- intensive many-task computing. Data diffusion acquires compute and storage resources dynamically, replicates data in response to demand, and schedules computations close to data, effectively harnessing data locality in application data access patterns. As demand increases, more resources are acquired, thus allowing faster response to subsequent requests that refer to the same data; when demand drops, resources are released. To explore the feasibility of data diffusion, we offer both a theoretical and empirical analysis. We define an abstract model for data diffusion, define and implement scheduling policies with heuristics that optimize real world performance, and develop a competitive online caching eviction policy. We also offer many empirical experiments to explore the benefits of data diffusion, both under static and dynamic resource provisioning. We show performance improvements of one to two orders of magnitude across three diverse workloads when compared to the performance of parallel file systems with throughputs approaching 80Gb/s on a modest cluster of 200 processors. We also compare data diffusion with a best model for active storage, contrasting the difference between a pull-model found in data diffusion and a push-model found in active storage, on up to 5832 processors. We conclude the chapter with performance results from a large scale astronomy application demonstrating that our approach improves both its performance and scalability.},
author = {Raicu, Ioan and Foster, Ian and Zhao, Yong and Al., Et},
booktitle = {Data intensive distributed computing / challenges and solutions for large scale information management},
pages = {28--73},
title = {{Towards Data Intensive Many-Task Computing}},
year = {2012}
}
@article{Barham2003,
abstract = {Numerous systems have been designed which use virtualization to subdivide the ample resources of a modern computer. Some require specialized hardware, or cannot support commodity operating systems. Some target 100\% binary compatibility at the expense of performance. Others sacrifice security or functionality for speed. Few offer resource isolation or performance guarantees; most provide only best-effort provisioning, risking denial of service.This paper presents Xen, an x86 virtual machine monitor which allows multiple commodity operating systems to share conventional hardware in a safe and resource managed fashion, but without sacrificing either performance or functionality. This is achieved by providing an idealized virtual machine abstraction to which operating systems such as Linux, BSD and Windows XP, can be ported with minimal effort.Our design is targeted at hosting up to 100 virtual machine instances simultaneously on a modern server. The virtualization approach taken by Xen is extremely efficient: we allow operating systems such as Linux and Windows XP to be hosted simultaneously for a negligible performance overhead --- at most a few percent compared with the unvirtualized case. We considerably outperform competing commercial and freely available solutions in a range of microbenchmarks and system-wide tests.},
author = {Barham, Paul and Dragovic, Boris and Fraser, Keir and Hand, Steven and Harris, Tim and Ho, Alex and Neugebauer, Rolf and Pratt, Ian and Warfield, Andrew},
doi = {10.1145/1165389.945462},
file = {:home/tomaton/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Barham et al. - 2003 - Xen and the art of virtualization.pdf:pdf},
isbn = {1-58113-757-5},
issn = {01635980},
journal = {ACM SIGOPS Operating Systems Review},
keywords = {hypervisors,paravirtualization,virtual machine monitors},
pages = {164},
pmid = {685953},
title = {{Xen and the Art of Virtualization}},
volume = {37},
year = {2003}
}
@book{Berman2003,
abstract = {From the Summary of the Book: This book, Grid Computing: Making the Global Infrastructure a Reality, [1] brings together many of the major projects that are driving and shaping an emerging global Grid. In the chapters of this book you will find the perspectives of a pioneering group of Grid developers, researchers and application scientists whose vision forms the present and provides a view into the future of Grid computing. Many of the chapters in this book provide definitions and characterizations of the Grid – peruse these and you will form your own view. Common to all perspectives is the notion that the Grid supports the integration of resources (computers, networks, data archives, instruments etc.). To build an integrated system, individuals and communities are working in coordination to ensure that the large and complex system of Grid software will be robust, useful, and provide an interoperable collection of services that support large-scale distributed computing and data management. Grids are intrinsically distributed and heterogeneous but must be viewed by the user (whether an individual or another computer) as a virtual environment with uniform access to resources. Much of Grid software technology addresses the issues of resource schedul- ing, quality of service, fault tolerance, decentralized control and security and so on, which enable the Grid to be perceived as a single virtual platform by the user. For example, Grid security technologies must ensure that a single sign-on will generate security credentials that can be used for the many different actions (potentially on multiple resources) that may be needed in a Grid session. For some researchers and developers, the Grid is viewed as the future of the Web or Internet computing. The Web largely consists of individuals talking independently to servers; the Grid provides a collection of servers and clients often work- ing collectively together to solve a problem. Computer-to-computer traffic is characteristic of Grids and both exploits and drives the increasing network backbone bandwidth. The term Grid was originally used in analogy to other infrastructure (such as electrical power) grids.We will see in this book that the analogy correctly characterizes some aspects of Grid Computing (ubiquity, for example), but not others (the performance variability of different resources that can support the same code, for example).},
doi = {10.1002/0470867167.ch21},
editor = {Berman, Fran and Fox, G and Hey, AJG},
file = {:home/tomaton/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Unknown - 2003 - Grid computing making the global infrastructure a reality.pdf:pdf},
isbn = {0471495166},
publisher = {Wiley},
title = {{Grid Computing - Making the Global Infrastructure a Reality}},
url = {http://eprints.soton.ac.uk/257695/},
year = {2003}
}
@article{LeNovere2006,
abstract = {BioModels Database (http://www.ebi.ac.uk/biomodels/), part of the international initiative BioModels.net, provides access to published, peer-reviewed, quantitative models of biochemical and cellular systems. Each model is carefully curated to verify that it corresponds to the reference publication and gives the proper numerical results. Curators also annotate the components of the models with terms from controlled vocabularies and links to other relevant data resources. This allows the users to search accurately for the models they need. The models can currently be retrieved in the SBML format, and import/export facilities are being developed to extend the spectrum of formats supported by the resource.},
author = {{Le Nov\`{e}re}, Nicolas and Bornstein, Benjamin and Broicher, Alexander and Courtot, M\'{e}lanie and Donizelli, Marco and Dharuri, Harish and Li, Lu and Sauro, Herbert and Schilstra, Maria and Shapiro, Bruce and Snoep, Jacky L and Hucka, Michael},
doi = {10.1093/nar/gkj092},
file = {:home/tomaton/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Le Nov\`{e}re et al. - 2006 - BioModels Database a free, centralized database of curated, published, quantitative kinetic models of biochem.pdf:pdf},
isbn = {1362-4962 (Electronic)$\backslash$r0305-1048 (Linking)},
issn = {1362-4962},
journal = {Nucleic acids research},
pages = {D689--D691},
pmid = {16381960},
title = {{BioModels Database: A Free, Centralized Database of Curated, Published, Quantitative Kinetic Models of Biochemical and Cellular Systems.}},
volume = {34},
year = {2006}
}
@article{Garey1979,
abstract = {This book's introduction features a humorous story of a man with a line of people behind him, who explains to his boss, "I can't find an efficient algorithm, but neither can all these famous people." This man illustrates an important quality of a class of problems, namely, the NP-complete problems: if you can prove that a problem is in this class, then it has no known polynomial-time solution that is guaranteed to work in general. This quality implies that the problem is difficult to deal with in practice. The focus of this book is to teach the reader how to identify, deal with, and understand the essence of NP-complete problems; Computers and Intractability does all of those things effectively. In a readable yet mathematically rigorous manner, the book covers topics such as how to prove that a given problem is NP-complete and how to cope with NP-complete problems. (There is even a chapter on advanced topics, with numerous references.) Computers and Intractability also contains a list of more than 300 problems-most of which are known to be NP-complete-with comments and references.},
author = {Garey, Michael R. and Johnson, David S.},
file = {:home/tomaton/Downloads/Theory Of Computation/Computers And Intractability A Guide To The Theory Of Np-Completeness - Michael Garey.djvu:djvu;:home/tomaton/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Garey, Johnson - 1979 - Computers and Intractability A Guide to the Theory of NP-Completeness (Series of Books in the Mathematical Sc(2).pdf:pdf},
isbn = {0716710455},
journal = {Computers and Intractability},
title = {{Computers and Intractability: A Guide to the Theory of NP-Completeness (Series of Books in the Mathematical Sciences)}},
year = {1979}
}
@article{Bahn2008,
abstract = {This paper presents several parallel FFT algorithms with different degree of communication overhead for multiprocessors in network-on-chip (NoC) environment. Three different methods of parallel FFT are presented. One is the reference parallel FFT for comparison, and the other two with well-distributed computation as well as reduced communication overhead. By evenly distributing parallel computation tasks which uses data locality, the execution time for completing each stage of FFT can be reduced. Moreover, by optimizing data exchanges we minimize the communication overhead. Depending on the communication regularity, one can select appropriate parallel FFT algorithm. By using the simulation results of our cycle-accurate SystemC NoC model with a parameterizable 2-D mesh architecture, and the performance analysis in time as well as complexity, our proposed algorithms are shown to outperform other parallel FFT algorithm or high-speed DSP implementations.},
author = {Bahn, Jun Ho and Yang, Jungsook and Bagherzadeh, Nader},
doi = {10.1109/ITNG.2008.55},
file = {:home/tomaton/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Bahn, Yang, Bagherzadeh - 2008 - Parallel FFT algorithms on network-on-chips.pdf:pdf},
isbn = {0769530990},
issn = {0218-1266},
journal = {Proceedings - International Conference on Information Technology: New Generations, ITNG 2008},
pages = {1087--1093},
title = {{Parallel FFT algorithms on network-on-chips}},
year = {2008}
}
@article{Perrey2003,
abstract = {This paper attempts a definition of service derived by unifying its usage in practice. In doing so it identifies participant's perspective as separate from actual different usages. Using this as an aid, the paper analyses the criteria applied in the use of service and considers how these can be aligned to derive commonality underlying the usage. Also included is a brief outline of the way in which a service-oriented architecture following such a model would affect the practice and process of developing large-scale, distributed software systems.},
author = {Perrey, R. and Lycett, M.},
doi = {10.1109/SAINTW.2003.1210138},
file = {:home/tomaton/Downloads/01210138.pdf:pdf},
isbn = {0-7695-1873-7},
journal = {2003 Symposium on Applications and the Internet Workshops, 2003. Proceedings.},
keywords = {Business,Computer architecture,Contracts,Creep,Information systems,Internet,Large-scale systems,Ontologies,Service oriented architecture,Software systems,Web services,business data processing,business services,large-scale distributed systems,organisation,service-oriented architecture,software engineering},
pages = {116--119},
title = {{Service-oriented architecture}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=1210138},
year = {2003}
}
@article{Tudor2008,
abstract = {Despite the continuous advances of the last years in grid computing, the grid computing programming paradigms are dominated by the message passing concept. There is little support for other paradigms such as shared data or associative programming. In this paper we analyze why previous attempts did not have a significant impact in the grid computing community. We start by assessing the landscape of grid programming solutions with a focus on shared data concepts. Next, we introduce an original idea to attack shared data programming on the grid by making use of both relaxed consistency models and user specified type consistency in an object oriented model.},
author = {Tudor, Dacian and Cretu, Vladimir},
doi = {10.1109/CISIS.2008.118},
file = {:home/tomaton/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Tudor, Cretu - 2008 - Experiences on grid shared data programming.pdf:pdf},
isbn = {0769531091},
issn = {1741-847X},
journal = {Proceedings - CISIS 2008: 2nd International Conference on Complex, Intelligent and Software Intensive Systems},
number = {2},
pages = {387--393},
title = {{Experiences on grid shared data programming}},
year = {2008}
}
@article{Sarkar2010,
abstract = {Biomedical informatics involves a core set of methodologies that can provide a foundation for crossing the "translational barriers" associated with translational medicine. To this end, the fundamental aspects of biomedical informatics (e.g., bioinformatics, imaging informatics, clinical informatics, and public health informatics) may be essential in helping improve the ability to bring basic research findings to the bedside, evaluate the efficacy of interventions across communities, and enable the assessment of the eventual impact of translational medicine innovations on health policies. Here, a brief description is provided for a selection of key biomedical informatics topics (Decision Support, Natural Language Processing, Standards, Information Retrieval, and Electronic Health Records) and their relevance to translational medicine. Based on contributions and advancements in each of these topic areas, the article proposes that biomedical informatics practitioners ("biomedical informaticians") can be essential members of translational medicine teams.},
author = {Sarkar, Indra Neil},
doi = {10.1186/1479-5876-8-22},
file = {:home/tomaton/Downloads/1479-5876-8-22.pdf:pdf},
isbn = {1479-5876 (Electronic)$\backslash$r1479-5876 (Linking)},
issn = {1479-5876},
journal = {Journal of translational medicine},
pages = {22},
pmid = {20187952},
title = {{Biomedical informatics and translational medicine.}},
volume = {8},
year = {2010}
}
@techreport{EGICompendium2013,
file = {:home/tomaton/Downloads/EGI-Compendium-2012.pdf:pdf},
institution = {EGI.eu},
number = {December 2012},
pages = {65--67},
title = {{The EGI Compendium of National Grid Infrastructures in Europe 2012 Edition}},
year = {2013}
}
@article{Matejak2014mj,
author = {Matej\'{a}k, Marek},
file = {:home/tomaton/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Matej\'{a}k - 2014 - Physiology in modelica.pdf:pdf},
journal = {MEFANET Journal},
number = {1},
pages = {10--14},
title = {{Physiology in modelica}},
url = {http://mj.mefanet.cz/mj-03140307},
volume = {2},
year = {2014}
}
@inproceedings{ruda2009virtual,
author = {Ruda, Miroslav and \v{S}ustr, Zden\v{e}k and Sitera, Jiř\'{\i} and Anto\v{s}, David and Hejtm\'{a}nek, Luk\'{a}\v{s} and Holub, Petr and Mula\v{c}, Milo\v{s}},
booktitle = {Cracow Grid Workshop’09},
file = {:home/tomaton/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Ruda et al. - 2009 - Virtual Clusters as a New Service of MetaCentrum, the Czech NGI.pdf:pdf},
pages = {66--71},
title = {{Virtual Clusters as a New Service of MetaCentrum, the Czech NGI}},
year = {2009}
}
@article{Leung2014,
author = {Leung, Kai Yan Eugene and van der Lijn, Fedde and Vrooman, Henri a. and Sturkenboom, Miriam C. J. M. and Niessen, Wiro J.},
doi = {10.1007/s12021-014-9240-7},
file = {:home/tomaton/Downloads/art\%3A10.1007\%2Fs12021-014-9240-7.pdf:pdf},
issn = {1539-2791},
journal = {Neuroinformatics},
keywords = {imaging,magnetic resonance,medical informatics,neuroimaging,radiology information systems},
pages = {65--81},
title = {{IT Infrastructure to Support the Secondary Use of Routinely Acquired Clinical Imaging Data for Research}},
url = {http://link.springer.com/10.1007/s12021-014-9240-7},
volume = {13},
year = {2014}
}
@article{Kofranek2010,
abstract = {We present the current state of complex circulatory dynamics model development based on Guyton's famous diagram. The aim is to provide an open-source model that will allow the simulation of a number of pathological conditions on a virtual patient including cardiac, respiratory, and kidney failure. The model will also simulate the therapeutic influence of various drugs, infusions of electrolytes, blood transfusion, etc. As a current result of implementation, we describe a core model of human physiology targeting the systemic circulation, arterial pressure and body fluid regulation, including short- and long-term regulations. The model can be used for educational purposes and general reflection on physiological regulation in pathogenesis of various diseases.},
author = {Kofr\'{a}nek, Jiř\'{\i} and Rusz, Jan},
file = {:home/tomaton/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Kofr\'{a}nek, Rusz - 2010 - Restoration of Guyton´s diagram for regulation of the circulation as a basis for quantitative physiological mo.pdf:pdf},
issn = {1802-9973},
journal = {Physiological research / Academia Scientiarum Bohemoslovaca},
keywords = {Blood Circulation,Blood Circulation: physiology,Blood Pressure,Blood Pressure: physiology,Body Fluids,Body Fluids: physiology,Cardiovascular,Computer Simulation,Humans,Models,Systems Biology},
month = jan,
number = {6},
pages = {897--908},
pmid = {20533860},
title = {{Restoration of Guyton´s Diagram for Regulation of the Circulation as a Basis For Quantitative Physiological Model Development.}},
volume = {59},
year = {2010}
}
@book{Holland1975,
abstract = {Genetic algorithms were developed initially by Holland et al. in the 1960s and 1970s!!! Genetic algorithms are playing an increasingly important role in studies of complex adaptive systems, ranging from adaptive agents in economic theory to the use of machine learning techniques in the design of complex devices such as aircraft turbines and integrated circuits. Adaptation in Natural and Artificial Systems is the book that initiated this field of study, presenting the theoretical foundations and exploring applications. In its most familiar form, adaptation is a biological process, whereby organisms evolve by rearranging genetic material to survive in environments confronting them. In this now classic work, Holland presents a mathematical model that allows for the nonlinearity of such complex interactions. He demonstrates the model's universality by applying it to economics, physiological psychology, game theory, and artificial intelligence and then outlines the way in which this approach modifies the traditional views of mathematical genetics. Initially applying his concepts to simply defined artificial systems with limited numbers of parameters, Holland goes on to explore their use in the study of a wide range of complex, naturally occuring processes, concentrating on systems having multiple factors that interact in nonlinear ways. Along the way he accounts for major effects of coadaptation and coevolution: the emergence of building blocks, or schemata, that are recombined and passed on to succeeding generations to provide, innovations and improvements. John H. Holland is Professor of Psychology and Professor of Electrical Engineering and Computer Science at the University of Michigan. He is also Maxwell Professor at the Santa Fe Institute and is Director of the University of Michigan/Santa Fe Institute Advanced Research Program.},
author = {Holland, John H},
booktitle = {Ann Arbor MI University of Michigan Press},
isbn = {0262581116},
issn = {10834419},
pages = {211},
pmid = {15369078},
title = {{Adaptation in Natural and Artificial Systems}},
url = {http://www.citeulike.org/group/664/article/400721},
volume = {Ann Arbor},
year = {1975}
}
@techreport{egi2014,
file = {:home/tomaton/Downloads/EGI-InSPIRE-D4.10-final.pdf:pdf},
institution = {EGI.eu},
title = {{Annual report of the EGI Production Infrastructure}},
year = {2014}
}
@article{Santamore1991,
abstract = {Because of close anatomic association, the pressure and volume in one ventricle can directly influence the pressure and volume in the opposite ventricle. To examine the importance of ventricular interdependence in controlling the circulation, we developed a computer model in which ventricular interdependence could be turned on and off. Left ventricular chamber contractility, as judged by maximal elastance (Emax), was enhanced on the order of 10\% as a result of ventricular interaction, whereas right ventricular Emax was affected by as much as 60\% under physiological conditions. With increases in systemic vascular resistance, ventricular interaction caused a smaller stroke volume (SV) decrease than with no interaction. For canine data (SV = 21.4 ml), doubling systemic vascular resistance decreased SV by 3.7 without ventricular interdependence, 3.5 with diastolic ventricular interdependence, and 3.3 ml with diastolic and systolic ventricular interdependence. In contrast, with increases in pulmonary vascular resistance, ventricular interaction caused a greater decrease in SV than with no interaction present. Decreasing left ventricular free wall elastance or right ventricular free wall elastance decreased SV. Diastolic ventricular interdependence reduced the SV changes, whereas systolic ventricular interdependence accentuated the SV changes with alterations in right and left ventricular free-wall elastance. The results of the present simulation demonstrate the importance of ventricular interdependence in the observed responses of the right ventricle to volume overload, pressure overload, and ischemia.},
author = {Santamore, W P and Burkhoff, D},
file = {:home/tomaton/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Santamore, Burkhoff - 1991 - Hemodynamic consequences of ventricular interaction as assessed by model analysis.pdf:pdf},
institution = {Philadelphia Heart Institute, Presbyterian Medical Center, Pennsylvania 19104.},
journal = {The American journal of physiology},
number = {1 Pt 2},
pages = {H146--H157},
pmid = {1992793},
title = {{Hemodynamic consequences of ventricular interaction as assessed by model analysis.}},
volume = {260},
year = {1991}
}
@article{Thomas2008,
abstract = {We present the current state of the development of the SAPHIR project (a Systems Approach for PHysiological Integration of Renal, cardiac and respiratory function). The aim is to provide an open-source multi-resolution modelling environment that will permit, at a practical level, a plug-and-play construction of integrated systems models using lumped-parameter components at the organ/tissue level while also allowing focus on cellular- or molecular-level detailed sub-models embedded in the larger core model. Thus, an in silico exploration of gene-to-organ-to-organism scenarios will be possible, while keeping computation time manageable. As a first prototype implementation in this environment, we describe a core model of human physiology targeting the short- and long-term regulation of blood pressure, body fluids and homeostasis of the major solutes. In tandem with the development of the core models, the project involves database implementation and ontology development.},
author = {Thomas, S Randall and Baconnier, Pierre and Fontecave, Julie and Fran\c{c}oise, Jean-Pierre and Guillaud, Fran\c{c}ois and Hannaert, Patrick and Hern\'{a}ndez, Alfredo and {Le Rolle}, Virginie and Mazi\`{e}re, Pierre and Tahi, Fariza and White, Ronald J},
doi = {10.1098/rsta.2008.0079},
file = {:home/tomaton/Downloads/3175.full(1).pdf:pdf},
isbn = {1364-503X (Print)$\backslash$n1364-503X (Linking)},
issn = {1364-503X},
journal = {Philosophical transactions. Series A, Mathematical, physical, and engineering sciences},
number = {June},
pages = {3175--3197},
pmid = {18565814},
title = {{SAPHIR: a physiome core model of body fluid homeostasis and blood pressure regulation.}},
volume = {366},
year = {2008}
}
@article{Barker2008,
abstract = {Workflow technologies are emerging as the dominant approach to coordinate groups of distributed services. However with a space filled with competing specifications, standards and frameworks from multiple domains, choosing the right tool for the job is not always a straightforward task. Researchers are often unaware of the range of technology that already exists and focus on implementing yet another proprietary workflow system. As an antidote to this common problem, this paper presents a concise survey of existing workflow technology from the business and scientific domain and makes a number of key suggestions towards the future development of scientific workflow systems.},
author = {Barker, Adam and {Van Hemert}, Jano},
doi = {10.1145/2213836.2213899},
file = {:home/tomaton/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Barker, Van Hemert - 2008 - Scientific Workflow A Survey and Research Directions.pdf:pdf},
isbn = {3-540-68105-1, 978-3-540-68105-2},
journal = {Proceedings of the 7th International Conference on Parallel Processing and Applied Mathematics},
pages = {746--753},
title = {{Scientific Workflow: A Survey and Research Directions}},
url = {http://dl.acm.org/citation.cfm?id=1786194.1786281},
year = {2008}
}
@article{Vandenberghe2006,
abstract = {The time-varying elastance theory of Suga et al. is widely used to simulate left ventricular function in mathematical models and in contemporary in vitro models. We investigated the validity of this theory in the presence of a left ventricular assist device. Left ventricular pressure and volume data are presented that demonstrate the heart-device interaction for a positive-displacement pump (Novacor) and a rotary blood pump (Medos). The Novacor was implanted in a calf and used in fixed-rate mode (85 BPM), whereas the Medos was used at several flow levels (0-3 l/min) in seven healthy sheep. The Novacor data display high beat-to-beat variations in the amplitude of the elastance curve, and the normalized curves deviate strongly from the typical bovine curve. The Medos data show how the maximum elastance depends on the pump flow level. We conclude that the original time-varying elastance theory insufficiently models the complex hemodynamic behavior of a left ventricle that is mechanically assisted, and that there is need for an updated ventricular model to simulate the heart-device interaction.},
author = {Vandenberghe, Stijn and Segers, Patrick and Steendijk, Paul and Meyns, Bart and Dion, Robert a E and Antaki, James F and Verdonck, Pascal},
doi = {10.1097/01.mat.0000196525.56523.b8},
file = {:home/tomaton/Downloads/Modeling\_Ventricular\_Function\_during\_Cardiac.2.pdf:pdf},
isbn = {0000196525},
issn = {1058-2916},
journal = {ASAIO journal (American Society for Artificial Internal Organs : 1992)},
number = {July 2005},
pages = {4--8},
pmid = {16436883},
title = {{Modeling ventricular function during cardiac assist: does time-varying elastance work?}},
volume = {52},
year = {2006}
}
@article{Martin-Sanchez2004,
abstract = {In this paper, we review the results of BIOINFOMED, a study funded by the European Commission (EC) with the purpose to analyse the different issues and challenges in the area where Medical Informatics and Bioinformatics meet. Traditionally, Medical Informatics has been focused on the intersection between computer science and clinical medicine, whereas Bioinformatics have been predominantly centered on the intersection between computer science and biological research. Although researchers from both areas have occasionally collaborated, their training, objectives and interests have been quite different. The results of the Human Genome and related projects have attracted the interest of many professionals, and introduced new challenges that will transform biomedical research and health care. A characteristic of the 'post genomic' era will be to correlate essential genotypic information with expressed phenotypic information. In this context, Biomedical Informatics (BMI) has emerged to describe the technology that brings both disciplines (BI and MI) together to support genomic medicine. In recognition of the dynamic nature of BMI, institutions such as the EC have launched several initiatives in support of a research agenda, including the BIOINFOMED study. © 2003 Elsevier Inc. All rights reserved.},
author = {Martin-Sanchez, F. and Iakovidis, I. and N\o rager, S. and Maojo, V. and {De Groen}, P. and {Van Der Lei}, J. and Jones, T. and Abraham-Fuchs, K. and Apweiler, R. and Babic, a. and Baud, R. and Breton, V. and Cinquin, P. and Doupi, P. and Dugas, M. and Eils, R. and Engelbrecht, R. and Ghazal, P. and Jehenson, P. and Kulikowski, C. and Lampe, K. and {De Moor}, G. and Orphanoudakis, S. and Rossing, N. and Sarachan, B. and Sousa, a. and Spekowius, G. and Thireos, G. and Zahlmann, G. and Zv\'{a}rov\'{a}, J. and Hermosilla, I. and Vicente, F. J.},
doi = {10.1016/j.jbi.2003.09.003},
file = {:home/tomaton/Downloads/1-s2.0-S1532046403000856-main.pdf:pdf},
isbn = {1532-0464},
issn = {15320464},
journal = {Journal of Biomedical Informatics},
keywords = {Bioinformatics,Biomedical Informatics,Genomic medicine,Genomics,Medical informatics},
pages = {30--42},
pmid = {15016384},
title = {{Synergy between medical informatics and bioinformatics: Facilitating genomic medicine for future health care}},
volume = {37},
year = {2004}
}
@misc{Foster1997,
abstract = {Emerging high-performance applications require the ability to exploit diverse, geographically distributed resources. These applications use high-speed networks to integrate supercomputers, large databases, archival storage devices, advanced visualization devices, and/or scientific instruments to form networked virtual supercomputers or metacomputers. While the physical infrastructure to build such systems is becoming widespread, the heterogeneous and dynamic nature of the metacomputing environment poses new challenges for developers of system software, parallel tools, and applications. In this article, we introduce Globus, a system that we are developing to address these challenges. The Globus system is intended to achieve a vertically integrated treatment of application, middleware, and network. A low-level toolkit provides basic mechanisms such as communication, authentication, network information, and data access. These mechanisms are used to construct various higher-level metacomputing services, such as parallel programming tools and schedulers. Our long-term goal is to build an Adaptive Wide Area Resource Environment (AWARE), an integrated set of higher-level services that enable applications to adapt to heterogeneous and dynamically changing metacomputing environments. Preliminary versions of Globus components were deployed successfully as part of the I-WAY networking experiment. 1},
author = {Foster, Ian and Kesselman, Carl},
booktitle = {International Journal of High Performance Computing Applications},
doi = {10.1177/109434209701100205},
issn = {1094-3420},
pages = {115--128},
title = {{Globus: a Metacomputing Infrastructure Toolkit}},
volume = {11},
year = {1997}
}
@inproceedings{Brugard2009,
author = {Brug\aa rd, Jan and Hedberg, Daniel and Cascante, Marta and Cedersund, Gunnar and G\'{o}mez-Garrido, \`{A}lex and Maier, Dieter and Nyman, Elin and Selivanov, Vitaly and Str\aa lfors, Peter and {Biomax Informatics}, A G},
booktitle = {7th International Modelica Conference, Como, Italy},
file = {:home/tomaton/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Brug\aa rd et al. - 2009 - Creating a Bridge between Modelica and the Systems Biology Community.pdf:pdf},
title = {{Creating a Bridge between Modelica and the Systems Biology Community}},
year = {2009}
}
@article{Westerhof1971,
author = {Westerhof, N and Elzinga, G and Sipkema, P},
journal = {Journal of Applied Physiology},
month = nov,
number = {5},
pages = {776--781},
title = {{An artificial arterial system for pumping hearts.}},
url = {http://jap.physiology.org/content/31/5/776.abstract},
volume = {31},
year = {1971}
}
@article{Hoimyr2012,
author = {H\o imyr, N and Blomer, J and Buncic, P and Giovannozzi, M and Gonzalez, A and Harutyunyan, A and Jones, P L and Karneyeu, A and Marquina, M a and Mcintosh, E and Segal, B and Skands, P and Grey, F and {Lombra\~{n}a Gonz\'{a}lez}, D and Zacharov, I},
doi = {10.1088/1742-6596/396/3/032057},
file = {:home/tomaton/Downloads/1742-6596\_396\_3\_032057.pdf:pdf},
issn = {1742-6588},
journal = {Journal of Physics: Conference Series},
month = dec,
number = {3},
pages = {032057},
title = {{BOINC Service for Volunteer Cloud Computing}},
volume = {396},
year = {2012}
}
@article{AlvesDaSilva2007,
author = {{Alves Da Silva}, Alexandre P. and Falc\~{a}o, Djalma M.},
doi = {10.1002/9780470225868.ch2},
file = {:home/tomaton/Downloads/5396781.pdf:pdf},
isbn = {9780471457114},
journal = {Modern Heuristic Optimization Techniques: Theory and Applications to Power Systems},
keywords = {Character-based and real-valued encodings,Problem-specific operators definition,Thermal unit commitment},
pages = {25--42},
title = {{Fundamentals of Genetic Algorithms}},
year = {2007}
}
@inproceedings{Tribula2013,
author = {Tribula, Martin and Je\v{z}ek, Filip and Privitzer, Pavol and Kofr\'{a}nek, Jiř\'{\i} and Kolman, Josef},
booktitle = {sborn\'{\i}k př\'{\i}sp\v{e}vků MEDSOFT},
file = {:home/tomaton/Downloads/Medsoft\_2013\_Tribula.pdf:pdf},
pages = {197--204},
title = {{Webov\'{y} v\'{y}ukov\'{y} simul\'{a}tor krevn\'{\i}ho ob\v{e}hu}},
year = {2013}
}
@book{Rich2008,
author = {Rich, Elaine},
isbn = {9780132288064},
publisher = {Prentice-Hal},
title = {{Automata, Computability and Complexity}},
year = {2008}
}
@inproceedings{Blockwitz2012,
author = {Blockwitz, Torsten and Otter, Martin and Akesson, Johan and Arnold, Martin and Clau�, Christoph and Elmqvist, Hilding and Friedrich, Markus and Junghanns, Andreas and Mauss, Jakob and Neumerkel, Dietmar and Olsson, Hans and Viel, Antoine},
booktitle = {Proceedings of the 9 th International Modelica Conference},
doi = {10.3384/ecp12076173},
file = {:home/tomaton/Downloads/dymola/dymola-2014.2.orig/opt/dymola/documentation/Functional Mockup Interface 2.0 The Standard for Tool independent Exchange of Simulation Models - Modelica 2012.pdf:pdf},
keywords = {change,co-simulation,fmi,fmu,func-,functional mockup interface,model ex-,simulation,tional mockup unit},
month = nov,
pages = {173--184},
title = {{Functional Mockup Interface 2.0: The Standard for Tool independent Exchange of Simulation Models}},
url = {http://www.ep.liu.se/ecp\_article/index.en.aspx?issue=76;article=17},
year = {2012}
}
@article{Suga1980,
author = {Suga, H and Sagawa, K and Demer, L},
doi = {10.1161/01.RES.46.2.256},
file = {:home/tomaton/Downloads/Circulation Research-1980-Suga-256-63.pdf:pdf},
issn = {0009-7330},
journal = {Circulation research},
pages = {256--263},
pmid = {7351043},
title = {{Determinants of instantaneous pressure in canine left ventricle. Time and volume specification.}},
volume = {46},
year = {1980}
}
@article{Cooley1965,
author = {Cooley, JW and Tukey, JW},
file = {:home/tomaton/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Cooley, Tukey - 1965 - An algorithm for the machine calculation of complex Fourier series.pdf:pdf},
journal = {Mathematics of computation},
pages = {297--301},
title = {{An Algorithm for the Machine Calculation of Complex Fourier Series}},
url = {http://www.jstor.org/stable/2003354},
year = {1965}
}
@book{Ashlock2005,
author = {Ashlock, D. and Ashlock, D.},
booktitle = {Guelph, Ontario: Springer},
file = {:home/tomaton/Downloads/Evolutionary computation for modeling and optimization.pdf:pdf},
isbn = {9780387221960},
pages = {571},
title = {{Evolutionary Computation for Modeling and Optimization}},
year = {2005}
}
@article{Milojicic2011,
address = {Los Alamitos, CA, USA},
author = {Milojicic, Dejan and Llorente, Ignacio M and Montero, Ruben S},
doi = {10.1109/MIC.2011.44},
issn = {1089-7801},
journal = {IEEE Internet Computing},
number = {2},
pages = {11--14},
publisher = {IEEE Computer Society},
title = {{OpenNebula: A Cloud Management Tool}},
volume = {15},
year = {2011}
}
@phdthesis{Cantu-Paz1999,
author = {Cantu-Paz, Erick},
file = {:home/tomaton/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Cantu-Paz - 1999 - Designing efficient and accurate parallel genetic algorithms.pdf:pdf},
school = {University of Illinois at Urbana-Champaign},
title = {{Designing Efficient and Accurate Parallel Genetic Algorithms}},
year = {1999}
}
@inproceedings{Kofranek2012,
author = {Kofr\'{a}nek, Jiř\'{\i} and Pecinovsk\'{y}, Rudolf and Nov\'{a}k, Petr},
booktitle = {International Conference Foundations of Computer Science},
file = {:home/tomaton/Downloads/Kopenograms\_Graphical\_Language\_for\_Structured\_Algorithms.pdf:pdf},
keywords = {algorithmic,algorithms,education,for writing data structures,graphical language,on describing how those,programmiong methodology,therefore in our contribution,uml,we shall focus only},
pages = {90--96},
title = {{Kopenograms – Graphical Language for Structured Algorithms}},
year = {2012}
}
@book{suetens2009,
author = {Suetens, Paul},
publisher = {Cambridge University Press},
title = {{Fundamentals of medical imaging}},
year = {2009}
}
@article{Bassingthwaighte2009,
abstract = {The Physiome Project, exemplified by the Cardiac Physiome, is now 10 years old. In this article, we review past progress and future challenges in developing a quantitative framework for understanding human physiology that incorporates both genetic inheritance and environmental influence. Despite the enormity of the challenge, which is certainly greater than that facing the pioneers of the human genome project 20 years ago, there is reason for optimism that real and accelerating progress is being made.},
author = {Bassingthwaighte, James and Hunter, Peter and Noble, Denis},
doi = {10.1113/expphysiol.2008.044099},
file = {:home/tomaton/Downloads/document(5).pdf:pdf},
isbn = {1469-445X (Electronic)$\backslash$n0958-0670 (Linking)},
issn = {1469-445X},
journal = {Experimental physiology},
number = {5},
pages = {597--605},
pmid = {19098089},
title = {{The Cardiac Physiome: perspectives for the future.}},
volume = {94},
year = {2009}
}
@article{Kacsuk2012,
abstract = {The WS-PGRADE/gUSE generic DCI gateway framework has been developed to support a large variety of user communities. It provides a generic purpose, workflow-oriented graphical user interface to create and run workflows on various DCIs including clusters, Grids, desktop Grids and clouds. The framework can be used by NGIs to support small user communities who cannot afford to develop their own customized science gateway. The WS-PGRADE/gUSE framework also provides two API interfaces (Application Specific Module API and Remote API) to create application-specific science gateways according to the needs of different user communities. The paper describes in detail the workflow concept of WS-PGRADE, the DCI Bridge service that enables access to most of the popular European DCIs and the Application Specific Module and Remote API concepts to generate application-specific science gateways.},
author = {Kacsuk, Peter and Farkas, Zoltan and Kozlovszky, Miklos and Hermann, Gabor and Balasko, Akos and Karoczkai, Krisztian and Marton, Istvan},
doi = {10.1007/s10723-012-9240-5},
file = {:home/tomaton/Downloads/art\%3A10.1007\%2Fs10723-012-9240-5.pdf:pdf},
isbn = {1570-7873},
issn = {15707873},
journal = {Journal of Grid Computing},
keywords = {Customized interface,Distributed computing infrastructures,Science gateway,Workflow},
pages = {601--630},
title = {{WS-PGRADE/gUSE Generic DCI Gateway Framework for a Large Variety of User Communities}},
volume = {10},
year = {2012}
}
@article{Beard2005,
author = {Beard, Daniel a and Bassingthwaighte, James B and Greene, Andrew S},
doi = {10.1152/physiolgenomics.00117.2005},
file = {:home/tomaton/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Beard, Bassingthwaighte, Greene - 2005 - Computational modeling of physiological systems.pdf:pdf},
issn = {1531-2267},
journal = {Physiological genomics},
pages = {1--3},
pmid = {16179418},
title = {{Computational Modeling of Physiological Systems}},
volume = {23},
year = {2005}
}
@book{Erl2008,
author = {Erl, Thomas},
publisher = {Prentice Hall},
title = {{SOA Principles of Service Design}},
year = {2008}
}
@inproceedings{Blochwitza,
author = {Blochwitz, T and Otter, M and Arnold, M and Bausch, C},
booktitle = {Proceeding of 8th Modelica Conference, Dresden},
file = {:home/tomaton/Downloads/otter2011-FMI-ecp11063013.pdf:pdf},
title = {{The Functional Mockup Interface for Tool Independent Exchange of Simulation Models}},
year = {2011}
}
@article{Armbrust2010,
author = {Armbrust, Michael and Stoica, Ion and Zaharia, Matei and Fox, Armando and Griffith, Rean and Joseph, Anthony D. and Katz, Randy and Konwinski, Andy and Lee, Gunho and Patterson, David and Rabkin, Ariel},
doi = {10.1145/1721654.1721672},
file = {:home/tomaton/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Armbrust et al. - 2010 - A view of cloud computing.pdf:pdf},
issn = {00010782},
journal = {Communications of the ACM},
month = apr,
number = {4},
pages = {50--58},
title = {{A view of cloud computing}},
volume = {53},
year = {2010}
}
@article{Zatloukal2012,
author = {Zatloukal, Vladim\'{\i}r and Ro\v{c}ek, Ale\v{s}},
file = {:home/tomaton/Downloads/DNMAT-15.pdf:pdf},
isbn = {9781618041180},
journal = {Advances in Data Networks, Communications, Computers and Materials},
pages = {104--108},
title = {{Secure medical multimedia DICOM data transfers over Internet 1}},
year = {2012}
}
@phdthesis{Raicu2009,
author = {Raicu, Ioan},
file = {:home/tomaton/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Raicu - 2009 - Many-task computing bridging the gap between high-throughput computing and high-performance computing.pdf:pdf},
number = {March},
title = {{Many-task Computing: Bridging the Gap between High-throughput Computing and High-performance Computing}},
year = {2009}
}
@article{Tiller2008,
author = {Tiller, Michael M},
file = {:home/tomaton/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Tiller - 2008 - Patterns and Anti-Patterns in Modelica.pdf:pdf},
journal = {Proceedings Modelica 2008 Conference},
keywords = {anti-patterns,patterns},
pages = {647--655},
title = {{Patterns and Anti-Patterns in Modelica}},
year = {2008}
}
@misc{epacs2014,
title = {{ePACS}},
url = {http://www.epacs.cz}
}
@article{FernandezdeCanete2014,
abstract = {A mathematical model that provides an overall description of both the short- and long-term mechanisms of arterial pressure regulation is presented. Short-term control is exerted through the baroreceptor reflex while renal elimination plays a role in long-term control. Both mechanisms operate in an integrated way over the compartmental model of the cardiovascular system. The whole system was modelled in MODELICA, which uses a hierarchical object-oriented modelling strategy, under the DYMOLA simulation environment. The performance of the controlled system was analysed by simulation in light of the existing hypothesis and validation tests previously performed with physiological data, demonstrating the effectiveness of both regulation mechanisms under physiological and pathological conditions.},
author = {{Fernandez de Canete}, J and Luque, J and Barbancho, J and Munoz, V},
doi = {10.1016/j.compbiomed.2014.01.006},
file = {:home/tomaton/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Fernandez de Canete et al. - 2014 - Modelling of long-term and short-term mechanisms of arterial pressure control in the cardiovascul(2).pdf:pdf},
issn = {1879-0534},
journal = {Computers in Biology and Medicine},
month = apr,
pages = {104--112},
pmid = {24561348},
title = {{Modelling of Long-term and Short-term Mechanisms of Arterial Pressure Control in the Cardiovascular System: An Object-oriented Approach}},
volume = {47},
year = {2014}
}
@article{FernandezDeCanete2013,
abstract = {The modeling of physiological systems via mathematical equations reflects the calculation procedure more than the structure of the real system modeled, with the simulation environment SIMULINK™ being one of the best suited to this strategy. Nevertheless, object-oriented modeling is spreading in current simulation environments through the use of the individual components of the model and its interconnections to define the underlying dynamic equations. In this paper we describe the use of the SIMSCAPE™ simulation environment in the object-oriented modeling of the closed loop cardiovascular system. The described approach represents a valuable tool in the teaching of physiology for graduate medical students.},
author = {{Fernandez de Canete}, Javier and del Saz-Orozco, P and Moreno-Boza, D and Duran-Venegas, E},
doi = {10.1016/j.compbiomed.2013.01.007},
file = {:home/tomaton/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Ferandez de Canete et al. - 2013 - Object-oriented modeling and simulation of the closed loop cardiovascular system by using SIMSCAPE.pdf:pdf},
issn = {1879-0534},
journal = {Computers in biology and medicine},
keywords = {Algorithms,Cardiology,Cardiology: instrumentation,Cardiology: methods,Cardiovascular System,Computer Simulation,Computer-Assisted,Humans,Left,Left: physiology,Models,Respiration,Right,Right: physiology,Signal Processing,Theoretical,User-Computer Interface,Ventricular Function},
month = may,
number = {4},
pages = {323--33},
title = {{Object-oriented Modeling and Simulation of the Closed Loop Cardiovascular System by Using SIMSCAPE.}},
volume = {43},
year = {2013}
}
@article{Zhao2008,
abstract = {With the advances in e-Sciences and the growing complexity of scientific analyses, more and more scientists and researchers are relying on workflow systems for process coordination, derivation automation, provenance tracking, and bookkeeping. While workflow systems have been in use for decades, it is unclear whether scientific workflows can or even should build on existing workflow technologies, or they require fundamentally new approaches. In this paper, we analyze the status and challenges of scientific workflows, investigate both existing technologies and emerging languages, platforms and systems, and identify the key challenges that must be addressed by workflow systems for e-science in the 21st century.},
archivePrefix = {arXiv},
arxivId = {0808.3545},
author = {Zhao, Yong and Raicu, Ioan and Foster, Ian},
eprint = {0808.3545},
file = {:home/tomaton/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Zhao, Raicu, Foster - 2008 - Scientific workflow systems for 21st century, new bottle or new wine.pdf:pdf},
journal = {IEEE Congress on Services - Part I, 2008.},
pages = {467 -- 471},
title = {{Scientific Workflow Systems for 21st Century e-Science, New Bottle or New Wine?}},
year = {2008}
}
@article{Letchford2012,
author = {Letchford, Adam},
doi = {10.1007/978-3-642-16729-4},
file = {:home/tomaton/Downloads/9783642167287-c1.pdf:pdf},
isbn = {978-3-642-16728-7},
keywords = {HB Economic Theory},
pages = {17--41},
title = {{Review of “The Linear Ordering Problem: Exact and Heuristic Methods in Combinatorial Optimization”}},
url = {http://eprints.lancs.ac.uk/55579/},
year = {2012}
}
@article{Beberg2009,
abstract = {Accurate simulation of biophysical processes requires vast computing resources. Folding@home is a distributed computing system first released in 2000 to provide such resources needed to simulate protein folding and other biomolecular phenomena. Now operating in the range of 5 PetaFLOPS sustained, it provides more computing power than can typically be gathered and operated locally due to cost, physical space, and electrical/cooling load. This paper describes the architecture and operation of Folding@home, along with some lessons learned over the lifetime of the project.},
author = {Beberg, Adam L. and Ensign, Daniel L. and Jayachandran, Guha and Khaliq, Siraj and Pande, Vijay S.},
doi = {10.1109/IPDPS.2009.5160922},
file = {:home/tomaton/Downloads/05160922.pdf:pdf},
isbn = {9781424437504},
issn = {1530-2075},
journal = {IPDPS 2009 - Proceedings of the 2009 IEEE International Parallel and Distributed Processing Symposium},
title = {{Folding@home: Lessons from eight years of volunteer distributed computing}},
year = {2009}
}
@article{Pruett2013,
author = {Pruett, William A and Husband, Leland D and Husband, Graham and Dakhlalla, Muhammad and Bellamy, Kyle and Coleman, Thomas G and Hester, Robert L},
file = {:home/tomaton/Downloads/journal.pone.0074329.pdf:pdf},
isbn = {1932-6203},
journal = {PloS one},
number = {9},
pages = {e74329},
title = {{A Population Model of Integrative Cardiovascular Physiology}},
volume = {8},
year = {2013}
}
@misc{Maojo2003,
abstract = {In this report, the authors compare and contrast medical informatics (MI) and bioinformatics (BI) and provide a viewpoint on their complementarities and potential for collaboration in various subfields. The authors compare MI and BI along several dimensions, including: (1) historical development of the disciplines, (2) their scientific foundations, (3) data quality and analysis, (4) integration of knowledge and databases, (5) informatics tools to support practice, (6) informatics methods to support research (signal processing, imaging and vision, and computational modeling, (7) professional and patient continuing education, and (8) education and training. It is pointed out that, while the two disciplines differ in their histories, scientific foundations, and methodologic approaches to research in various areas, they nevertheless share methods and tools, which provides a basis for exchange of experience in their different applications. MI expertise in developing health care applications and the strength of BI in biological "discovery science" complement each other well. The new field of biomedical informatics (BMI) holds great promise for developing informatics methods that will be crucial in the development of genomic medicine. The future of BMI will be influenced strongly by whether significant advances in clinical practice and biomedical research come about from separate efforts in MI and BI, or from emerging, hybrid informatics subdisciplines at their interface.},
author = {Maojo, Victor and Kulikowski, Casimir A.},
booktitle = {Journal of the American Medical Informatics Association},
doi = {10.1197/jamia.M1305},
file = {:home/tomaton/Downloads/515.pdf:pdf},
isbn = {1067-5027},
issn = {10675027},
number = {6},
pages = {515--522},
pmid = {12925552},
title = {{Bioinformatics and Medical Informatics: Collaborations on the Road to Genomic Medicine?}},
volume = {10},
year = {2003}
}
@article{Helton2006,
abstract = {Sampling-based methods for uncertainty and sensitivity analysis are reviewed. The following topics are considered: (i) definition of probability distributions to characterize epistemic uncertainty in analysis inputs, (ii) generation of samples from uncertain analysis inputs, (iii) propagation of sampled inputs through an analysis, (iv) presentation of uncertainty analysis results, and (v) determination of sensitivity analysis results. Special attention is given to the determination of sensitivity analysis results, with brief descriptions and illustrations given for the following procedures/techniques: examination of scatterplots, correlation analysis, regression analysis, partial correlation analysis, rank transformations, statistical tests for patterns based on gridding, entropy tests for patterns based on gridding, nonparametric regression analysis, squared rank differences/rank correlation coefficient test, two-dimensional Kolmogorov-Smirnov test, tests for patterns based on distance measures, top down coefficient of concordance, and variance decomposition. ?? 2005 Elsevier Ltd. All rights reserved.},
author = {Helton, J. C. and Johnson, J. D. and Sallaberry, C. J. and Storlie, C. B.},
doi = {10.1016/j.ress.2005.11.017},
file = {:home/tomaton/Downloads/1-s2.0-S0951832005002292-main.pdf:pdf},
isbn = {0951-8320},
issn = {09518320},
journal = {Reliability Engineering and System Safety},
keywords = {Aleatory uncertainty,Epistemic uncertainty,Latin hypercube sampling,Monte Carlo,Sensitivity analysis,Uncertainty analysis},
pages = {1175--1209},
title = {{Survey of Sampling-based Methods for Uncertainty and Sensitivity Analysis}},
volume = {91},
year = {2006}
}
@article{Kulhanek2010,
author = {Kulh\'{a}nek, Tom\'{a}\v{s} and \v{S}ilar, J and Matej\'{a}k, Marek and Privitzer, Pavol and Kofranek, Jiř\'{\i} and Tribula, Martin},
journal = {Proceedings of VPH Conference},
title = {{Distributed Computation and Parameter Estimation in Identification of Physiological Systems}},
year = {2010}
}
@article{VanHoudt2012,
abstract = {Nicolaides Baraitser syndrome heterozygous SMARCA2 ...},
author = {{Van Houdt}, Jeroen K J and Nowakowska, Beata Anna and Sousa, S\'{e}rgio B and van Schaik, Barbera D C and Seuntjens, Eve and Avonce, Nelson and Sifrim, Alejandro and Abdul-Rahman, Omar a and van den Boogaard, Marie-Jos\'{e} H and Bottani, Armand and Castori, Marco and Cormier-Daire, Val\'{e}rie and Deardorff, Matthew a and Filges, Isabel and Fryer, Alan and Fryns, Jean-Pierre and Gana, Simone and Garavelli, Livia and Gillessen-Kaesbach, Gabriele and Hall, Bryan D and Horn, Denise and Huylebroeck, Danny and Klapecki, Jakub and Krajewska-Walasek, Malgorzata and Kuechler, Alma and Lines, Matthew a and Maas, Saskia and MacDermot, Kay D and McKee, Shane and Magee, Alex and de Man, Stella a and Moreau, Yves and Morice-Picard, Fanny and Obersztyn, Ewa and Pilch, Jacek and Rosser, Elizabeth and Shannon, Nora and Stolte-Dijkstra, Irene and {Van Dijck}, Patrick and Vilain, Catheline and Vogels, Annick and Wakeling, Emma and Wieczorek, Dagmar and Wilson, Louise and Zuffardi, Orsetta and van Kampen, Antoine H C and Devriendt, Koenraad and Hennekam, Raoul and Vermeesch, Joris Robert},
doi = {10.1038/ng.1105},
file = {:home/tomaton/Downloads/document.pdf:pdf},
isbn = {1546-1718 (Electronic)$\backslash$n1061-4036 (Linking)},
issn = {1061-4036},
journal = {Nature Genetics},
number = {4},
pages = {445--449},
pmid = {22366787},
title = {{Heterozygous missense mutations in SMARCA2 cause Nicolaides-Baraitser syndrome}},
volume = {44},
year = {2012}
}
@article{Hucka2003,
author = {Hucka, M. and Finney, A. and Sauro, H. M. and Bolouri, H. and Doyle, J. C. and Kitano, H. and Arkin, a. P. and Bornstein, B. J. and Bray, D. and Cornish-Bowden, A. and Cuellar, a. a. and Dronov, S. and Gilles, E. D. and Ginkel, M. and Gor, V. and Goryanin, I. I. and Hedley, W. J. and Hodgman, T. C. and Hofmeyr, J.-H. and Hunter, P. J. and Juty, N. S. and Kasberger, J. L. and Kremling, A. and Kummer, U. and {Le Novere}, N. and Loew, L. M. and Lucio, D. and Mendes, P. and Minch, E. and Mjolsness, E. D. and Nakayama, Y. and Nelson, M. R. and Nielsen, P. F. and Sakurada, T. and Schaff, J. C. and Shapiro, B. E. and Shimizu, T. S. and Spence, H. D. and Stelling, J. and Takahashi, K. and Tomita, M. and Wagner, J. and Wang, J.},
doi = {10.1093/bioinformatics/btg015},
file = {:home/tomaton/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Hucka et al. - 2003 - The systems biology markup language (SBML) a medium for representation and exchange of biochemical network models.pdf:pdf},
issn = {1367-4803},
journal = {Bioinformatics},
month = mar,
number = {4},
pages = {524--531},
title = {{The Systems Biology Markup Language (SBML): A Medium for Representation and Exchange of Biochemical Network Models}},
volume = {19},
year = {2003}
}
@article{Yu2011,
abstract = {MOTIVATION: The Physiome Model Repository 2 (PMR2) software was created as part of the IUPS Physiome Project (Hunter and Borg, 2003), and today it serves as the foundation for the CellML model repository. Key advantages brought to the end user by PMR2 include: facilities for model exchange, enhanced collaboration and a detailed change history for each model. AVAILABILITY: PMR2 is available under an open source license at http://www.cellml.org/tools/pmr/; a fully functional instance of this software can be accessed at http://models.physiomeproject.org/.},
author = {Yu, Tommy and Lloyd, Catherine M and Nickerson, David P and Cooling, Michael T and Miller, Andrew K and Garny, Alan and Terkildsen, Jonna R and Lawson, James and Britten, Randall D and Hunter, Peter J and Nielsen, Poul M F},
doi = {10.1093/bioinformatics/btq723},
issn = {1367-4811},
journal = {Bioinformatics (Oxford, England)},
keywords = {Biological,Computational Biology,Computational Biology: methods,Databases,Factual,Internet,Models,Software},
number = {5},
pages = {743--744},
pmid = {21216774},
title = {{The Physiome Model Repository 2.}},
volume = {27},
year = {2011}
}
@inproceedings{Amdahl1967,
author = {Amdahl, Gene M.},
booktitle = {Proceedings of AFIPS Conference},
file = {:home/tomaton/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Amdahl - 1967 - Validity of the single processor approach to achieving large scale computing capabilities.pdf:pdf},
pages = {483--485},
title = {{Validity of the Single Processor Approach to Achieving Large Scale Computing Capabilities}},
year = {1967}
}
@article{Cunsolo2009,
abstract = {Only commercial cloud solutions have been implemented so far, offering computing resources and services for renting. Some interesting projects, such as Nimbus, OpenNEbula, Reservoir, work on cloud. One of their aims is to provide a cloud infrastructure able to provide and share resources and services for scientific purposes. The encouraging results of volunteer computing projects in this context and the flexibility of the cloud, suggested to address our research efforts towards a combined new computing paradigm we named Cloud@Home.On one hand it can be considered as a generalization of the @homephilosophy, knocking down the barriers of volunteer computing, and also allowing to share more general services. On the other hand, Cloud@Home can be considered as the enhancement of the grid-utility vision of cloud computing. In this new paradigm, userspsila hosts are not passive interface to cloud services anymore, but they can interact (free or by charge) with other clouds. In this paper we present the Cloud@Home paradigm, highlighting its contribution to the actual state of the art on the topic of distributed and cloud computing. We detail the functional architecture and the core structure implementing such paradigm, demonstrating how it is really possible to build up a Cloud@Home infrastructure.},
author = {Cunsolo, Vincenzo D. and Distefano, Salvatore and Puliafito, Antonio and Scarpa, Marco},
doi = {10.1109/NCA.2009.41},
file = {:home/tomaton/Downloads/05190364.pdf:pdf},
isbn = {9780769536989},
journal = {Proceedings - 2009 8th IEEE International Symposium on Network Computing and Applications, NCA 2009},
pages = {134--139},
title = {{Volunteer computing and desktop cloud: The cloud @ home paradigm}},
year = {2009}
}
@article{Kumar2014,
author = {Kumar, R and Gupta, N and Charu, S and Jain, K and Jangir, SK},
file = {:home/tomaton/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Kumar et al. - 2014 - Open Source Solution for Cloud Computing Platform Using OpenStack.pdf:pdf},
keywords = {cloud computing,eucalyptus,icehouse,open nebula,openstack},
number = {5},
pages = {89--98},
title = {{Open Source Solution for Cloud Computing Platform Using OpenStack}},
url = {http://www.ijcsmc.com/docs/papers/May2014/V3I5201427.pdf},
volume = {3},
year = {2014}
}
@article{fielding2000chapter,
author = {Fielding, Roy Thomas},
institution = {University of California},
journal = {Architectural Styles and the Design of Network-based Software Architectures, Dissertation},
title = {{Chapter 5: Representational State Transfer (REST)}},
year = {2000}
}
@article{Kofranek2008,
author = {Kofr\'{a}nek, Jiř\'{\i} and Matej\'{a}k, Marek and Privitzer, Pavol and Tribula, Martin},
journal = {Technical Computing Prague},
pages = {1--16},
title = {{Causal or acausal modeling: labour for humans or labour for machines}},
year = {2008}
}
@article{Anjum2012,
author = {Anjum, Ashiq and Hill, Richard and McClatchey, Richard and Bessis, Nik and Branson, Andrew},
doi = {10.1504/IJWGS.2012.049169},
file = {:home/tomaton/Downloads/Glueing\%20Grids\%20and\%20Clouds\%20Together.pdf:pdf},
journal = {International Journal of Web and Grid Services},
number = {3},
pages = {248--265},
title = {{Glueing Grids and Clouds Together: a Service-oriented Approach}},
volume = {8},
year = {2012}
}
@article{Chervenak2000,
author = {Chervenak, A and Foster, I and Kesselman, C and Salisbury, C and Tuecke, S},
file = {:home/tomaton/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Chervenak et al. - 2000 - The data grid Towards an architecture for the distributed management and analysis of large scientific datasets.pdf:pdf},
journal = {Journal of Network and Computer Applications},
number = {3},
pages = {187--200},
publisher = {Elsevier},
title = {{The Data Grid: Towards an Architecture for the Distributed Management and Analysis of Large Scientific Datasets}},
volume = {23},
year = {2000}
}
@article{Leaver-fay2014,
author = {Leaver-fay, Andrew and Tyka, Michael and Lewis, Steven M and Lange, Oliver F and Jacak, Ron and Kaufman, Kristian and Renfrew, P Douglas and Smith, Colin a and Davis, Ian W and Cooper, Seth and Treuille, Adrien and Mandell, Daniel J and Ban, Yih-en Andrew and Fleishman, Sarel J and Corn, Jacob E and Kim, David E},
doi = {10.1016/B978-0-12-381270-4.00019-6.R},
file = {:home/tomaton/Downloads/nihms-350681.pdf:pdf},
isbn = {9780123812704},
title = {{R 3: An Object-Oriented Software Suite for the Simulation and Design of Macromolecules}},
year = {2014}
}
@article{Wilkins-Diehr2007,
author = {Wilkins-Diehr, Nancy},
doi = {10.1002/cpe.1098},
file = {:home/tomaton/Downloads/1098\_ftp.pdf:pdf},
issn = {15320626},
journal = {Concurrency and Computation: Practice and Experience},
month = apr,
number = {6},
pages = {743--749},
title = {{Special Issue: Science Gateways—Common Community Interfaces to Grid Resources}},
url = {http://doi.wiley.com/10.1002/cpe.1098},
volume = {19},
year = {2007}
}
@incollection{Riedel2009,
author = {Riedel, M and Laure, E and Field, L and Navarro, J P and Casey, J and Litmaath, M and Koblitz, B and Catlett, C and Skow, D and Zheng, C and Papadopoulos, P M and Katz, M and Sharma, N and Smirnova, O and Arzberger, P and Rana, A S and Martin, T and Wan, M and Welch, V and Rimovsky, T and Newhouse, S and Vanni, A and Tanaka, Y and Tanimura, Y and Ikegami, T and Abramson, D and Enticott, C and Jenkins, G and Pordes, R and Timm, S and Moont, G and Aggarwal, M and Colling, D and Aa, O Van Der and Sim, A and Natarajan, V and Shoshani, A and Gu, J and Chen, S and Galang, G and Zappi, R and Magnoni, L and Ciaschini, V and Pace, M and Venturi, V and Marzolla, M and Andreetto, P and Cowles, B and Wang, S and Saeki, Y and Sato, H and Matsuoka, S and Uthayopas, P and Sriprayoonsakul, S and Koeroo, O and Viljoen, M and Pearlman, L and Pickles, S and Wallom, David and Moloney, G and Lauret, J and Marsteller, J and Sheldon, P and Pathak, S and Witt, S De and Jensen, J and Hodges, M and Ross, D and Phatanapherom, S and Netzer, G and Gregersen, A R and Jones, M and Kacsuk, P and Streit, A and Mallmann, D and Wolf, F and Huedo, E and Geddes, N},
booktitle = {Concurrency and Computation: Practice and Experience 21.8},
doi = {10.1002/cpe},
file = {:home/tomaton/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Riedel et al. - 2009 - Interoperation of world-wide production e-Science infrastructures.pdf:pdf},
number = {March},
pages = {961--990},
title = {{Interoperation of World-wide Production e-Science Infrastructures}},
year = {2009}
}
@article{Gyenge2003,
abstract = {This study is concerned with the formulation of a 'kidney module' linked to the plasma compartment of a larger mathematical model previously developed. Combined, these models can be used to predict, amongst other things, fluid and small ion excretion rates by the kidney; information that should prove useful in evaluating values and trends related to whole-body fluid balance for different clinical conditions to establish fluid administration protocols and for educational purposes. The renal module assumes first-order, negative-feedback responses of the kidney to changes in plasma volume and/or plasma sodium content from their normal physiological set points. Direct hormonal influences are not explicitly formulated in this empiric model. The model also considers that the renal excretion rates of small ions other than sodium are proportional to the excretion rate of sodium. As part of the model development two aspects are emphasized (1): the estimation of parameters related to the renal elimination of fluid and small ions, and (2) model validation via comparisons between the model predictions and selected experimental data. For validation, model predictions of the renal dynamics are compared with new experimental data for two cases: plasma overload resulting from external fluid infusion (e.g. infusions of iso-osmolar solutions and/or hypertonic/hyperoncotic saline solutions), and untreated hypo volemic conditions that result from the external loss of blood. The present study demonstrates that the empiric kidney module presented above can provide good short-term predictions with respect to all renal outputs considered here. Physiological implications of the model are also presented.},
author = {Gyenge, Christina C and Bowen, Bruce D and Reed, Rolf K and Bert, Joel L},
file = {:home/tomaton/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Gyenge et al. - 2003 - Mathematical model of renal elimination of fluid and small ions during hyper- and hypovolemic conditions.pdf:pdf},
issn = {0001-5172},
journal = {Acta anaesthesiologica Scandinavica},
keywords = {Algorithms,Animals,Blood Volume,Blood Volume: physiology,Chlorides,Chlorides: urine,Hemorrhage,Hemorrhage: physiopathology,Hypovolemia,Hypovolemia: physiopathology,Ions,Ions: urine,Kidney,Kidney: metabolism,Kidney: physiology,Least-Squares Analysis,Models, Biological,Models, Statistical,Osmolar Concentration,Potassium,Potassium: urine,Reproducibility of Results,Saline Solution, Hypertonic,Sodium,Sodium: urine,Swine,Urodynamics,Urodynamics: physiology},
month = feb,
number = {2},
pages = {122--37},
pmid = {12631040},
title = {{Mathematical model of renal elimination of fluid and small ions during hyper- and hypovolemic conditions.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/12631040},
volume = {47},
year = {2003}
}
@misc{dicom2011,
title = {{DICOM Standard 2011}},
url = {https://dabsoft.ch/dicom/index.html},
year = {2011}
}
@article{Frigo2005,
author = {Frigo, M. and Johnson, S.G.},
doi = {10.1109/JPROC.2004.840301},
file = {:home/tomaton/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Frigo, Johnson - 2005 - The Design and Implementation of FFTW3.pdf:pdf},
issn = {0018-9219},
journal = {Proceedings of the IEEE},
number = {2},
pages = {216--231},
title = {{The Design and Implementation of FFTW3}},
volume = {93},
year = {2005}
}
@incollection{Kuba2007a,
author = {Kuba, Martin and Kouřil, Daniel and Proch\'{a}zka, Michal},
booktitle = {Towards Next Generation Grids},
doi = {10.1007/978-0-387-72498-0\_8},
editor = {Priol, Thierry and Vanneschi, Marco},
file = {:home/tomaton/Downloads/chp\%3A10.1007\%2F978-0-387-72498-0\_8.pdf:pdf},
pages = {83--91},
publisher = {Springer US},
title = {{Sealed Grid with Downloadable Services}},
year = {2007}
}
@article{Allcock2005,
abstract = {The GridFTP extensions to the File Transfer Protocol define a general-purpose mechanism for secure, reliable, high-performance data movement. We report here on the Globus striped GridFTP framework, a set of client and server libraries designed to support the construction of data-intensive tools and applications. We describe the design of both this framework and a striped GridFTP server constructed within the framework. We show that this server is faster than other FTP servers in both single-process and striped configurations, achieving, for example, speeds of 27.3 Gbit/s memory-to-memory and 17 Gbit/s disk-to-disk over a 60 millisecond round trip time, 30 Gbit/s network. In another experiment, we show that the server can support 1800 concurrent clients without excessive load. We argue that this combination of performance and modular structure make the Globus GridFTP framework both a good foundation on which to build tools and applications, and a unique testbed for the study of innovative data management techniques and network protocols.},
author = {Allcock, William and Bresnahan, John and Kettimuthu, Rajkumar and Link, Michael and Dumitrescu, Catalin and Raicu, Ioan and Foster, Ian},
doi = {10.1109/SC.2005.72},
file = {:home/tomaton/Documents/27580054.pdf:pdf},
isbn = {1595930612},
journal = {Proceedings of the ACM/IEEE 2005 Supercomputing Conference, SC'05},
number = {c},
pages = {1--11},
title = {{The Globus Striped GridFTP Framework and Server}},
volume = {2005},
year = {2005}
}
@article{Vines2014,
abstract = {Policies ensuring that research data are available on public archives are increasingly being implemented at the government [1], funding agency [2-4], and journal [5, 6] level. These policies are predicated on the idea that authors are poor stewards of their data, particularly over the long term [7], and indeed many studies have found that authors are often unable or unwilling to share their data [8-11]. However, there are no systematic estimates of how the availability of research data changes with time since publication. We therefore requested data sets from a relatively homogenous set of 516 articles published between 2 and 22 years ago, and found that availability of the data was strongly affected by article age. For papers where the authors gave the status of their data, the odds of a data set being extant fell by 17\% per year. In addition, the odds that we could find a working e-mail address for the first, last, or corresponding author fell by 7\% per year. Our results reinforce the notion that, in the long term, research data cannot be reliably preserved by individual researchers, and further demonstrate the urgent need for policies mandating data sharing via public archives. © 2014 Elsevier Ltd.},
archivePrefix = {arXiv},
arxivId = {1312.5670},
author = {Vines, Timothy H. and Albert, Arianne Y K and Andrew, Rose L. and D\'{e}barre, Florence and Bock, Dan G. and Franklin, Michelle T. and Gilbert, Kimberly J. and Moore, Jean S\'{e}bastien and Renaut, S\'{e}bastien and Rennison, Diana J.},
doi = {10.1016/j.cub.2013.11.014},
eprint = {1312.5670},
file = {:home/tomaton/Downloads/1-s2.0-S0960982213014000-main.pdf:pdf},
isbn = {0960-9822},
issn = {09609822},
journal = {Current Biology},
pages = {94--97},
pmid = {24361065},
title = {{The Availability of Research Data Declines Rapidly with Article Age}},
volume = {24},
year = {2014}
}
@misc{Kofranek2014a,
author = {Kofr\'{a}nek, Jiř\'{\i} and Privitzer, Pavol and Tribula, Martin and \v{S}ilar, Jan and Kulh\'{a}nek, Tom\'{a}\v{s} and Matej\'{a}k, Marek and Je\v{z}ek, Filip},
publisher = {Charles University in Prague, Com-Sys Trade s.r.o., Creative Connections s.r.o.},
title = {{Virtual Patient Simulator, CZ Utility model. Application number: 2014-30329. Issue number: 27613}},
url = {http://isdv.upv.cz/portal/pls/portal/portlets.pts.det?xprim=10082946},
year = {2014}
}
@article{Pearl1987,
author = {Pearl, Judea and Korf, Richard E.},
doi = {10.1146/annurev.cs.02.060187.002315},
file = {:home/tomaton/Downloads/annurev\%2Ecs\%2E02\%2E060187\%2E002315.pdf:pdf},
issn = {8756-7016},
journal = {Annual Review of Computer Science},
pages = {451--467},
title = {{Search Techniques}},
volume = {2},
year = {1987}
}
@article{Saliba2012,
abstract = {PURPOSE: Innovative technologies to deliver health care across borders have attracted both evangelists and sceptics. Our aim was to systematically identify factors that hinder or support implementation of cross-border telemedicine services worldwide in the last two decades. METHODS: Two reviewers independently searched ten databases including MEDLINE and EMBASE, in June 2011 including citations from 1990 onwards when at least an abstract was available in English. We also searched ELDIS and INTUTE databases and Internet search engines to identify grey literature. We included studies which (a) described the use of telemedicine to deliver cross-border healthcare and, or (b) described the factors that hinder or support implementation of cross-border telemedicine services. All study designs were included. Two reviewers independently assessed titles and abstracts of articles identified. Papers were allocated to one of four reviewers who extracted relevant data and validated it. We took a qualitative approach to the analysis, conducting a narrative synthesis of the evidence. RESULTS: 6026 records were identified of which 5806 were excluded following screening of titles and abstracts. We assessed 227 full text articles, excluding 133 because they were fatally flawed or did not meet the inclusion criteria, producing a final sample of 94. They involved 76 countries worldwide, most involving collaborations between high and low or middle income countries. Most described services delivering a combination of types of telemedicine but specialties most represented were telepathology, telesurgery, Emergency and trauma telemedicine and teleradiology. Most link health professionals, with only a few linking professionals directly to patients. A main driver for the development of cross-border telemedicine is the need to improve access to specialist services in low and middle income countries and in underserved rural areas in high income countries. Factors that hinder or support implementation clustered into four main themes: (1) legal factors; (2) sustainability factors; (3) cultural factors; and (4) contextual factors. CONCLUSIONS: National telemedicine programmes may build infrastructure and change mindsets, laying the foundations for successful engagement in cross-border services. Regional networks can also help with sharing of expertise and innovative ways of overcoming barriers to the implementation of services. Strong team leadership, training, flexible and locally responsive services delivered at low cost, using simple technologies, and within a clear legal and regulatory framework, are all important factors for the successful implementation of cross-border telemedicine services.},
author = {Saliba, Vanessa and Legido-Quigley, Helena and Hallik, Riina and Aaviksoo, Ain and Car, Josip and McKee, Martin},
doi = {10.1016/j.ijmedinf.2012.08.003},
file = {:home/tomaton/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Saliba et al. - 2012 - Telemedicine across borders a systematic review of factors that hinder or support implementation.pdf:pdf},
issn = {1872-8243},
journal = {International journal of medical informatics},
keywords = {Culture,Humans,International Cooperation,Leadership,Neoplasms,Neoplasms: prevention \& control,Telemedicine,Telemedicine: legislation \& jurisprudence,Telemedicine: utilization},
month = dec,
number = {12},
pages = {793--809},
pmid = {22975018},
title = {{Telemedicine Across Borders: A Systematic Review of Factors That Hinder or Support Implementation.}},
volume = {81},
year = {2012}
}
@inproceedings{fritzson2002,
author = {Fritzson, Peter and Bunus, Peter},
booktitle = {Simulation Symposium, 2002. Proceedings. 35th Annual},
organization = {IEEE},
pages = {365--380},
title = {{Modelica -- A General Object-oriented Language for Continuous and Discrete-event System Modeling and Simulation}},
year = {2002}
}
@inproceedings{Kofranek2011f,
author = {Kofr\'{a}nek, Jiř\'{\i} and Matej\'{a}k, Marek and Je\v{z}ek, Filip and Privitzer, Pavol and \v{S}ilar, Jan},
booktitle = {sborn\'{\i}k př\'{\i}sp\v{e}vků MEDSOFT},
file = {:home/tomaton/Downloads/Medsoft\_2011\_Kofranek\_Jan\_2.pdf:pdf},
pages = {106--121},
title = {{V\'{Y}UKOV\'{Y} WEBOV\'{Y} SIMUL\'{A}TOR KREVN\'{I}HO OB\v{E}HU}},
year = {2011}
}
@article{Marozzo2011,
abstract = {Data mining techniques are used in many application areas to extract useful knowledge from large datasets. Very often, parameter sweeping is used in data mining applications to explore the effects produced on the data analysis result by different values of the algorithm parameters. Parameter sweeping applications can be highly computing demanding, since the number of single tasks to be executed increases with the number of swept parameters and the range of their values. Cloud technologies can be effectively exploited to provide end-users with the computing and storage resources, and the execution mechanisms needed to efficiently run this class of applications. In this paper, we present a Data Mining Cloud App framework that supports the execution of parameter sweeping data mining applications on a Cloud. The framework has been implemented using the Windows Azure platform, and evaluated through a set of parameter sweeping clustering and classification applications. The experimental results demonstrate the effectiveness of the proposed framework, as well as the scalability that can be achieved through the parallel execution of parameter sweeping applications on a pool of virtual servers.},
author = {Marozzo, Fabrizio and Talia, Domenico and Trunfio, Paolo},
doi = {10.1109/CloudCom.2011.56},
file = {:home/tomaton/Downloads/06133165.pdf:pdf},
isbn = {9780769546223},
journal = {Proceedings - 2011 3rd IEEE International Conference on Cloud Computing Technology and Science, CloudCom 2011},
keywords = {Cloud computing,Data mining,Parameter sweeping},
pages = {367--374},
title = {{A cloud framework for parameter sweeping data mining applications}},
year = {2011}
}
@article{Avanzolini1988,
abstract = {A pulsatile simulator of the closed-loop cardiovascular system, designed to solve simulation, identification and control problems in a research and education context, is presented. Its implimentation makes use of a command-driven interactive program for simulation of non-linear ordinary differential equations. The flexibility of the simulator is demonstrated by the results presented which refer to a basal steady-state circulatory condition as well as a transient induced by an abrupt change in peripheral resistance.},
author = {Avanzolini, Guido and Barbini, Paolo and Cappello, Angelo and Cevenini, Gabriele},
doi = {10.1016/0020-7101(88)90006-2},
issn = {00207101},
journal = {International Journal of Bio-Medical Computing},
keywords = {Cardiac assist devices,Cardiovascular system,Interactive simulation,Pulsatile model,Simulation language},
month = jan,
number = {1},
pages = {39--49},
title = {{CADCS simulation of the closed-loop cardiovascular system}},
url = {http://www.sciencedirect.com/science/article/pii/0020710188900062},
volume = {22},
year = {1988}
}
@article{Javornik2011,
author = {Javornik, Michal and Dostal, Otto and Slavicek, Karel},
file = {:home/tomaton/Downloads/Regional-Medical-Imaging-System.pdf:pdf},
keywords = {dicom,integration,medical,medical education},
number = {7},
pages = {374--378},
title = {{Regional Medical Imaging System}},
volume = {5},
year = {2011}
}
@incollection{Guyton2006,
abstract = {For this 11th edition of a classic text, Guyton and Hall, both affiliated with the Department of Physiology and Biophysics at the University of Mississippi Medical Center, have added a full-color design incorporating 800 figures, including ECGs, charts, graphs, and new line drawings. Features retained from the previous editions include short chapters, reference tables, discussion of the relationship between pathophysiology and clinical medicine, and the application of core concepts to clinical examples and real-life situations. Brandon/Hill suggested the 10th edition of the text for both initial purchase and as a part of the small medical library's core collection. Annotation : 2005 Book News, Inc., Portland, OR (booknews.com)},
author = {Guyton, Arthur Clifton and Hall, John E.},
booktitle = {Textbook of medical physiology},
chapter = {9},
isbn = {072168677X},
pages = {107},
publisher = {Elsevier Saunders},
title = {{Heart Muscle; The Heart as a Pump and Function of the Heart Valves}},
year = {2006}
}
@article{Krefting2010,
abstract = {In this paper, we describe the grid integration of medical image processing applications as grid workflows. The workflow management system is able to execute all tasks related to grid communication, such as authorization, scheduling and monitoring. It remains to the developer to make the code accessible for the workflow manager, and to define, what to do with it. Coarse-grained parallelization of processing steps for runtime reduction can easily be realized. We describe the procedure how to port the code to the grid and show exemplarily the integration of segmentation and registration algorithms for transrectal ultrasound guided prostate biopsies. ?? 2009 Elsevier B.V. All rights reserved.},
author = {Krefting, Dagmar and Vossberg, Michal and Hoheisel, Andreas and Tolxdorff, Thomas},
doi = {10.1016/j.future.2009.07.004},
file = {:home/tomaton/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Krefting et al. - 2010 - Simplified implementation of medical image processing algorithms into a grid using a workflow management system.pdf:pdf},
issn = {0167739X},
journal = {Future Generation Computer Systems},
keywords = {Healthgrids,Image processing software,Workflow management},
number = {4},
pages = {681--684},
publisher = {Elsevier B.V.},
title = {{Simplified Implementation of Medical Image Processing Algorithms into a Grid Using a Workflow Management System}},
volume = {26},
year = {2010}
}
@article{Weinhardt2009,
abstract = {The article describes a technical classification of Grid and Cloud Computing for a profound discussion on the business opportunities of the Cloud Computing paradigm. For this purpose, we present a framework for business models in Clouds. With the help of this framework business models can be placed at infrastructure, platform or application level. Subsequently, we discuss currently existing Cloud services which are integrated into the framework as well as categorized according to their pricing model and service type. Finally, the paper discusses challenges that have to be mastered in order to make the Cloud vision come true, such as the development of a Cloud API, the pricing of complex services, as well as security and reliability.},
author = {Weinhardt, Christof and Anandasivam, Arun and Blau, Benjamin and Borissov, Nikolay and Meinl, Thomas and Michalk, Wibke and St\"{o}\ss er, Jochen},
doi = {10.1007/s12599-009-0071-2},
file = {:home/tomaton/Downloads/art\%3A10.1007\%2Fs12599-009-0071-2.pdf:pdf},
isbn = {1867-0202},
issn = {1867-0202},
journal = {Business \& Information Systems Engineering},
pages = {391--399},
title = {{Cloud Computing – A Classification, Business Models, and Research Directions}},
volume = {1},
year = {2009}
}
@article{Gotshall2000,
abstract = {We conduct experiments to determine the optimum population size for problems as the instance size varies. We show that increasing the population size increases the accuracy of the GA. Increasing population size also causes the number of generations to converge to increase. The optimal population for a given problem is the point of inflection where the benefit of quick convergence is offset by increasing inaccuracy. Finally, we propose a method that might be used for determining the optimum population size for a given problem instance. This method holds for all three of the dissimilar problems that were used to conduct the experiment. It seems possible that it may hold for all GA applicable problems.},
author = {Gotshall, Stanley and Rylander, Bart},
file = {:home/tomaton/Downloads/10.1.1.105.2431.pdf:pdf},
journal = {Proceedings On Genetic And Evolutionary Computation Conference},
keywords = {Evolutionary Computation,Genetic Algorithm,Optimization,Population},
title = {{Optimal population size and the genetic algorithm}},
year = {2000}
}
@article{Olabarriaga2010,
abstract = {This paper presents the design, implementation, and usage of a virtual laboratory for medical image analysis. It is fully based on the Dutch grid, which is part of the Enabling Grids for E-sciencE (EGEE) production infrastructure and driven by the gLite middleware. The adopted service-oriented architecture enables decoupling the user-friendly clients running on the user's workstation from the complexity of the grid applications and infrastructure. Data are stored on grid resources and can be browsed/viewed interactively by the user with the Virtual Resource Browser (VBrowser). Data analysis pipelines are described as Scufl workflows and enacted on the grid infrastructure transparently using the MOTEUR workflow management system. VBrowser plug-ins allow for easy experiment monitoring and error detection. Because of the strict compliance to the grid authentication model, all operations are performed on behalf of the user, ensuring basic security and facilitating collaboration across organizations. The system has been operational and in daily use for eight months (December 2008), with six users, leading to the submission of 9000 jobs/month in average and the production of several terabytes of data.},
author = {Olabarriaga, S\'{\i}lvia D and Glatard, Tristan and de Boer, Piter T},
doi = {10.1109/TITB.2010.2046742},
file = {:home/tomaton/Downloads/05443468.pdf:pdf},
issn = {1558-0032},
journal = {IEEE transactions on information technology in biomedicine : a publication of the IEEE Engineering in Medicine and Biology Society},
number = {4},
pages = {979--985},
pmid = {20371412},
title = {{A virtual laboratory for medical image analysis.}},
volume = {14},
year = {2010}
}
@article{Hofmann2005,
author = {Hofmann, M.},
doi = {10.1177/154851290500200405},
file = {:home/tomaton/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Hofmann - 2005 - On the Complexity of Parameter Calibration in Simulation Models.pdf:pdf},
issn = {1548-5129},
journal = {The Journal of Defense Modeling and Simulation: Applications, Methodology, Technology},
keywords = {1,already,complexity theory,computer science,existing model to a,if system data,introduction,military applications,model calibration,model calibration is the,or,reference system,task of adjusting an,validation methodology},
month = oct,
number = {4},
pages = {217--226},
title = {{On the Complexity of Parameter Calibration in Simulation Models}},
volume = {2},
year = {2005}
}
@article{Kuba2006,
abstract = {Today, applications for Grids emerge in various scientific fields, each with specific requirements. We present concept and architecture which enables biomedical experts to collaborate and share resources by encapsulating their knowledge and expertise as grid services, with (semi-)formally described semantics. Grid Services allow machine processing of the encapsulated knowledge, while their semantic description provides means for their automated discovery and interaction. This brings new possibilities of building biomedical systems offering machine-driven assistance to the biomedical experts.},
author = {Kuba, Martin and Kraj\'{\i}cek, Ondrej and Lesn\'{y}, Petr and Vejvalka, Jan and Holecek, Tom\'{a}s},
file = {:home/tomaton/Downloads/fulltext.pdf:pdf},
issn = {0926-9630},
journal = {Studies in health technology and informatics},
pages = {273--282},
pmid = {16823145},
title = {{Grid Empowered Sharing of Medical Expertise.}},
volume = {120},
year = {2006}
}
@article{Takahashi2013,
abstract = {This paper describes the application of Model Based approach for constructing the simulator for the cardiovascular system. Each organ composing the cardiovascular system is modeled based on the previously suggested electrical circuit approach and the entire simulator is implemented by using MATLAB / Simulink. This simulator makes it possible to estimate parameters of the cardiovascular system as an inverse-problem solving approach. The experimental results showed that the parameters were precisely estimated. These results also indicate the possibility of the application of Model Based approach to the coupled simulation in the medical engineering filed.},
author = {Takahashi, Shuji and Sakawa, Kenta and Shiraishi, Yoichi and Miyashita, Hiroshi and Technology, Science},
file = {:home/tomaton/Downloads/06736195.pdf:pdf},
keywords = {Arterial System,Blood,Blood flow,Cardiovascular System,Heart,Integrated circuit modeling,Inverse-problem,Mathematical model,Medical Engineering,Model,Simulation,arterial system,cardiovascular system,inverse-problem,medical engineering,model,simulation},
pages = {493--500},
shorttitle = {SICE Annual Conference (SICE), 2013 Proceedings of},
title = {{Modeling, Simulation and Parameter Estimation of the Cardiovascular System by Using Model Based Approach}},
year = {2013}
}
@article{Foster2008,
author = {Foster, Ian and Zhao, Yong and Raicu, Ioan and Lu, Shiyong},
doi = {10.1109/GCE.2008.4738445},
file = {:home/tomaton/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Foster et al. - 2008 - Cloud computing and grid computing 360-degree compared.pdf:pdf},
journal = {Grid Computing Environments \ldots},
title = {{Cloud Computing and Grid Computing 360-degree Compared}},
year = {2008}
}
@article{Barga2011,
abstract = {Extending the capabilities of desktop and mobile applications through on-demand cloud, data-driven services will significantly broaden the research community's capabilities, accelerating the pace of engineering and scientific discovery. The net effect will be the democratization of research capabilities that are now available only to the most elite scientists.},
author = {Barga, Roger and Gannon, Dennis and Reed, Daniel},
doi = {10.1109/MIC.2011.20},
file = {:home/tomaton/Downloads/05676168.pdf:pdf},
isbn = {1089-7801},
issn = {10897801},
journal = {IEEE Internet Computing},
keywords = {Internet,MapReduce,cloud computing,data analytics,datacenters,scientific research},
pages = {72--75},
title = {{The client and the cloud: Democratizing research computing}},
volume = {15},
year = {2011}
}
@inproceedings{Kulhanek2014,
author = {Kulh\'{a}nek, Tom\'{a}\v{s} and Matej\'{a}k, Marek and \v{S}ilar, Jan and Kofr\'{a}nek, Jiř\'{\i}},
booktitle = {sborn\'{\i}k př\'{\i}sp\v{e}vků MEDSOFT},
pages = {148--153},
title = {{Identifikace fyziologick\'{y}ch syst\'{e}mů}},
url = {http://www.creativeconnections.cz/medsoft/2014/Medsoft\_2014\_Kulhanek.pdf},
year = {2014}
}
@article{Burkhoff1993,
abstract = {One of the most important consequences of acute left ventricular dysfunction (LVD) is pulmonary edema resulting from a rise in pulmonary venous pressure (PVP). It is generally believed that the PVP rise is a direct hemodynamic consequence of LVD. While this paradigm seems plausible, especially if the LV is viewed as a sump pump, there is no specific evidence to support this simple explanation. A theoretical analysis was performed to assess the hemodynamic mechanisms responsible for the dramatic rise in PVP after acute LVD. The ventricles were modeled as time-varying elastances; pulmonary and systemic vascular systems were modeled as series of resistive and capacitive elements. In response to a 50\% decrease in LV contractile strength [end-systolic elastance (Ees)], cardiac output (CO) and mean arterial pressure (MAP) dropped substantially, while PVP increased minimally from its baseline of 12 to approximately 15 mmHg. With LV Ees set at 50\% of normal, the effects of sympathetic activation were tested. When heart rate and total peripheral resistance were increased, CO and MAP improved, yet PVP still did not rise. The only intervention that caused a substantial increase in PVP was to simulate the decrease in unstressed volume (VU) of the venous system known to occur with sympathetic activation. When VU was decreased by about 15-20\% (comparable to experimentally observed shifts with acute heart failure), PVP increased above 25 mmHg. The effects of pericardial constraints were investigated, and the results suggest a major role of this organ in determining the overall hemodynamic response to acute LVD, sympathetic activation, and explaining the responses to therapy. Thus this analysis suggests that elevations of PVP do not occur simply as a direct hemodynamic consequence of acute LVD. Rather, changes in PVP may be dictated more by sympathetic control on venous capacity. If confirmed, recognition of this as a primary mechanism may prove important in directing development of new therapies and in understanding the mechanisms of disease progression in heart failure.},
author = {Burkhoff, D and Tyberg, J V},
file = {:home/tomaton/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Burkhoff, Tyberg - 1993 - Why does pulmonary venous pressure rise after onset of LV dysfunction a theoretical analysis.pdf:pdf},
institution = {Department of Medicine, Columbia Presbyterian Hospital, New York, New York 10032.},
isbn = {0002-9513 (Print)$\backslash$r0002-9513 (Linking)},
issn = {0002-9513},
journal = {The American journal of physiology},
number = {5 Pt 2},
pages = {H1819--H1828},
pmid = {8238596},
title = {{Why does pulmonary venous pressure rise after onset of LV dysfunction: a theoretical analysis.}},
volume = {265},
year = {1993}
}
@misc{harvi2013,
title = {{Harvi - interactive simulation-based digital textbook of cardiovascular physiology and hemodynamics}},
url = {http://www.pvloops.com}
}
@article{Moles2003,
author = {Moles, Carmen G and Mendes, Pedro and Banga, Julio R},
doi = {10.1101/gr.1262503.},
file = {:home/tomaton/Downloads/0132467.pdf:pdf},
journal = {Genome Research},
pages = {2467--2474},
title = {{Parameter Estimation in Biochemical Pathways: A Comparison of Global Optimization Methods}},
year = {2003}
}
@article{Feron2013,
author = {Feron, Hwa and Lehmann, Axel and Hofmann, Marko},
doi = {10.1109/WSC.2013.6721651},
file = {:home/tomaton/Downloads/p2807-feron.pdf:pdf},
isbn = {978-1-4799-3950-3},
journal = {2013 Winter Simulations Conference (WSC)},
keywords = {WSC 2012},
month = dec,
pages = {2807--2818},
publisher = {Ieee},
title = {{Challenges of and criteria for validating a physiology model within a TCCC serious game}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=6721651},
year = {2013}
}
@article{hester2011,
abstract = {Mathematical models and simulations are important tools in discovering key causal relationships governing physiological processes. Simulations guide and improve outcomes of medical interventions involving complex physiology. We developed HumMod, a Windows-based model of integrative human physiology. HumMod consists of 5000 variables describing cardiovascular, respiratory, renal, neural, endocrine, skeletal muscle, and metabolic physiology. The model is constructed from empirical data obtained from peer-reviewed physiological literature. All model details, including variables, parameters, and quantitative relationships, are described in Extensible Markup Language (XML) files. The executable (HumMod.exe) parses the XML and displays the results of the physiological simulations. The XML description of physiology in HumMod's modeling environment allows investigators to add detailed descriptions of human physiology to test new concepts. Additional or revised XML content is parsed and incorporated into the model. The model accurately predicts both qualitative and quantitative changes in clinical and experimental responses. The model is useful in understanding proposed physiological mechanisms and physiological interactions that are not evident, allowing one to observe higher level emergent properties of the complex physiological systems. HumMod has many uses, for instance, analysis of renal control of blood pressure, central role of the liver in creating and maintaining insulin resistance, and mechanisms causing orthostatic hypotension in astronauts. Users simulate different physiological and pathophysiological situations by interactively altering numerical parameters and viewing time-dependent responses. HumMod provides a modeling environment to understand the complex interactions of integrative physiology. HumMod can be downloaded at http://hummod.org.},
author = {Hester, Robert L and Brown, Alison J and Husband, Leland and Iliescu, Radu and Pruett, Drew and Summers, Richard and Coleman, Thomas G},
doi = {10.3389/fphys.2011.00012},
file = {:home/tomaton/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Hester et al. - 2011 - HumMod A Modeling Environment for the Simulation of Integrative Human Physiology(2).pdf:pdf},
issn = {1664-042X},
journal = {Frontiers in physiology},
keywords = {hummod,integrative physiology,model,physiome},
month = jan,
number = {April},
pages = {12},
pmid = {21647209},
publisher = {Frontiers Media SA},
title = {{HumMod: A Modeling Environment for the Simulation of Integrative Human Physiology}},
volume = {2},
year = {2011}
}
@inproceedings{Cook1971,
abstract = {It is shown that any recognition problem solved by a polynomial time-bounded nondeterministic Turing machine can be “reduced” to the problem of determining whether a given propositional formula is a tautology. Here “reduced” means, roughly speaking, that the first problem can be solved deterministically in polynomial time provided an oracle is available for solving the second. From this notion of reducible, polynomial degrees of difficulty are defined, and it is shown that the problem of determining tautologyhood has the same polynomial degree as the problem of determining whether the first of two given graphs is isomorphic to a subgraph of the second. Other examples are discussed. A method of measuring the complexity of proof procedures for the predicate calculus is introduced and discussed.},
author = {Cook, Stephen A.},
booktitle = {STOC '71 Proceedings of the third annual ACM symposium on Theory of computing},
doi = {10.1145/800157.805047},
issn = {08985626},
pages = {151--158},
title = {{The Complexity of Theorem-Proving Procedures}},
year = {1971}
}
@article{Kulhanek2014mefanet,
author = {Kulh\'{a}nek, Tom\'{a}\v{s} and Tribula, Martin and Kofr\'{a}nek, Jiř\'{\i} and Matej\'{a}k, Marek},
file = {:home/tomaton/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Kulh\'{a}nek et al. - 2014 - Simple models of the cardiovascular system for educational and research purposes.pdf:pdf},
isbn = {1805-9171},
journal = {MEFANET Journal},
number = {2},
pages = {56--63},
title = {{Simple Models of the Cardiovascular System for Educational and Research Purposes}},
volume = {2},
year = {2014}
}
@book{Hager2010,
abstract = {Written by high performance computing (HPC) experts, Introduction to High Performance Computing for Scientists and Engineers provides a solid introduction to current mainstream computer architecture, dominant parallel programming models, and useful optimization strategies for scientific HPC. From working in a scientific computing center, the authors gained a unique perspective on the requirements and attitudes of users as well as manufacturers of parallel computers. The text first introduces the architecture of modern cache-based microprocessors and discusses their inherent performance limitations, before describing general optimization strategies for serial code on cache-based architectures. It next covers shared- and distributed-memory parallel computer architectures and the most relevant network topologies. After discussing parallel computing on a theoretical level, the authors show how to avoid or ameliorate typical performance problems connected with OpenMP. They then present cache-coherent nonuniform memory access (ccNUMA) optimization techniques, examine distributed-memory parallel programming with message passing interface (MPI), and explain how to write efficient MPI code. The final chapter focuses on hybrid programming with MPI and OpenMP. Users of high performance computers often have no idea what factors limit time to solution and whether it makes sense to think about optimization at all. This book facilitates an intuitive understanding of performance limitations without relying on heavy computer science knowledge. It also prepares readers for studying more advanced literature.},
author = {Hager, Georg and Wellein, Gerhard},
doi = {10.1201/EBK1439811924},
file = {:home/tomaton/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Hager, Wellein - 2010 - Introduction to High Performance Computing for Scientists and Engineers.pdf:pdf},
isbn = {9781439811924},
pages = {356},
title = {{Introduction to High Performance Computing for Scientists and Engineers}},
year = {2010}
}
@misc{jsim,
title = {{JSim: Java-based Simulation Platform for Data Analysis}},
url = {http://www.physiome.org/jsim}
}
@article{Madden2012,
author = {Madden, Patrick H.},
doi = {10.1109/MDT.2012.2230391},
file = {:home/tomaton/Downloads/06363528.pdf:pdf},
journal = {IEEE Design $\backslash$\& Test of Computers},
number = {April},
pages = {58--64},
title = {{Dispelling the Myths of Parallel Computing}},
year = {2012}
}
@article{Svec2007,
abstract = {OBJECTIVES: Kymographic imaging through videokymography has been recognized as a convenient, novel way to display laryngeal behavior, yet little systematic research has been done to map the relevant features displayed in such images. Here we have aimed at specification of these features to enable systematic visual characterization and categorization of vocal fold vibratory patterns in voice disorders. METHODS: A cross-sectional, descriptive design was used. We selected 45 subjects and extracted 100 videokymographic images from the archive of more than 7,000 videokymographic examinations of subjects with a wide range of voice disorders. The images showed a large variety of vocal fold vibratory behaviors during sustained phonations. We visually identified the prominent features that distinguished the vibration patterns across the images. RESULTS: We divided the findings into 10 feature categories. They included refined traditional features (eg, mucosal waves), as well as additional features that are obscured in strobolaryngoscopy (eg, different types of irregularities, left-right frequency differences, shapes of lateral and medial peaks, cycle aberrations). CONCLUSIONS: The variations in the identified features reveal different behavioral origins of voice disorders. The findings open new possibilities for objective documentation and for monitoring vocal fold behavior in clinical practice through kymographic imaging.},
author = {Svec, Jan G and Sram, Frantisek and Schutte, Harm K},
issn = {0003-4894},
journal = {The Annals of otology, rhinology, and laryngology},
keywords = {Computer-Assisted,Cross-Sectional Studies,Female,Humans,Image Processing,Kymography,Kymography: methods,Laryngoscopy,Male,Mucous Membrane,Mucous Membrane: physiopathology,Retrospective Studies,Vibration,Video Recording,Video Recording: methods,Vocal Cords,Vocal Cords: physiopathology,Voice Disorders,Voice Disorders: diagnosis},
language = {en},
month = mar,
number = {3},
pages = {172--80},
pmid = {17419520},
title = {{Videokymography in Voice Disorders: What to Look for?}},
url = {http://europepmc.org/abstract/MED/17419520},
volume = {116},
year = {2007}
}
@inproceedings{Reddy2014,
abstract = {In recent years Medical Informatics related apps, combine information technology with raw and clinical Medical data to improve the standards in health care diagnosis and Medical Research. This paper mainly deals with how the environment for storing, analysis and processing of Image Databases will be created and operated over the networks. In addition to that different considerable elements like network protocols, Grid based distributed computing systems and accessible elements are explained in this paper. Cloud computing brings radical changes in Medical Image Database management systems operating over the wide area of networks across the Globe. In a holistic way this frame work enables researchers and doctors to design and operate Image Processing Application in a simple, economy manner. It also enables them to make best use of Cloud and other network resources as they are available at real time situations.},
author = {Reddy, A Nanda Gopal and Bhatnagar, Roheet},
booktitle = {2014 International Conference on Advances in Energy Conversion Technologies (ICAECT)},
doi = {10.1109/ICAECT.2014.6757071},
file = {:home/tomaton/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Reddy, Bhatnagar - 2014 - Distributed Medical Image Management A platform for storing, analysis and processing of Image Database over th.pdf:pdf},
isbn = {978-1-4799-2206-2},
keywords = {Cloud Computing,Conferences,DSL,Decision support systems,Energy conversion,Grid,High definition video,Medical Image,Networks,Protocols,clinical medical data,cloud computing,distributed medical image management,grid based distributed computing systems,health care,health care diagnosis,image processing application,information technology,medical image database management systems,medical image processing,medical informatics,medical research,network protocols,network resources,storing,visual databases},
month = jan,
pages = {108--112},
publisher = {IEEE},
shorttitle = {Advances in Energy Conversion Technologies (ICAECT},
title = {{Distributed Medical Image Management: A platform for storing, analysis and processing of Image Database over the cloud}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=6757071},
year = {2014}
}
@article{Thain2005,
abstract = {Since 1984, the Condor project has enabled ordinary users to do extraordinary computing. Today, the project continues to explore the social and technical problems of cooperative computing on scales ranging from the desktop to the world-wide computational grid. In this chapter, we provide the history and philosophy of the Condor project and describe how it has interacted with other projects and evolved along with the field of distributed computing. We outline the core components of the Condor system and describe how the technology of computing must correspond to social structures. Throughout, we reflect on the lessons of experience and chart the course traveled by research ideas as they grow into production systems.},
author = {Thain, Douglas and Tannenbaum, Todd and Livny, Miron},
doi = {10.1002/cpe.938},
file = {:home/tomaton/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Thain, Tannenbaum, Livny - 2005 - Distributed computing in practice The Condor experience.pdf:pdf},
isbn = {1532-0626},
issn = {15320626},
journal = {Concurrency Computation Practice and Experience},
keywords = {Community,Condor,Grid,History,Planning,Scheduling,Split execution},
pages = {323--356},
title = {{Distributed computing in practice: The Condor experience}},
volume = {17},
year = {2005}
}
@article{wuyts2003effects,
author = {Wuyts, FLORIS L and Heylen, LOUIS and Mertens, FONS and Caju, M D and Rooman, RAOUL and de Heyning, P H and {De Bodt}, Marc},
journal = {ANNALS OF OTOLOGY RHINOLOGY AND LARYNGOLOGY},
number = {6},
pages = {540--548},
publisher = {ANNALS PUBLISHING CO},
title = {{Effects of Age, Sex, and Disorder on Voice Range Profile Characteristics of 230 Children}},
volume = {112},
year = {2003}
}
@article{Kacsuk2009,
author = {Kacsuk, Peter and Kovacs, Jozsef and Farkas, Zoltan and Marosi, Attila Csaba and Gombas, Gabor and Balaton, Zoltan},
doi = {10.1007/s10723-009-9139-y},
file = {:home/tomaton/Downloads/art\%3A10.1007\%2Fs10723-009-9139-y.pdf:pdf},
issn = {1570-7873},
journal = {Journal of Grid Computing},
keywords = {boinc,desktop,grid,is partly supported by,parameter sweep,portal,published in this paper,the european commission,the research and development,volunteer},
month = sep,
number = {4},
pages = {439--461},
title = {{SZTAKI Desktop Grid (SZDG): A Flexible and Scalable Desktop Grid System}},
volume = {7},
year = {2009}
}
@book{Pacheco1997,
abstract = {A hands-on introduction to parallel programming based on the Message-Passing Interface (MPI) standard, the de-facto industry standard adopted by major vendors of commercial parallel systems. This textbook/tutorial, based on the C language, contains many fully-developed examples and exercises. The complete source code for the examples is available in both C and Fortran 77. Students and professionals will find that the portability of MPI, combined with a thorough grounding in parallel programming principles, will allow them to program any parallel system, from a network of workstations to a parallel supercomputer.* Proceeds from basic blocking sends and receives to the most esoteric aspects of MPI.* Includes extensive coverage of performance and debugging.* Discusses a variety of approaches to the problem of basic I/O on parallel machines.* Provides exercises and programming assignments.},
author = {Pacheco, Peter S.},
isbn = {1558603395},
pages = {418},
publisher = {Morgan Kaufmann},
title = {{Parallel Programming with MPI}},
year = {1997}
}
@article{Ortiz2011,
abstract = {Cloud-computing standards haven't yet gained traction, and industry observers say this could limit future adoption of the technology.},
author = {Ortiz, Sixto},
doi = {10.1109/MC.2011.220},
file = {:home/tomaton/Downloads/05958700.pdf:pdf},
issn = {00189162},
journal = {Computer},
keywords = {Cloud computing,Hypervisor,IEEE P2301,IEEE P2302,Standards,Virtualization},
number = {July},
pages = {13--16},
title = {{The Problem with Cloud-computing Standardization}},
volume = {44},
year = {2011}
}
@article{Shroff1985,
author = {Shroff, S. G. and Janicki, J. S. and Weber, K. T.},
journal = {Am J Physiol Heart Circ Physiol},
month = aug,
number = {2},
pages = {H358--370},
title = {{Evidence and quantitation of left ventricular systolic resistance}},
url = {http://ajpheart.physiology.org/content/249/2/H358},
volume = {249},
year = {1985}
}
@article{Sa2006,
abstract = {Full-body patient simulators provide a technological basis for clinical education without risk to real patients. In a previous study, we described a model for educational simulation of infant cardiovascular physiology. Using essentially the same methodology, we derive a mathematical model for the cardiovascular system of a healthy 1-week-old neonate. Computer simulations of this model result in vital signs that are close to target hemodynamic variables. Simulated systemic arterial pressure waveform and left ventricular pressure-volume loop are realistic, and the system reacts appropriately to blood loss. We also adapt the model structure and change its parameters to reflect the congenital heart defects: patent ductus arteriosus, tetralogy of Fallot, complex coarctation of the aorta with patent foramen ovale, and transposition of the great arteries. Simulated vital signs are again close to target hemodynamic variables. The resulting model for neonatal cardiovascular pathophysiology is an essential step in attaining a full-body, model-driven neonatal acute care simulator.},
author = {{S\'{a} Couto}, Carla D and van Meurs, Willem L and Goodwin, Jane A and Andriessen, Peter},
journal = {Simulation in Healthcare},
keywords = {1,1 in a previous,12,4,cardiovascular physiology,congenital heart defect,mathematical model,medical education,neonate,simul healthcare 2006,simulation,study,ulator technology,we described a model},
number = {Inaugural},
pages = {4--12},
title = {{A Model for Educational Simulation of Neonatal Cardiovascular Pathophysiology}},
volume = {1},
year = {2006}
}
@book{Saltelli2004,
abstract = {This book is a ‘primer’ in global sensitivity analysis (SA). Its am- bition is to enable the reader to apply global SA to a mathematical or computational model. It offers a description of a few selected techniques for sensitivity analysis, used for assessing the relative importance of model input factors. These techniques will answer questions of the type ‘which of the uncertain input factors is more important in determining the uncertainty in the output of interest?’ or ‘if we could eliminate the uncertainty in one of the input factors, which factor should we choose to reduce the most the variance of the output?’ Throughout this primer, the input factors of interest will be those that are uncertain, i.e. whose value lie within a finite interval of non-zero width. As a result, the reader will not find sensitivity analysis methods here that look at the local property of the input–output relationships, such as derivative-based analysis1. Special attention is paid to the selection of the method, to the fram- ing of the analysis and to the interpretation and presentation of the results. The examples will help the reader to apply the methods in a way that is unambiguous and justifiable, so as to make the sensitiv- ity analysis an added value to model-based studies or assessments. Both diagnostic and prognostic uses of models will be considered (a description of these is in Chapter 2), and Bayesian tools of anal- ysis will be applied in conjunction with sensitivity analysis. When discussing sensitivity with respect to factors, we shall interpret the term ‘factor’ in a very broad sense: a factor is anything that can be changed in a model prior to its execution. This also includes struc- tural or epistemic sources of uncertainty. To make an example, factors will be presented in applications that are in fact ‘triggers’, used to select one model structure versus another, one mesh size ver- sus another, or altogether different conceptualisations of a system.},
author = {Saltelli, Andrea and Tarantola, Stefano and Campolongo, Francesca and Ratto, Marco},
doi = {10.1002/0470870958},
file = {:home/tomaton/Downloads/SALTELLI2004.pdf:pdf},
isbn = {0470870931},
pages = {219},
title = {{Sensitivity Analysis in Practice}},
year = {2004}
}
@book{Tanenbaum2007,
abstract = {Virtually every computing system today is part of a distributed system. Programmers, developers, and engineers need to understand the underlying principles and paradigms as well as the real-world application of those principles. Now, internationally renowned expert Andrew S. Tanenbaum with colleague Martin van Steen presents a complete introduction that identifies the seven key principles of distributed systems, with extensive examples of each. Adds a completely new chapter on architecture to address the principle of organizing distributed systems. Provides extensive new material on peer-to-peer systems, grid computing and Web services, virtualization, and application-level multicasting. Updates material on clock synchronization, data-centric consistency, object-based distributed systems, and file systems and Web systems coordination. For all developers, software engineers, and architects who need an in-depth understanding of distributed systems.},
author = {Tanenbaum, Andrew S. and van Steen, Maarten},
booktitle = {Communication},
file = {:home/tomaton/Downloads/TU\_Wien-Verteilte\_Systeme\_VO\_(G\"{o}schka)\_-\_Tannenbaum-distributed\_systems\_principles\_and\_paradigms\_2nd\_edition.pdf:pdf},
isbn = {9780132392273},
title = {{Distributed Systems: Principles and Paradigms, 2/E}},
year = {2007}
}
@article{Krefting2009,
abstract = {Many scenarios in medical research are predestined for grid computing. Large amounts of data in complex medical image, biosignal and genome processing demand large computing power and data storage. Integration of distributed, heterogeneous data, e.g. correlation between phenotype and genotype data are playing an essential part in life sciences. Sharing of specialized software, data and processing results for collaborative work are further tasks which would strongly benefit from the use of grid infrastructures. However, two major barriers are identified in existing grid environments that prevent extensive use within the life sciences community: Extended security requirements and appropriate usability. To meet these requirements, the MediGRID project is enhancing the basic D-Grid infrastructure along with the implementation of prototype applications from different fields of biomedical research. In this paper, we focus on the developments for ease-of-use under consideration of different aspects of security. They encompass not only security within the grid infrastructure, but also the boundary conditions of network security on the site of the research institutions. For medical grids, we propose a strictly web-portal-based access to grid resources for end-users, with user-guiding, application specific, graphical interfaces. Different levels of authorization are implemented, from fully authorized users to guests without certificate authentication in order to allow hands-on experience for potential grid users. © 2008 Elsevier B.V. All rights reserved.},
author = {Krefting, Dagmar and Bart, Julian and Beronov, Kamen and Dzhimova, Olga and Falkner, J\"{u}rgen and Hartung, Michael and Hoheisel, Andreas and Knoch, Tobias a. and Lingner, Thomas and Mohammed, Yassene and Peter, Kathrin and Rahm, Erhard and Sax, Ulrich and Sommerfeld, Dietmar and Steinke, Thomas and Tolxdorff, Thomas and Vossberg, Michal and Viezens, Fred and Weisbecker, Anette},
doi = {10.1016/j.future.2008.05.005},
file = {:home/tomaton/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Krefting et al. - 2009 - MediGRID Towards a user friendly secured grid infrastructure.pdf:pdf},
issn = {0167739X},
journal = {Future Generation Computer Systems},
keywords = {Grid computing,Healthgrids,Security,Usability},
number = {3},
pages = {326--336},
publisher = {Elsevier B.V.},
title = {{MediGRID: Towards a User Friendly Secured Grid Infrastructure}},
volume = {25},
year = {2009}
}
@article{Suga1974,
abstract = {We have previously shown in the normally ejecting canine left ventricle that E(t), the time-varying ratio of instantaneous pressure, P(t), to instantaneous volume, V(t), is little affected by end-diastolic volume or aortic pressure. The present study on an excised, supported canine heart preparation indicates that the thesis on E(t) is also valid for either totally isovolumic or auxobaric beats. Intraventricular volume was measured more accurately than it was in the previous study by a new volumetric system. Regression analysis of the data showed that the instantaneous pressure-volume relationship could be approximated by the equation P(t) = E(t).[V(t) - Vd], where Vd is an empirical constant, over a wide range of intraventricular volume. Similar E(t) curves were obtained from both isovolumic and auxobaric beats for a given contractile state. When the contractile state of the preparation was enhanced by a constant-rate infusion (0.2 \{micro\}g/min) of norepinephrine or isoproterenol into the coronary artery, the peak magnitude of E(t) increased 63\% from 3.6 mm Hg/ml and the time to peak E(t) shortened 10\% from 175 msec. We conclude that the present investigation substantiates our earlier study which established a link between E(t) and the contractile state of the heart.},
author = {Suga, H and Sagawa, K},
doi = {10.1161/01.RES.35.1.117},
file = {:home/tomaton/Downloads/Circulation Research-1974-SUGA-117-26.pdf:pdf},
isbn = {0009-7330 (Print) 0009-7330 (Linking)},
issn = {0009-7330},
journal = {Circulation research},
keywords = {instantaneous elasticity,pressure-volume diagram},
pages = {117--126},
pmid = {4841253},
title = {{Instantaneous pressure-volume relationships and their ratio in the excised, supported canine left ventricle.}},
volume = {35},
year = {1974}
}
@article{Foster2006,
author = {Foster, Ian},
file = {:home/tomaton/Downloads/GT4.pdf:pdf},
journal = {Journal of Computer Science and Technology},
pages = {513--520},
title = {{Globus Toolkit Version 4: Software for Service-oriented Systems}},
volume = {21(4)},
year = {2006}
}
@article{Sneddon2011,
abstract = {Managing the overwhelming numbers of molecular states and interactions is a fundamental obstacle to building predictive models of biological systems. Here we introduce the Network-Free Stochastic Simulator (NFsim), a general-purpose modeling platform that overcomes the combinatorial nature of molecular interactions. Unlike standard simulators that represent molecular species as variables in equations, NFsim uses a biologically intuitive representation: objects with binding and modification sites acted on by reaction rules. During simulations, rules operate directly on molecular objects to produce exact stochastic results with performance that scales independently of the reaction network size. Reaction rates can be defined as arbitrary functions of molecular states to provide powerful coarse-graining capabilities, for example to merge Boolean and kinetic representations of biological networks. NFsim enables researchers to simulate many biological systems that were previously inaccessible to general-purpose software, as we illustrate with models of immune system signaling, microbial signaling, cytoskeletal assembly and oscillating gene expression.},
author = {Sneddon, Michael W and Faeder, James R and Emonet, Thierry},
doi = {10.1038/nmeth.1546},
file = {:home/tomaton/Downloads/document(1).pdf:pdf},
isbn = {1548-7105 (Electronic)$\backslash$n1548-7091 (Linking)},
issn = {1548-7091},
journal = {Nature methods},
number = {2},
pages = {177--183},
pmid = {21186362},
title = {{Efficient modeling, simulation and coarse-graining of biological complexity with NFsim.}},
volume = {8},
year = {2011}
}
@article{Iosup2010,
author = {Iosup, Alexandru and Ostermann, Simon and Yigitbasi, Nezih and Prodan, Radu and Fahringer, Thomas and Epema, D},
file = {:home/tomaton/Downloads/05719609.pdf:pdf},
journal = {IEEE Transactions on Parallel and Distributed Systems},
number = {6},
pages = {931--945},
title = {{Performance Analysis of Cloud Computing Services for Many-Tasks Scientific Computing}},
volume = {22},
year = {2010}
}
@article{Humphrey2012,
author = {Humphrey, Marty and Beekwilder, Norm and Goodall, Jonathan L. and Ercan, Mehmet B.},
doi = {10.1109/eScience.2012.6404420},
file = {:home/tomaton/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Humphrey, Beekwilder - 2012 - Calibration of watershed models using cloud computing.pdf:pdf},
isbn = {9781467344661},
journal = {2012 IEEE 8th International Conference on E-Science},
keywords = {-cloud computing,Biological system modeling,Calibration,Cloud computing,Clouds,Computational modeling,Data models,Microsoft Windows Azure,SWAT,Water resources,Windows Azure,calibration,cloud computing,cloud cores,cloud-based system,computational model parameters,hydrologic systems,hydrology,laptop computer,model calibration,physically-observed phenomena,real-time interactive model,river basins,rivers,search algorithm,search problems,water quality,watershed model calibration,watershed modeling},
language = {English},
month = oct,
number = {1048222},
pages = {1--8},
publisher = {IEEE},
title = {{Calibration of Watershed Models Using Cloud Computing}},
year = {2012}
}
@book{Butenhof1997,
abstract = {With this practical book, you will attain a solid understanding of threads and will discover how to put this powerful mode of programming to work in real-world applications. The primary advantage of threaded programming is that it enables your applications to accomplish more than one task at the same time by using the number-crunching power of multiprocessor parallelism and by automatically exploiting I/O concurrency in your code, even on a single processor machine. The result: applications that are faster, more responsive to users, and often easier to maintain. Threaded programming is particularly well suited to network programming where it helps alleviate the bottleneck of slow network I/O. This book offers an in-depth description of the IEEE operating system interface standard, POSIXAE (Portable Operating System Interface) threads, commonly called Pthreads. Written for experienced C programmers, but assuming no previous knowledge of threads, the book explains basic concepts such as asynchronous programming, the lifecycle of a thread, and synchronization. You then move to more advanced topics such as attributes objects, thread-specific data, and realtime scheduling. An entire chapter is devoted to "real code," with a look at barriers, read/write locks, the work queue manager, and how to utilize existing libraries. In addition, the book tackles one of the thorniest problems faced by thread programmers-debugging-with valuable suggestions on how to avoid code errors and performance problems from the outset. Numerous annotated examples are used to illustrate real-world concepts. A Pthreads mini-reference and a look at future standardization are also included.},
author = {Butenhof, David R.},
isbn = {0201633922},
title = {{Programming with POSIX Threads}},
year = {1997}
}
@article{Hester2011systems,
abstract = {Over the last 10 years, 'Systems Biology' has focused on the integration of biology and medicine with information technology and computation. The current challenge is to use the discoveries of the last 20 years, such as genomics and proteomics, to develop targeted therapeutical strategies. These strategies are the result of understanding the aetiologies of complex diseases. Scientists predict the data will make personalized medicine rapidly available. However, the data need to be considered as a highly complex system comprising multiple inputs and feedback mechanisms. Translational medicine requires the functional and conceptual linkage of genetics to proteins, proteins to cells, cells to organs, organs to systems and systems to the organism. To help understand the complex integration of these systems, a mathematical model of the entire human body, which accurately links the functioning of all organs and systems together, could provide a framework for the development and testing of new hypotheses that will be important in clinical outcomes. There are several efforts to develop a 'Human Physiome', with the strengths and weaknesses of each being presented here. The development of a 'Human Model', with verification, documentation and validation of the underlying and integrative responses, is essential to provide a usable environment. Future development of a 'Human Model' requires integrative physiologists working in collaboration with other scientists, who have expertise in all areas of human biology, to develop the most accurate and usable human model.},
author = {Hester, Robert L and Iliescu, Radu and Summers, Richard and Coleman, Thomas G},
doi = {10.1113/jphysiol.2010.201558},
file = {:home/tomaton/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Hester et al. - 2011 - Systems biology and integrative physiological modelling.pdf:pdf},
issn = {1469-7793},
journal = {The Journal of physiology},
keywords = {Biological,Genomics,Humans,Models,Proteomics,Systems Biology},
month = mar,
number = {Pt 5},
pages = {1053--60},
pmid = {21135044},
publisher = {Physiological Soc},
title = {{Systems Biology and Integrative Physiological Modelling}},
volume = {589},
year = {2011}
}
@inproceedings{kulhanek2009dd,
author = {Kulh\'{a}nek, Tom\'{a}\v{s}},
booktitle = {Proceeding of PhD. Conference 2009 was published as: Doktorandsk\'{e} dny '09},
editor = {Ku\v{z}elov\'{a}, D},
pages = {62--64},
publisher = {Institute of Computer Science/MatfyzPress},
title = {{Virtual Distributed Environment for Exchange of Medical Images}},
url = {http://www.cs.cas.cz/hakl/doktorandsky-den/files/2009/sbornik-dd-2009.pdf},
year = {2009}
}
@inproceedings{Kulhanek2013b,
author = {Kulh\'{a}nek, Tom\'{a}\v{s} and Matej\'{a}k, Marek and \v{S}ilar, Jan and Privitzer, Pavol and Tribula, Martin and Je\v{z}ek, Filip and Kofr\'{a}nek, Jiř\'{\i}},
booktitle = {sborn\'{\i}k př\'{\i}sp\v{e}vků MEDSOFT},
pages = {115--121},
title = {{Hybridn\'{\i} architektura pro webov\'{e} simul\'{a}tory (cze) Hybrid architecture for web simulators (en)}},
url = {http://www.creativeconnections.cz/medsoft/2013/Medsoft\_2013\_Kulhanek.pdf},
year = {2013}
}
@article{Benkner2010,
abstract = {The increasing volume of data describing human disease processes and the growing complexity of understanding, managing, and sharing such data presents a huge challenge for clinicians and medical researchers. This paper presents the @neurIST system, which provides an infrastructure for biomedical research while aiding clinical care, by bringing together heterogeneous data and complex processing and computing services. Although @neurIST targets the investigation and treatment of cerebral aneurysms, the system's architecture is generic enough that it could be adapted to the treatment of other diseases. Innovations in @neurIST include confining the patient data pertaining to aneurysms inside a single environment that offers clinicians the tools to analyze and interpret patient data and make use of knowledge-based guidance in planning their treatment. Medical researchers gain access to a critical mass of aneurysm related data due to the system's ability to federate distributed information sources. A semantically mediated grid infrastructure ensures that both clinicians and researchers are able to seamlessly access and work on data that is distributed across multiple sites in a secure way in addition to providing computing resources on demand for performing computationally intensive simulations for treatment planning and research.},
author = {Benkner, Siegfried and Arbona, Antonio and Berti, Guntram and Chiarini, Alessandro and Dunlop, Robert and Engelbrecht, Gerhard and Frangi, Alejandro F. and Friedrich, Christoph M. and Hanser, Susanne and Hasselmeyer, Peer and Hose, Rod D. and Iavindrasana, Jimison and Khler, Martin and Iacono, Luigi Lo and Lonsdale, Guy and Meyer, Rodolphe and Moore, Bob and Rajasekaran, Hariharan and Summers, Paul E. and Whrer, Alexander and Wood, Steven},
doi = {10.1109/TITB.2010.2049268},
file = {:home/tomaton/Downloads/05456192.pdf:pdf},
isbn = {1558-0032 (Electronic)$\backslash$r1089-7771 (Linking)},
issn = {10897771},
journal = {IEEE Transactions on Information Technology in Biomedicine},
keywords = {Aneurysms,architecture,biomechanical simulation,biomedical grid,ontology},
number = {6},
pages = {1365--1377},
pmid = {20435543},
title = {{@neurIST: Infrastructure for Advanced Disease Management through Integration of Heterogeneous Data, Computing, and Complex Processing Services}},
volume = {14},
year = {2010}
}
@article{Foster2003,
author = {Foster, Ian and Kesselman, Carl and Nick, Jeffrey M and Tuecke, Steven},
file = {:home/tomaton/Downloads/ogsa.pdf:pdf},
journal = {Grid Computing: Making the Global Infrastructure a Reality},
pages = {217--249},
title = {{The Physiology of the Grid: An Open Grid Service Architecture for Distributed Systems Integration}},
year = {2003}
}
@article{Campbell1990,
abstract = {Elastance-resistance [E(t)-R] representations of the left ventricle (LV) were evaluated for their ability to reproduce instantaneous pressure [P(t)] and outflow [Q(t)]. Experiments were performed in open-chest rats. P(t) and Q(t) were measured during steady-state ejecting beats and during a beat in which the aorta was suddenly clamped. The degree of clamping varied from partial to total occlusion. The total occlusion beat was considered an isovolumic beat that generated an isovolumic pressure [Piso(t)] with a characteristic time to maximal Piso(t) [Tpisomax]. In ejecting beats, 34\% of stroke volume was delivered after Tpisomax. P(t) and Q(t) from the steady-state ejecting beats and Piso(t) from the clamped beat were then used to estimate parameters of an E(t)-R model. Components of P(t) and Q(t) not accounted for by E(t)-R were identified and termed extra-pressure [Pext(t)] and extra-outflow [Qext(t)]. Pext(t) and Qext(t) were near-zero valued until Tpisomax; then they became systematically positive and finally negative valued after end ejection. During partial aortic occlusion, P(t) was elevated and Q(t) was reduced. However, the time of ejection was extended, and the fraction of stroke volume delivered after Tpisomax increased as P(t) was made higher. Partial occlusion also prolonged the positive phase of Pext(t) and Qext(t). Elements possessing "active" and "deactive" properties were added to the E(t)-R model in an attempt to account for Pext(t) and Qext(t) during partial occlusion. Optional forms of these elements were considered. These expanded E(t)-R models were fitted to basal ejecting data and then asked to predict data from a partial occlusion beat. All expanded models failed to adequately predict the partial occlusion pressure and/or outflow. It was concluded that 1) late ejection was quantitatively important to LV pumping, 2) behavior during late ejection was inconsistent with E(t)-R, and 3) ad hoc modification of E(t)-R models was not likely to yield LV pumping models that could satisfactorily reproduce instantaneous P(t) and Q(t) behavior over the entire ejection period.},
author = {Campbell, K B and Kirkpatrick, R D and Knowlen, G G and Ringo, J a},
doi = {10.1161/01.RES.66.1.218},
file = {:home/tomaton/Downloads/Circulation Research-1990-Campbell-218-33.pdf:pdf},
issn = {0009-7330},
journal = {Circulation research},
pages = {218--233},
pmid = {2295140},
title = {{Late-systolic pumping properties of the left ventricle. Deviation from elastance-resistance behavior.}},
volume = {66},
year = {1990}
}
@phdthesis{Fielding2000,
author = {Fielding, RT},
file = {:home/tomaton/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Fielding - 2000 - Architectural styles and the design of network-based software architectures.pdf:pdf},
school = {University of California},
title = {{Architectural styles and the design of network-based software architectures}},
url = {http://jpkc.fudan.edu.cn/picture/article/216/35/4b/22598d594e3d93239700ce79bce1/7ed3ec2a-03c2-49cb-8bf8-5a90ea42f523.pdf},
year = {2000}
}
@article{Raman1998,
abstract = {Conventional resource management systems use a system model to describe resources and a centralized scheduler to control their allocation. We argue that this paradigm does not adapt well to distributed systems, particularly those built to support high throughput computing. Obstacles include heterogeneity of resources, which make uniform allocation algorithms difficult to formulate, and distributed ownership, leading to widely varying allocation policies. Faced with these problems, we developed and implemented the classified advertisement (classad) matchmaking framework, a flexible and general approach to resource management in distributed environment with decentralized ownership of resources. Novel aspects of the framework include a semi structured data model that combines schema, data, and query in a simple but powerful specification language, and a clean separation of the matching and claiming phases of resource allocation. The representation and protocols result in a robust, scalable and flexible framework that can evolve with changing resources. The framework was designed to solve real problems encountered in the deployment of Condor, a high throughput computing system developed at the University of Wisconsin-Madison. Condor is heavily used by scientists at numerous sites around the world. It derives much of its robustness and efficiency from the matchmaking architecture},
author = {Raman, Rajesh and Livny, M. and Solomon, Marvin},
doi = {10.1109/HPDC.1998.709966},
file = {:home/tomaton/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Raman, Livny, Solomon - 1998 - Matchmaking distributed resource management for high throughput computing.pdf:pdf},
isbn = {0-8186-8579-4},
journal = {Proceedings. The Seventh International Symposium on High Performance Distributed Computing (Cat. No.98TB100244)},
pages = {140--146},
title = {{Matchmaking: distributed resource management for high throughput computing}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=709966},
year = {1998}
}
@article{Xin2011,
abstract = {Cloud computing has been considered as a significant change, especially to the so-called \&\#x201C;long tail\&\#x201D; in the Internet industry, which targets at a niche market. This paper focuses on the innovation of Internet long tail in the cloud environment. For this purpose, it systematically analyzes and summarizes the influence of cloud computing on innovation and how to seize these opportunities for Internet long tail. The result reveals that Cloud computing has brought unprecedented innovative opportunities for Internet long tail to access to the markets monopolized by big corporations, making the long tail more valuable to meet the various demand.},
author = {Xin, Liu and Song, Chen},
doi = {10.1109/ICPIM.2011.5983735},
file = {:home/tomaton/Downloads/05983735.pdf:pdf},
isbn = {9781457703584},
journal = {Proceedings of 2011 International Conference on Product Innovation Management, ICPIM 2011},
keywords = {Cloud computing,innovation,the Internet long tail},
pages = {603--607},
title = {{Cloud-based innovation of Internet long tail}},
year = {2011}
}
@inproceedings{Sarek2009,
annote = {http://www.creativeconnections.cz/medsoft/2009/Medsoft\_2009\_\%C5\%A0\%C3\%A1rek\_Milan.pdf},
author = {\v{S}\'{a}rek, Milan and Kulh\'{a}nek, Tom\'{a}\v{s}},
booktitle = {sborn\'{\i}k př\'{\i}sp\v{e}vků MEDSOFT},
file = {:home/tomaton/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/\v{S}\'{a}rek, Kulh\'{a}nek - 2009 - Nov\'{e} sm\v{e}ry medic\'{\i}nsk\'{y}ch aplikac\'{\i} sdru\v{z}en\'{\i} CESNET(2).pdf:pdf},
pages = {145--148},
title = {{Nov\'{e} sm\v{e}ry medic\'{\i}nsk\'{y}ch aplikac\'{\i} sdru\v{z}en\'{\i} CESNET}},
year = {2009}
}
@article{Richardson1998,
abstract = {VNC is an ultra thin client system based on a simple display protocol that is platform independent. It achieves mobile computing without requiring the user to carry any hardware. VNC provides access to home computing environments from anywhere in the world, on whatever computing infrastructure happens to be available-including, for example, public Web browsing terminals in airports. In addition, VNC allows a single desktop to be accessed from several places simultaneously, thus supporting application sharing in the style of computer supported cooperative work (CSCW). The technology underlying VNC is a simple remote display protocol. It is the simplicity of this protocol that makes VNC so powerful. Unlike other remote display protocols such as the X Window System and Citrix's ICA, the VNC protocol is totally independent of operating system, windowing system, and applications. The VNC system is freely available for download from the ORL Web site at http://www.orl.co.uk/vnc/. We begin the article by summarizing the evolution of VNC from our work on thin client architectures. We then describe the structure of the VNC protocol, and conclude by discussing the ways we use VNC technology now and how it may evolve further as new clients and servers are developed},
author = {Richardson, Tristan and Stafford-Fraser, Quentin and Wood, Kenneth R. and Hopper, Andy},
doi = {10.1109/4236.656066},
file = {:home/tomaton/Downloads/tr.98.1.pdf:pdf},
issn = {10897801},
journal = {IEEE Internet Computing},
pages = {33--38},
pmid = {10680121},
title = {{Virtual network computing}},
volume = {2},
year = {1998}
}
@article{openmodelica2005,
author = {Fritzson, Peter and Aronsson, Peter and Lundvall, H\aa kan and Nystr\"{o}m, Kaj and Pop, Adrian and Saldamli, Levon and Broman, David},
journal = {Simulation News Europe},
number = {45},
title = {{The OpenModelica Modeling, Simulation, and Software Development Environment}},
volume = {44},
year = {2005}
}
@misc{Reese,
author = {Reese, George},
file = {:home/tomaton/Downloads/Cloud Application Architectures.pdf:pdf},
isbn = {9780596156367},
title = {{Cloud Computing Architectures: Building Applications and Infrastructures in the Cloud}}
}
@article{Lu2014b,
author = {Lu, Shilin and Ranjan, Rajiv and Strazdins, Peter},
doi = {10.1002/cpe.3325},
file = {:home/tomaton/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Unknown - Unknown - HPCTOOLKIT Tools for performance analysis of optimized parallel programs.pdf:pdf},
issn = {15320626},
journal = {Concurrency and Computation: Practice and Experience},
month = jun,
pages = {n/a--n/a},
title = {{Reporting an experience on design and implementation of e-Health systems on Azure cloud}},
year = {2014}
}
@article{Wassink2009,
abstract = {Life science workflow systems are developed to help life scientists to conveniently connect various programs and Web services. In practice however, much time is spent on data conversion, because Web services provided by different organisations use different data formats. We have analysed all the Taverna workflows available at the my Experiment Web site on December 11, 2008. Our analysis of the tasks in these workflows shows several noticeable aspects: their number ranges from 1 to 70 tasks per workflow; 18\% of the workflows consist of a single task.Of the tasks used are 22\% Web services; local services, i.e. tasks executed by the workflow system itself, are very popular and cover 57\% of tasks; tasks implemented by the workflow designer, scripting tasks, are is also used often (14\%). Our analysis shows that over 30\% of tasks are related to data conversion.},
author = {Wassink, Ingo and {Van Der Vet}, Paul E. and Wolstencroft, Katy and Neerincx, Pieter B T and Roos, Marco and Rauwerda, Han and Breit, Timo M.},
doi = {10.1109/SERVICES-I.2009.48},
file = {:home/tomaton/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Wassink et al. - 2009 - Analysing scientific workflows Why workflows not only connect web services.pdf:pdf},
isbn = {9780769538129},
journal = {SERVICES 2009 - 5th 2009 World Congress on Services},
keywords = {Data conversion,Scientific workflow,Scripting,Sub-workflow,Web services},
pages = {314--321},
title = {{Analysing scientific workflows: Why workflows not only connect web services}},
year = {2009}
}
@article{Kohl2010,
abstract = {In just over a decade, Systems Biology has moved from being an idea, or rather a disparate set of ideas, to a mainstream feature of research and funding priorities. Institutes, departments, and centers of various flavors of Systems Biology have sprung up all over the world. An Internet search now produces more than 2 million hits. Of the 2,800 entries in PubMed with "Systems Biology" in either the title or the abstract, only two papers were published before 2000, and >90\% were published in the past five years. In this article, we interpret Systems Biology as an approach rather than as a field or a destination of research. We illustrate that this approach is productive for the exploration of systems behavior, or "phenotypes," at all levels of structural and functional complexity, explicitly including the supracellular domain, and suggest how this may be related conceptually to genomes and biochemical networks. We discuss the role of models in Systems Biology and conclude with a consideration of their utility in biomedical research and development.},
author = {Kohl, P and Crampin, E J and Quinn, T A and Noble, D},
doi = {10.1038/clpt.2010.92},
file = {:home/tomaton/Downloads/document(4).pdf:pdf},
isbn = {1532-6535 (Electronic)$\backslash$n0009-9236 (Linking)},
issn = {1532-6535},
journal = {Clinical Pharmacology and Therapeutics},
pages = {25--33},
pmid = {20531468},
title = {{Systems Biology: An Approach.}},
volume = {88},
year = {2010}
}
@inproceedings{kulhanek2011dd,
author = {Kulh\'{a}nek, Tom\'{a}\v{s}},
booktitle = {Proceeding of PhD. Conference 2011 was published as: Doktorandsk\'{e} dny '11},
editor = {Ku\v{z}elov\'{a}, D},
pages = {90--94},
publisher = {Institute of Computer Science/MatfyzPress},
title = {{Infrastructure for Data Storage and Computation in Biomedical Research}},
url = {http://www.cs.cas.cz/hakl/doktorandsky-den/files/2011/sbornik-dd-2011.pdf},
year = {2011}
}
@article{Karp1972,
author = {Karp, R and $\backslash$},
doi = {10.1007/978-1-4684-2001-2\_9},
file = {:home/tomaton/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Karp - 1972 - Reducibility among combinatorial problems.pdf:pdf},
isbn = {978-1-4684-2003-6},
journal = {Miller and J. Thatcher, eds. Complexity of Computer Computations , Plenum Press},
pages = {85--103},
publisher = {Springer US},
title = {{Reducibility among Combinatorial Problems", in R}},
year = {1972}
}
@article{Bayer1972Org,
author = {Bayer, Rudolf and McCreight, E. M.},
doi = {10.1007/BF00288683},
file = {:home/tomaton/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Bayer, McCreight - 2002 - Organization and maintenance of large ordered indexes.pdf:pdf},
issn = {0001-5903},
journal = {Acta Informatica},
number = {3},
pages = {173--189},
title = {{Organization and Maintenance of Large Ordered Indexes}},
volume = {1},
year = {1972}
}
@article{Tolson2007,
abstract = {A new global optimization algorithm, dynamically dimensioned search (DDS), is introduced for automatic calibration of watershed simulation models. DDS is designed for calibration problems with many parameters, requires no algorithm parameter tuning, and automatically scales the search to find good solutions within the maximum number of user-specified function (or model) evaluations. As a result, DDS is ideally suited for computationally expensive optimization problems such as distributed watershed model calibration. DDS performance is compared to the shuffled complex evolution (SCE) algorithm for multiple optimization test functions as well as real and synthetic SWAT2000 model automatic calibration formulations. Algorithms are compared for optimization problems ranging from 6 to 30 dimensions, and each problem is solved in 1000 to 10,000 total function evaluations per optimization trial. Results are presented so that future modelers can assess algorithm performance at a computational scale relevant to their modeling case study. In all four of the computationally expensive real SWAT2000 calibration formulations considered here (14, 14, 26, and 30 calibration parameters), results show DDS to be more efficient and effective than SCE. In two cases, DDS requires only 15–20\% of the number of model evaluations used by SCE in order to find equally good values of the objective function. Overall, the results also show that DDS rapidly converges to good calibration solutions and easily avoids poor local optima. The simplicity of the DDS algorithm allows for easy recoding and subsequent adoption into any watershed modeling application framework.},
author = {Tolson, Bryan a. and Shoemaker, Christine a.},
doi = {10.1029/2005WR004723},
file = {:home/tomaton/Downloads/wrcr10694.pdf:pdf},
isbn = {0043-1397},
issn = {00431397},
journal = {Water Resources Research},
keywords = {http://dx.doi.org/10.1029/2005WR004723, doi:10.102},
number = {August 2006},
pages = {1--16},
title = {{Dynamically dimensioned search algorithm for computationally efficient watershed model calibration}},
volume = {43},
year = {2007}
}
@inproceedings{Kulhanek2009Mefanet,
author = {Kulh\'{a}nek, Tom\'{a}\v{s} and Fri\v{c}, Marek and \v{S}\'{a}rek, Milan},
booktitle = {Mefanet 2009},
editor = {Schwarz, Daniel and Majern\'{\i}k, Jaroslav and Du\v{s}ek, Ladislav and \v{S}t\'{\i}pek, Stanislav and Mih\'{a}l, Vladim\'{\i}r},
file = {:home/tomaton/Downloads/kulhanek\_full.pdf:pdf},
keywords = {phoniatric application,remote desktop,virtualization},
publisher = {MSD Brno},
title = {{Vzd\'{a}len\'{y} př\'{\i}stup k virtu\'{a}ln\'{\i}m v\'{y}ukov\'{y}m a v\'{y}zkumn\'{y}m aplikac\'{\i}m - podpora foniatrick\'{y}ch vy\v{s}etřen\'{\i}}},
url = {http://www.mefanet.cz/res/file/mefanet2009/prispevky/kulhanek\_full.pdf},
year = {2009}
}
@article{mitamura1987,
author = {Mitamura, Y},
journal = {IFAC Control Aspects of Biomedical Engineering},
pages = {37--51},
title = {{Control aspects of the circulatory system}},
year = {1987}
}
@article{Yu2005a,
abstract = {With the advent of Grid and application technologies, scientists and engineers are building more and more complex applications to manage and process large data sets, and execute scientific experiments on distributed resources. Such application scenarios require means for composing and executing complex workflows. Therefore, many efforts have been made towards the development of workflow management systems for Grid computing. In this paper, we propose a taxonomy that characterizes and classifies various approaches for building and executing workflows on Grids. The taxonomy not only highlights the design and engineering similarities and differences of state-of-the-art in Grid workflow systems, but also identifies the areas that need further research.},
author = {Yu, Jia and Buyya, Rajkumar},
doi = {10.1145/1084805.1084814},
file = {:home/tomaton/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Yu, Buyya - 2005 - A taxonomy of scientific workflow systems for grid computing.pdf:pdf},
isbn = {1084805108},
issn = {01635808},
journal = {ACM SIGMOD Record},
keywords = {grid computing,scientific workflows,taxonomy},
number = {3},
pages = {44},
title = {{A Taxonomy of Scientific Workflow Systems For Grid Computing}},
volume = {34},
year = {2005}
}
@article{Litzkow1990,
abstract = {Condor is a distributed batch system designed to provide convenient access to unutilized workstations while preserving the rights of their owners and to meet the needs of users who are frustrated by the limitations of computing on a single workstation. Several principles have driven the design of Condor. The first is that workstation owners should always have the resources of the workstation they own at their disposal. The second is that access to remote capacity must be easy and should approximate the local execution environment as closely as possible. The third is portability, which is essential because of rapid developments in the workstations on which Condor operates. Mechanisms basic to the operation of Condor, working experience, and software support requirements are outlined},
author = {Litzkow, M. and Livny, M.},
doi = {10.1109/EDS.1990.138057},
isbn = {0818620927},
journal = {IEEE Workshop on Experimental Distributed Systems},
title = {{Experience with the Condor Distributed Batch System}},
year = {1990}
}
@inproceedings{Balaton2007,
author = {Balaton, Zoltan and Gombas, Gabor and Kacsuk, Peter and Kornafeld, Adam and Kovacs, Jozsef and Marosi, Attila Csaba and Vida, Gabor and Podhorszki, Norbert and Kiss, Tamas},
booktitle = {Parallel and Distributed Processing Symposium},
doi = {10.1109/IPDPS.2007.370665},
publisher = {IEEE},
title = {{SZTAKI Desktop Grid: A Modular and Scalable Way of Building Large Computing Grids}},
year = {2007}
}
@article{DeBono2011,
author = {de Bono, B. and Sammut, S.J. and Grenon, P.},
doi = {10.1109/eScienceW.2011.29},
file = {:home/tomaton/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/de Bono, Sammut, Grenon - 2011 - Achieving Semantic Interoperability between Physiology Models and Clinical Data.pdf:pdf},
isbn = {978-1-4673-0026-1},
journal = {2011 IEEE Seventh International Conference on e-Science Workshops},
month = dec,
pages = {135--142},
publisher = {Ieee},
title = {{Achieving Semantic Interoperability between Physiology Models and Clinical Data}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=6130742},
year = {2011}
}
@article{Pruett2014,
abstract = {The acute response of parathyroid hormone to perturbations in serum ionized calcium ([Ca(2+)]) is physiologically complex, and poorly understood. The literature provides numerous observations of quantitative and qualitative descriptions of parathyroid hormone (PTH) dynamics. We present a physiologically based mathematical model of PTH secretion constructed from mechanisms suggested in the literature, and validated against complex [Ca(2+)] clamping protocols from human data. The model is based on two assumptions. The first is that secretion is a fraction of cellular reserves, with the fraction being determined by the kinetics of [Ca(2+)] with its receptor. The second is that there are multiple distinct populations of parathyroid cells, with different secretory parameters. The steady state and transient PTH secretion responses of the model are in agreement with human experimental PTH responses to different hypocalcemia and hypercalcemia stimuli. This mathematical model suggests that a population of secreting cells is responsible for the PTH secretory dynamics observed experimentally.},
author = {Pruett, William a and Hester, Robert L},
doi = {10.1002/phy2.231},
file = {:home/tomaton/Downloads/e00231.full.pdf:pdf},
isbn = {6019841820},
issn = {2051-817X},
journal = {Physiological reports},
keywords = {calcium,hysteresis,parathyroid hormone},
month = feb,
number = {2},
pages = {e00231},
pmid = {24744900},
title = {{Parathyroid hormone secretion by multiple distinct cell populations, a time dynamic mathematical model.}},
url = {http://www.pubmedcentral.nih.gov/articlerender.fcgi?artid=3966243\&tool=pmcentrez\&rendertype=abstract},
volume = {2},
year = {2014}
}
@article{Ralovich2012,
abstract = {Coarctation of the aorta (CoA), is a congenital defect characterized by a severe narrowing of the aorta, usually distal to the aortic arch. The treatment options include surgical repair, stent implantation, and balloon angioplasty. In order to evaluate the physiological significance of the pre-operative coarctation and to assess the post-operative results, the hemodynamic analysis is usually performed by measuring the pressure gradient (deltaP) across the coarctation site via invasive cardiac catheterization. The measure of success is reduction of the (deltaP > 20 mmHg) systolic blood pressure gradient. In this paper, we propose a non-invasive method based on Computational Fluid Dynamics and MR imaging to estimate the pre- and post-operative hemodynamics for both native and recurrent coarctation patients. High correlation of our results and catheter measurements is shown on corresponding pre- and post-operative examination of 5 CoA patients.},
author = {Ralovich, Krist\'{o}f and Itu, Lucian and Mihalef, Viorel and Sharma, Puneet and Ionasec, Razvan and Vitanovski, Dime and Krawtschuk, Waldemar and Everett, Allen and Ringel, Richard and Navab, Nassir and Comaniciu, Dorin},
file = {:home/tomaton/Documents/chp\%3A10.1007\%2F978-3-642-33418-4\_60.pdf:pdf},
isbn = {978-3-642-33417-7},
journal = {Medical image computing and computer-assisted intervention : MICCAI ... International Conference on Medical Image Computing and Computer-Assisted Intervention},
keywords = {Aorta,Aorta: pathology,Aorta: physiopathology,Aortic Coarctation,Aortic Coarctation: pathology,Aortic Coarctation: physiopathology,Blood Flow Velocity,Computer-Assisted,Computer-Assisted: methods,Humans,Image Enhancement,Image Enhancement: methods,Image Interpretation,Magnetic Resonance Angiography,Magnetic Resonance Angiography: methods,Myocardial Perfusion Imaging,Myocardial Perfusion Imaging: methods,Reproducibility of Results,Sensitivity and Specificity},
pages = {486--93},
pmid = {23286084},
title = {{Hemodynamic assessment of pre- and post-operative aortic coarctation from MRI.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/23286084},
volume = {15},
year = {2012}
}
@inproceedings{Adamova2014,
author = {Adamova, Dagmar},
booktitle = {52 International Winter Meeting on Nuclear Physics, Bormio,Italy},
file = {:home/tomaton/Downloads/Bormio2014\_021.pdf:pdf},
number = {January},
title = {{Computing Framework for the LHC: Current Status and Challenges of the High Luminosity LHC Future}},
url = {http://pos.sissa.it/archive/conferences/212/021/Bormio2014\_021.pdf},
year = {2014}
}
@article{Oppenheim1970,
author = {Oppenheim, AV},
file = {:home/tomaton/Downloads/AVOSpeechSpectro0870.pdf:pdf},
journal = {Spectrum, IEEE},
title = {{Speech spectrograms using the fast Fourier transform}},
url = {http://ieeexplore.ieee.org/xpls/abs\_all.jsp?arnumber=5213512},
year = {1970}
}
@article{Hucka2004,
author = {Hucka, Michael and Finney, ABBJ and Bornstein, Benjamin J and Keating, Sarah M and Shapiro, Bruce E and Matthews, Joanne and Kovitz, Ben L and Schilstra, Maria J and Funahashi, Akira and Doyle, John C},
file = {::;:home/tomaton/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Hucka et al. - 2004 - Evolving a lingua franca and associated software infrastructure for computational systems biology the Systems Biol.pdf:pdf},
isbn = {1741-248X},
journal = {Systems biology},
number = {1},
pages = {41--53},
title = {{Evolving a Lingua Franca and Associated Software Infrastructure for Computational Systems Biology: The Systems Biology Markup Language (SBML) Project}},
volume = {1},
year = {2004}
}
@book{Chapman2008,
abstract = {Programming languages evolve just as natural languages do, driven by human desires to express thoughts more cleverly, succinctly, or elegantly than in the past. A big difference is the fact that one key receiver of programs is nonhuman. These nonhumans evolve faster than humans do, helping drive language mutation after mutation, andtogether with the human program writers and readersnaturally selecting among the mutations. In the 1970s, vector and parallel computer evolution was on the move. Programming assistance was provided by language extensionsfirst to Fortran and then to Cin the form of directives and pragmas, respectively. Vendors differentiated themselves by providing better extensions than did their competitors; and by the mid-1980s things had gotten out of hand for software vendors. At Kuck and Associates (KAI), we had the problem of dealing with the whole industry, so Bruce Leasure and I set out to fix things by forming an industrywide committee, the Parallel Computing Forum (PCF). PCF struck a nerve and became very active. In a few years we had a draft standard that we took through ANSI, and after a few more years it became the ANSI X3.H5 draft. Our stamina gave out before it became an official ANSI standard, but the industry paid attention, and extensions evolved more uniformly. This situation lasted for a few years, but the 1980s were a golden era for parallel architectural evolution, with many people writing parallel programs, so extensions again diverged, and programming needs grew. KAI took on the challenge of rethinking things and defining parallel profiling and correctness-checking tools at the same time, with the goal of innovative software development products. By the mid-1990s we had made a lot of progress and had discussed it a bit with some hardware vendors. When SGI bought Cray in April 1996, they had an immediate directive problem (two distinct extensions) and approached us about working with them. Together we refined what we had, opened up to the industry, and formed the Architecture Review Board (ARB). OpenMP was born 18 months later, as the New York Times reported:},
author = {Chapman, Barbara and Jost, Gabriele and van der Pas, Ruud},
file = {:home/tomaton/Downloads/9780262533027\_sch\_0001.pdf:pdf},
isbn = {0262533022},
publisher = {MIT press},
title = {{Using OpenMP}},
volume = {10},
year = {2008}
}
@article{Crouch2013,
author = {Crouch, Stephen and Hong, Neil Chue and Hettrick, Simon and Jackson, Mike and Pawlik, Aleksandra and Sufi, Shoaib and Carr, Les and {De Roure}, David and Goble, Carole and Parsons, Mark},
doi = {10.1109/MCSE.2013.133},
file = {:home/tomaton/Downloads/06731384.pdf:pdf},
isbn = {1521-9615},
issn = {15219615},
journal = {Computing in Science and Engineering},
keywords = {Domain engineering,Maintainability,Reliability,Scientific computing,Software engineering},
number = {6},
pages = {74--80},
title = {{The Software Sustainability Institute: Changing Research Software Attitudes and Practices}},
volume = {15},
year = {2013}
}
@inproceedings{Kulhanek2008Mefanet,
author = {Kulh\'{a}nek, Tom\'{a}\v{s} and \v{S}\'{a}rek, Milan},
booktitle = {Mefanet 2008},
file = {:home/tomaton/Downloads/25\_kulhanek.pdf:pdf},
publisher = {MSD Brno},
title = {{Virtualizace a integrace v gridov\'{e}m pacs syst\'{e}mu (cze) virtualization and integration in grid pacs system (eng)}},
url = {http://www.mefanet.cz/res/file/mefanet2008/prispevky/25\_kulhanek.pdf},
year = {2008}
}
