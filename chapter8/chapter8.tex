\chapter{Conclusion}
\label{sec:conclusion}

\section{Discussion}
\label{sec:discussion}
%Important decision about utilizing distributed computing infrastructure is what benefits it'll bring with respect of the caveats and resources it'll consume including the human capital compared to other existing solution.

%\subsection{Medical imaging}
%There are several use cases where exchanging or sharing DICOM images are beneficial, next to the second opinion and teleradiology (remote diagnostics), gathering information and expertize in rare diseases, studies in unusual cases or secondary use of clinical imaging data for research, optimizing new processing methods etc. 

%The Globus MEDICUS stores one or more copies of DICOM images within grid infrastructure, and as such, can be used as technology and infrastructure to built data warehouse for DICOM images of specific interest. Another philosophy is to federate files and metadata stored within home institutions, which seems to be preferred solution in hospitals and clinical use which were shown in other medical sharing image projects.

The result presented in section \ref{sec:resultsimages} is an example how a standard format and protocol DICOM is utilized to integrate current production system to exchange medical images (MEDIMED \cite{Slavicek2010}) and a grid based solution (Globus MEDICUS\cite{Erberich2007}). Remote Desktop Protocol (RDP) is also the key point in integrating the application of voice analysis\cite{Fric2007} into remote environment accessible via Internet presented in section \ref{sec:resultsvoice}. Key point in case of parameter estimation is a standard Functional Mockup Interface (FMU)\cite{Blochwitza} which allows controlling and simulating a physiological model in customized tool not related to modeling technology as presented in section \ref{sec:resultsestimation}. 

The selection of a joint element also increase chances of reusability of such system in future development when usually requirements change and reconstruction of a system or architecture is needed. E.g. the presented solution based on the Globus MEDICUS is in general a data warehouse storing one or more copies of DICOM images, however, federated files and metadata stored within home institutions which shares only network infrastructure to interchange the DICOM studies seems to be preferred and more acceptable solution by hospitals thus the authors of Globus MEDICUS in their further development followed a way of federation of medical images stored within home institutions as published by Chervenak et al. \cite{Chervenak2012}. The grid-computing infrastructure seems to be suitable for research and educational purposes rather than for clinical use. %Cloud-computing with ability of hybrid cloud, where part of virtual machines may reside in home institution may be also answer on this issue.

%here an underlying technology is hidden for common user. This research was originally motivated by the idea to investigate benefits and show robust grid-based technology against proprietary distributed technology, which may face up to scalability and maintenance issues. Another issue is the philosophy of storing medical images. The presented solution based on the Globus MEDICUS is in general a data warehouse storing one or more copies of DICOM images, in contrast to federated files and metadata stored within home institutions which shares only network infrastructure to interchange the DICOM studies. This seems to be more acceptable by hospitals and by the national and international regulation for clinical and diagnostic use, e.g. The authors of Globus MEDICUS in their further development followed a way of federation of medical images stored within home institutions rather than in a grid infrastructure published by Chervenak et al. \cite{Chervenak2012}. 
%

%However, the scalability is managed within the current MEDIMED system and separate PACS system including database of anonymized medical images with the medical context and description for research and education purposes coexist within the current system.


%This allows to keep current tools for processing the medical images when the technology of infrastructure is changed.
%Thus user experience is kept on using same tools or same workflows, however, accessing much broader database of records or having more powerful tools for processing the data.
 
The remote access to application via network protocol keeps the majority of user experience in the case of remote voice analysis presented in section \ref{sec:resultsvoice}. Such kind of service can be deployed on any web server and a occasional need to educate or perform higher number of analysis concurrently can be satisfied with cloud-computing deployment. The application process sound signal which is currently analysed by Fast Fourier Transformation algorithm quite effectively. Another challenge becomes to analyze the sound signal connected with high speed video or videokymography methods which needs to transfer, process and store large amount of data. Such future application might utilize the results of grid-based systems for sharing medical images.

In the case of application for parameter estimation presented in section \ref{sec:resultsestimation} the computation is sensitive on communication overhead. For simple models local high performance computing (HPC) resources are most beneficial, for medium and highly complex models the deployment of worker nodes into cloud-computing environment is worth to consider. The application for parameter sweep is embarrassingly parallel and suitable for high throughput computing (HTC) which is the focus of current grid-computing infrastructures. 

%Magnetic Particle Imager \footnote{introduced first by Gleich and Weizenecker\cite{Gleich2005}} (available only for animal models and not yet for human medicine) can produce high resolution images with fast shutter speed (~20 ms). Several computational and storage demanding biomedical application were shown in animal models by Saritas et al.\cite{Saritas2013}. There are research infrastructures which were established to coordinate the research in biology and medicine, e.g. Integrated Structural Biology Infrastructure for Europe (INSTRUCT)\footnote{\url{https://www.structuralbiology.eu/} accessed March 2015}, European Life Science Infrastructure for Biological Information (ELIXIR)\footnote{\url{http://www.elixir-europe.org/} accessed March 2015},  European Biomedical Imaging Infrastructure (Euro-BioImaging)\footnote{\url{http://www.eurobioimaging.eu/} accessed March 2015} and others. The purpose of these initiatives is to understand high-level phenotypes from genomic, metabolomic, proteomic, imaging and other types of data and they requires also multiscale mathematical models and simulation. As noted by Hunter et al.\cite{Hunter2013} such mathematical models can be delivered by physiome projects e.g. by virtual physiological human (VPH)\footnote{\url{http://www.vph-institute.org/} accessed March 2015}. 
%The medical imaging and processing methods are used to identify the parameters of models of human physiology for further diagnosis statement and treatment decision. Current studies focus on very simplified models and reduced number of parameters, e.g. Ralovich et al.\cite{Ralovich2012}
  
%The added value of the grid-computing or cloud-computing technology is the ability of enhanced collaboration in use cases which were difficult to achieve, e.g. in cases if secondary use of clinical imaging data for research

%for is an important area in research of rare diseases. As seen from the results obtained either in previous chapter or by other authors, the grid-computing is only one technology to facilitate some interconection of storage and computation capacity of different sites and servers owned by different organizations or individuals. 

%As seen from the results, there are several main purpose for which the grid-computing or cloud-computing infrastructure was built and are currently used for:
%\begin{enumerate}
%\item{solve big computational problems in distributed environment and achieve results in a reasonable computational time}
%\item{facilitate processing of the computation to support processing, analysis for further scientific results. This is provided by scientific portals, services, workflows etc. which allows non-exports in grid-computing or cloud-computing to do their job reducing researcher's time.}
%\item{share and archive database of scientific data for further processing and reproducibility.}
%\end{enumerate}
%\subsubsection{Scalability}
%
%From the perspective of efficiency (time complexity) and scalability (degree of parallelization) the heuristic methods for parameter estimation application brings at least some solution in a reasonable time. For small models it, however, doesn't make sense as the overhead and parallelizable fraction limits the speedup gain from distribution to grid or cloud-computing\ref{sec:resultsestimation}. 
%
%For complex models the infrastructure of grid-computing or cloud-computing can be used to distribute simulation tasks to explore wider space of possible solution.

%\subsubsection{Platform}

One of the important decision when porting an application to the grid environment is the platform of the used system. The architecture which involves computational nodes deployed in cloud-computing infrastructure was influenced by the fact, that the model implementation is exported from third party tool to the standard FMU library as mentioned in section \ref{sec:methodsestimation} for the MS Windows platform. This determined the platform of the worker node and the virtualization - or in case of parameter estimation a cloud computing is utilized on prepared platform with MS Windows Datacenter license. In case of parameter sweep a desktop-grid computing BOINC worker and application for MS Windows platform only is prepared for volunteers with the compatible system. To utilize service-grid infrastructure an export of the model into FMU library and implementation of the wrapper service must be done in the grid-computing platform which is usually Linux based system. Another option could be to use WINE\footnote{\url{https://www.winehq.org/} WINE. Accessed March 2015} -- compatibility layer capable of running Windows applications on several POSIX-compliant operating systems, such as Linux, Mac OSX, BSD. 

%With respect to scalability the degree and fraction of paralelization from the whole computational process needs to be considered, as, e.g. for simulating simple models and estimating the parameters takes couple of minutes to hours on single computer, which may be acceptable and deployment on grid computing will introduce overhead which degrades the benefits.

%\subsubsection{Porting}
%Each of the introduced systems and application was from it's beginning prepared for serial workflow. To achieve higher level of programming model,  some manual intervention is usually needed on the system or source code of application.

For the smaller types of application and scientific community with their own tools it is the question, whether to invest on porting their tools to grid specific platform and parallel programming model. 
In case of integrating with service grid-middleware or with desktop-grid framework, expert knowledge is needed to configure and customize the system. This is the case of sharing medical images presented in section \ref{sec:resultsimages}) and parameter estimation and parameter sweep which was tried with the desktop-grid approach - BOINC framework\ref{sec:resultsboinc}. %footnote{\url{http://boinc.berkeley.edu/} accessed March 2015}., although by using the wrapper application, no need to develop application code in C,C++ with desktop grid api. 
Virtualization facilitates integrating effort as presented in case of remote analysis of human voice (section \ref{sec:resultsvoice}) and as presented in the case of deployment of worker nodes in cloud computing environment for parameter estimation (section \ref{sec:resultsestimation}). % e.g. in the case of voice science, the analytical application was deployed on virtual machine and made available via remote desktop feature and future development was kept on the platform and environment familiar for the researchers. In the case of parameter estimation a worker nodes for parameter estimation a virtual machines within cloud-computing infrastructure, the similar approach is taken, the specific computational application which runs on local cluster can be strengthen by deploying multiple instances in virtual machines.

Based on the previous results and ideas it can be formulated the answer to the questions from the section \ref{sec:goal}:
\begin{itemize} 
\item \emph{Is it beneficial of utilizing grid-computing and cloud-computing technology for processing medical information and how?}

Grid-computing and cloud-computing may significantly speedup parameter study of medium and complex models in computational physiology. Such speedup might influence applicability in clinical use. %, it was shown that parameter study of the medium and complex models can highly benefit from grid-computing and cloud-computing environment. For the simple models only HPC resources with reduced communication overhead might be beneficial too. 
For the case of sharing and processing medical images or analysis of voice signals, grid-computing or cloud-computing introduce technology to facilitate cooperation among community of users from different geographically dispersed areas and facilitate sharing large data sets.

\item \emph{What are the limitations of processing medical information in grid or cloud?}

Limitation are given by the effort needed to integrate or port an application to do computation or share data. Cost of porting application to cloud-computing is reduced by virtualization technology than to grid-computing environment, which needs additional work to adapt the application for grid-computing platform and API. 

From programming model point of view, limitation are given by the theoretical features of algorithms and problems to solve. Grid-computing and cloud-computing is not general solution for hard problems (NP-complete problems) as discussed in section \ref{sec:introcomplexity}. However connected with non-exact methods a concurrent processing of many tasks may bring acceptable non-exact solution.

\item \emph{How can the grid-computing and cloud-computing influence the direction of biomedical research?}

%The fact that the computation or data are processed remotely is one of the paradigm shift. The data moves from files stored in some folder to elements or objects living somewhere on server or cloud which can be shared among researchers. 
 
% proposed a noninvasive method based on computational fluid dynamic and magnetic resonance imaging (MRI) to identify pressure difference in aorta for further hemodynamics analysis based on four element windkessel model. However, such type of studies usually focus on particular phenomenon and tries identify parameters of very simplified models that are currently known in systems biology domain. In the time of writing this thesis, 

%And the grid-based or  cloud-based medical data management solution can be used as technology and infrastructure to store and share the expected big ammount of raw scientific results, such as images or videos. 
%Several computational and storage demanding biomedical application were shown in animal models by Saritas et al.\cite{Saritas2013}. 
There are research infrastructures which were established to coordinate the research in biology and medicine, e.g. Integrated Structural Biology Infrastructure for Europe (INSTRUCT)\footnote{\url{https://www.structuralbiology.eu/} accessed March 2015}, European Life Science Infrastructure for Biological Information (ELIXIR)\footnote{\url{http://www.elixir-europe.org/} accessed March 2015},  European Biomedical Imaging Infrastructure (Euro-BioImaging)\footnote{\url{http://www.eurobioimaging.eu/} accessed March 2015} and others which technologically rely on grid-computing and cloud-computing infrustructures for science. The purpose of these initiatives is to understand high-level phenotypes from genomic, metabolomic, proteomic, imaging and other types of data and they require also multiscale mathematical models and simulation as noted e.g. by Hunter et al. \cite{Hunter2013} in his strategy for Virtual Physiological Human (VPH)\footnote{\url{http://www.vph-institute.org/} accessed March 2015}.

The integration with multidimensional models of geometrical, mechanical properties and the time-dependence of the compartments data taken from the medical and biological repositories is a challenge for current "physiome" projects and might be very beneficial with current most complex models of human physiology which are based mainly on lumped-parameter approach. The area of parameter study presented in section \ref{sec:resultsestimation} may deliver more exact lumped-parameter models and practical application for clinical and further research towards patient specific health care, in silico trails and drug discovery. 

%Some of the methods and pilot results were shown in sections \ref{sec:resultsestimation} and \ref{sec:resultsboinc}. 
\end{itemize}

%\subsection{Long-tail of science}

Based on the previous answers, it can be formulated another question for further research in the technology domain: 

\emph{How can biomedical research influence the direction of grid-computing and cloud-computing development?}

One area of discussion about this theme is how to preserve the scientific data to prevent loss of them \cite{Vines2014,P.BryanHeidorn2008} and how to facilitate access to computational resources for large amount of small scientific groups which have limited resources to port, integrate or customize their current tools and processes -- to support "long-tail" of science. The "long-tail" movement was noted and described first by Anderson \cite{Anderson2006} in business domain. % as a shift of business strategy focusing on offering and delivering not only very popular products but also products with relatively small quantities sold each to final consumers. 
The long-tail term comes from a feature of statistical distribution e.g. pareto distribution where only few (e.g. 20\% -- head) elements has high probability of some event (e.g. product being sold), while the rest (e.g. 80\% -- tail) has small probability. Thus, most business focus on hits (20\% of products, the 80-20 rule). The expansion of Internet and it's related technologies caused reduced sales, marketing and delivery costs for the products from the niche (80\% of products) -- long-tail. Strategy focusing on this kind of products became profitable and successful e.g. for companies such as Amazon or Apple.\cite{Anderson2006}. 
Cloud-computing technologies seems to be customizable and may be an enabling technology to focus on long-tail science consumers as noted e.g. by Weinhardt et al. \cite{Weinhardt2009}. Platform as a service may be a type of access to cloud-computing infrastructure to bridge the gap between programming application utilizing the powerful scientific infrastructure and keep focus on domain specific research as it is achieved by research portals and workflows for grid-computing infrastructures presented in section \ref{sec:introworkflows}.
% While infrastructure as a service approach delivered by cloud-computing gives a freedom to create virtual environment and deploy any type of application, Software as a service delivers usually solution for particular problem. The Platform as a service approach may be an challenge for further cloud-computing infrastructure development as it can deliver some kind of tool which is not solution, but can give a scientists a formal way to describe the problem, import data and visualize the processing of information using programming language capabilities but with strong tools and common workflows already implemented to address the long-tail of science.
%For the case of algorithms, that are already present in grid-computing middleware is key factor the worker/simulation part which is specific for each research community. 
%The infrastructure built for purpose of large projects becomes open for smaller teams of scientists who doesn't have strong IT department or background. The process introduced before might be inneficient in terms of researcher's time who may spent time to porting it's application and tunning it up in grid or cloud environment. 
%Integration to tools researchers already use, or introduce new tools with low learning curve ...
%It was also shown that the batch-processing is not appropriate for some sort of application. The voice analysis is expected to be done in real-time and with access to some additional software, services and databases which are hard to maintain locally. 
%\subsubsection{Long Tail Science}

%The provenance and reproducibility of scientific results implied a need to long-term preservation of scientific data, however, if it is left on individual researcher, there is loss of data, as analysed by Vines et al. or Heidorn \cite{Vines2014,P.BryanHeidorn2008}.


\section{Summary}

This thesis presents the infrastructure which thanks to virtualization technology joined several domain specific tools in the field of sharing and processing medical images, performing real-time voice analysis and simulating human physiology.  

A seamless integration of grid-based PACS system was established with current distributed system to share DICOM medical images. Access to real-time voice analysis application via remote desktop technology brings this type of service to any computer capable to connect to Internet. A system to support analysis and building complex models of human physiology in the phase of parameter estimation and parameter sweep was introduced and additional computational nodes can be flexibly joined by starting prepared virtual machines in cloud-computing deployment. Methodology of building complex models of human physiology was contributed with the idea of acausal and object-oriented modeling techniques. Methods for parameter study was shown and parameter study of complex models gain substantial speedup by utilizing cloud-computing deployment, which makes such kind of complex study applicable in physiological and biological research.
